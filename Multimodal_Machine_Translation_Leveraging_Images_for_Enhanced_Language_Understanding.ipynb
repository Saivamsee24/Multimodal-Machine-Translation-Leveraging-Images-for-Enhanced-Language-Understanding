{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saivamsee24/Multimodal-Machine-Translation-Leveraging-Images-for-Enhanced-Language-Understanding/blob/main/Multimodal_Machine_Translation_Leveraging_Images_for_Enhanced_Language_Understanding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUljMCgcMJpv",
        "outputId": "21642b1b-e961-42f9-c74e-a596ab954faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Info ‚Üí GPU 0: NVIDIA L4 (UUID: GPU-118ded44-0181-16e2-816b-c2bdd3b7d899)\n",
            "\n",
            "‚ö†Ô∏è WARNING: You did NOT receive an A100/H100.\n",
            "Training will be 10‚Äì20√ó slower.\n",
            "Please restart runtime until you get an A100/H100.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "gpu_info = subprocess.check_output(\"nvidia-smi -L\", shell=True).decode()\n",
        "print(\"GPU Info ‚Üí\", gpu_info)\n",
        "\n",
        "if \"A100\" not in gpu_info and \"H100\" not in gpu_info:\n",
        "    print(\"‚ö†Ô∏è WARNING: You did NOT receive an A100/H100.\")\n",
        "    print(\"Training will be 10‚Äì20√ó slower.\")\n",
        "    print(\"Please restart runtime until you get an A100/H100.\")\n",
        "else:\n",
        "    print(\"‚úÖ Great! You received a premium GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV9sbMe_YjxD",
        "outputId": "7a45b542-3ee2-4cb5-c61d-f2cd4e2c59e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e6704f2477fe8229a618e4782f4d81d5c2f2cc310da099a4e5c19d9e1fb0202c\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.9.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert_score) (4.57.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert_score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert_score) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert_score) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert_score) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert_score) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert_score) (2025.11.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert_score) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.3)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install transformers\n",
        "!pip install sacrebleu\n",
        "!pip install sentencepiece\n",
        "!pip install -U transformers accelerate datasets evaluate sentencepiece\n",
        "!pip install wandb\n",
        "!pip install rouge_score\n",
        "!pip install bert_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCnbl-RLwDic"
      },
      "outputs": [],
      "source": [
        "#Individual Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1apaftW-W7pY",
        "outputId": "e77b7589-d69f-494f-eefc-66ee71fad18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "üîó Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Found dataset at: /content/drive/MyDrive/dataset/multi30k-dataset\n",
            "üîó Symlink created ‚Üí /content/multi30k-dataset\n",
            "üîÑ Loading MBart tokenizer & SigLIP processor...\n",
            "üíæ Config saved at: /content/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: EN ‚Üí DE\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üíde)\n",
            "üîé Checking files for val en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: en‚Üíde)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [3:22:38<00:00,  1.62s/it, loss=0.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9370\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.50\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:52<00:00,  6.29it/s, loss=0.762]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8312\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 41.21\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:52<00:00,  6.29it/s, loss=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7771\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.42\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:53<00:00,  6.28it/s, loss=1.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7317\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.24\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:55<00:00,  6.27it/s, loss=0.207]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6974\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.21\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:01<00:00,  6.24it/s, loss=0.551]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6717\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.29\n",
            "üõë Early stopping MULTIMODAL en‚Üíde at epoch 6\n",
            "‚úÖ Finished MULTIMODAL training en‚Üíde | Best BLEU: 42.42\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:50<00:00,  8.42it/s, loss=0.62]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.9554\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 39.27\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:51<00:00,  8.41it/s, loss=1.41]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8746\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 39.82\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:49<00:00,  8.43it/s, loss=1.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8433\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.31\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:51<00:00,  8.42it/s, loss=0.784]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8187\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.86\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:47<00:00,  8.45it/s, loss=1.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8049\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.74\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:47<00:00,  8.45it/s, loss=0.534]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7961\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.99\n",
            "‚úÖ Finished TEXT-ONLY training en‚Üíde | Best BLEU: 40.86\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: EN ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üífr)\n",
            "üîé Checking files for val en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: en‚Üífr)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:59<00:00,  6.25it/s, loss=0.675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8600\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 51.84\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:09<00:00,  6.20it/s, loss=1.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7128\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 53.28\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:20<00:00,  6.14it/s, loss=0.328]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6471\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 55.12\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:18<00:00,  6.15it/s, loss=0.393]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6008\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 55.60\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:20<00:00,  6.14it/s, loss=0.409]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.5661\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 56.18\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:20<00:00,  6.15it/s, loss=0.254]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.5416\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 56.59\n",
            "‚úÖ Finished MULTIMODAL training en‚Üífr | Best BLEU: 56.18\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:01<00:00,  8.32it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.9008\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 48.44\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:02<00:00,  8.31it/s, loss=0.896]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7781\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 50.03\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:04<00:00,  8.30it/s, loss=0.97]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7376\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.69\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:00<00:00,  8.33it/s, loss=0.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7110\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 52.38\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:02<00:00,  8.31it/s, loss=0.679]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.6925\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 52.84\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:59<00:00,  8.34it/s, loss=0.194]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.6820\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 52.86\n",
            "‚úÖ Finished TEXT-ONLY training en‚Üífr | Best BLEU: 52.38\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: DE ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üíen)\n",
            "üîé Checking files for val de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: de‚Üíen)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:12<00:00,  6.18it/s, loss=0.609]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8808\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 44.66\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:11<00:00,  6.19it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7947\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 46.41\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:07<00:00,  6.21it/s, loss=0.716]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7447\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 46.24\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:59<00:00,  6.25it/s, loss=0.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7030\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 46.45\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:54<00:00,  6.28it/s, loss=0.674]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6704\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 46.90\n",
            "üõë Early stopping MULTIMODAL de‚Üíen at epoch 5\n",
            "‚úÖ Finished MULTIMODAL training de‚Üíen | Best BLEU: 46.41\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:02<00:00,  8.31it/s, loss=0.363]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8824\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 44.43\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:45<00:00,  8.47it/s, loss=1.8]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8264\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.25\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [15:00<00:00,  8.33it/s, loss=0.391]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8019\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.64\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:50<00:00,  8.42it/s, loss=0.466]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7843\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.78\n",
            "   üíæ Saved best TEXT-ONLY model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:44<00:00,  8.48it/s, loss=1.07]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7741\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.76\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:56<00:00,  8.37it/s, loss=0.269]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7661\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 46.09\n",
            "‚úÖ Finished TEXT-ONLY training de‚Üíen | Best BLEU: 45.78\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: DE ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üífr)\n",
            "üîé Checking files for val de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: de‚Üífr)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:00<00:00,  6.25it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.2171\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 35.63\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:57<00:00,  6.26it/s, loss=0.875]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.0412\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 39.27\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:59<00:00,  6.25it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9676\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.63\n",
            "   üíæ Saved best MULTIMODAL model ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:02<00:00,  6.24it/s, loss=0.404]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9151\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 41.02\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:01<00:00,  6.24it/s, loss=0.484]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8727\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 41.01\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 5083/7500 [13:32<06:34,  6.13it/s, loss=0.662]"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# üåç MULTIMODAL TRANSLATION + SIGLIP + LORA + FUSION vs TEXT-ONLY\n",
        "#  - Multi30K (data/task1/raw + image_splits)\n",
        "#  - SigLIP vision encoder (google/siglip-base-patch16-224)\n",
        "#  - mBART-50 text model with LoRA on attention (q_proj, v_proj)\n",
        "#  - Better fusion: Transformer-based fusion over [IMG + TEXT]\n",
        "#  - Also trains text-only mBART+LoRA baseline for comparison\n",
        "# ==============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    os.system(\"pip install -q transformers peft accelerate\")\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ DEVICE ------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ============================================================== #\n",
        "# CONFIG\n",
        "# ============================================================== #\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Paths\n",
        "    data_root: str = \"/content/multi30k-dataset\"\n",
        "    image_dir: str = \"flickr30k-images\"\n",
        "    save_dir: str = \"/content/multimodal_translation_models_siglip_lora_fusion\"\n",
        "\n",
        "    # Training\n",
        "    max_length: int = 64\n",
        "    batch_size: int = 2          # small for VRAM safety\n",
        "    learning_rate: float = 3e-5\n",
        "    num_epochs: int = 6\n",
        "    patience: int = 3\n",
        "    min_delta: float = 0.5       # BLEU improvement threshold to reset patience\n",
        "    use_amp: bool = True\n",
        "\n",
        "    # Data limits\n",
        "    max_train_samples: int = 15000\n",
        "    max_val_samples: int = 1000\n",
        "\n",
        "    # Optim\n",
        "    warmup_steps: int = 100\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # Vision model (SigLIP)\n",
        "    vision_model_name: str = \"google/siglip-base-patch16-224\"\n",
        "\n",
        "    # LoRA\n",
        "    use_lora: bool = True\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.1\n",
        "    lora_targets: List[str] = None\n",
        "\n",
        "    # Language directions\n",
        "    directions: List[Tuple[str, str]] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lora_targets is None:\n",
        "            # Attn projections in mBART encoder+decoder\n",
        "            self.lora_targets = [\"q_proj\", \"v_proj\"]\n",
        "        if self.directions is None:\n",
        "            self.directions = [\n",
        "                (\"en\", \"de\"),\n",
        "                (\"en\", \"fr\"),\n",
        "                (\"de\", \"en\"),\n",
        "                (\"de\", \"fr\"),\n",
        "                (\"fr\", \"en\"),\n",
        "                (\"fr\", \"de\"),\n",
        "            ]\n",
        "\n",
        "config = Config()\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# Global metric (avoid re-loading each epoch)\n",
        "sacrebleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ============================================================== #\n",
        "# OPTIONAL: DRIVE MOUNT + SYMLINK (if you want)\n",
        "# ============================================================== #\n",
        "\n",
        "def mount_and_link_dataset():\n",
        "    \"\"\"\n",
        "    Mounts Google Drive and links /content/multi30k-dataset to your folder.\n",
        "    Safe: no directory scanning, just checks existence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "    except Exception:\n",
        "        print(\"‚ÑπÔ∏è Not running in Colab / no google.colab, skipping mount.\")\n",
        "        return config.data_root\n",
        "\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    candidate_paths = [\n",
        "        \"/content/drive/MyDrive/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/dataset/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/multi30k-dataset\",\n",
        "    ]\n",
        "\n",
        "    dataset_path = None\n",
        "    for p in candidate_paths:\n",
        "        if os.path.exists(p):\n",
        "            dataset_path = p\n",
        "            print(f\"‚úÖ Found dataset at: {p}\")\n",
        "            break\n",
        "\n",
        "    if dataset_path is None:\n",
        "        print(\"‚ùå Multi30K dataset not found in default locations. Using existing:\", config.data_root)\n",
        "        return config.data_root\n",
        "\n",
        "    if os.path.islink(\"/content/multi30k-dataset\") or os.path.exists(\"/content/multi30k-dataset\"):\n",
        "        os.system(\"rm -rf /content/multi30k-dataset\")\n",
        "\n",
        "    os.symlink(dataset_path, \"/content/multi30k-dataset\")\n",
        "    print(\"üîó Symlink created ‚Üí /content/multi30k-dataset\")\n",
        "    return \"/content/multi30k-dataset\"\n",
        "\n",
        "# ============================================================== #\n",
        "# IMAGE LOADER (NO DIR LISTING)\n",
        "# ============================================================== #\n",
        "\n",
        "def safe_load_image(image_id: str, root: Path) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads one image by ID without listing directories.\n",
        "    Multi30K image IDs in image_splits are usually like \"1234567890.jpg\" or \"1234567890\".\n",
        "    We try: id, id.jpg, id.jpeg, id.png.\n",
        "    \"\"\"\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[: -len(ext)]\n",
        "            break\n",
        "\n",
        "    candidates = [\n",
        "        f\"{base}.jpg\",\n",
        "        f\"{base}.jpeg\",\n",
        "        f\"{base}.png\",\n",
        "        base,\n",
        "    ]\n",
        "\n",
        "    for name in candidates:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # Fallback: dummy gray image\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "# ============================================================== #\n",
        "# LORA HELPER\n",
        "# ============================================================== #\n",
        "\n",
        "def apply_lora_to_mbart(mbart: MBartForConditionalGeneration) -> MBartForConditionalGeneration:\n",
        "    \"\"\"\n",
        "    Wraps mBART with LoRA on attention projections.\n",
        "    \"\"\"\n",
        "    if not config.use_lora:\n",
        "        print(\"‚ÑπÔ∏è LoRA disabled; training full mBART (heavier).\")\n",
        "        return mbart\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    peft_model = get_peft_model(mbart, lora_cfg)\n",
        "    print(\"‚úÖ LoRA applied to mBART (targets:\", config.lora_targets, \")\")\n",
        "    peft_model.print_trainable_parameters()\n",
        "    return peft_model\n",
        "\n",
        "# ============================================================== #\n",
        "# FUSION BLOCK (BETTER THAN PLAIN CONCAT)\n",
        "# ============================================================== #\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Transformer-based fusion over [IMG_TOKEN + TEXT_TOKENS].\n",
        "    Lets the image token attend to text and vice versa.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dim_ff: int = 2048, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed: torch.Tensor, text_embed: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        img_embed: [B,1,d_model]\n",
        "        text_embed: [B,L,d_model]\n",
        "        returns fused: [B,1+L,d_model]\n",
        "        \"\"\"\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)  # [B,1+L,d]\n",
        "        x = self.encoder(x)                            # fuse via self-attention\n",
        "        return x\n",
        "\n",
        "# ============================================================== #\n",
        "# MULTIMODAL MODEL (SIGLIP + MBART + LORA + FUSION)\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # SigLIP vision encoder (vision-only)\n",
        "        print(f\"üîÑ Loading SigLIP vision model: {config.vision_model_name}\")\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "\n",
        "        # Freeze SigLIP to save memory & compute\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # SigLIP vision hidden size\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        print(\"üìê SigLIP vision hidden size:\", vision_dim)\n",
        "\n",
        "        # mBART-50 text model\n",
        "        print(\"üîÑ Loading mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "\n",
        "        # Apply LoRA on mBART\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "        # Shared text embeddings (LoRA-safe)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        # Project SigLIP CLS ‚Üí mBART hidden size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "\n",
        "        # Fusion block\n",
        "        self.fusion = FusionBlock(d_model=self.mbart.config.d_model, nhead=8, dim_ff=2048, dropout=0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        # 1) SigLIP image features (CLS token)\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]   # [B, hidden_dim]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)               # [B,1,d_model]\n",
        "\n",
        "        # 2) Text embeddings from mBART shared embedding matrix\n",
        "        text_embed = self.text_emb(input_ids)                      # [B,L,d_model]\n",
        "\n",
        "        # 3) Transformer-based fusion\n",
        "        fused = self.fusion(img_embed, text_embed)                 # [B,1+L,d_model]\n",
        "\n",
        "        # 4) Attention mask (add image token)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        # 5) mBART forward using inputs_embeds\n",
        "        outputs = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, pixel_values, tokenizer):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)\n",
        "        text_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, text_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# TEXT-ONLY MODEL (MBART + LORA)\n",
        "# ============================================================== #\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"üîÑ Loading text-only mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer):\n",
        "        gen_ids = self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# DATASETS\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, image_ids, src, tgt, tokenizer, image_processor, img_root):\n",
        "        self.ids = image_ids\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "        self.img_proc = image_processor\n",
        "        self.img_root = img_root\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        img = safe_load_image(img_id, self.img_root)\n",
        "        pv = self.img_proc(images=img, return_tensors=\"pt\")[\"pixel_values\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"pixel_values\": pv,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "class TextOnlyDataset(Dataset):\n",
        "    def __init__(self, src, tgt, tokenizer):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "# ============================================================== #\n",
        "# LOAD SPLIT\n",
        "# ============================================================== #\n",
        "\n",
        "def load_split(root, split, src_lang, tgt_lang, limit):\n",
        "    \"\"\"\n",
        "    Expects:\n",
        "      root/data/task1/raw/{split}/{split}.{lang}\n",
        "      root/data/task1/image_splits/{split}.txt\n",
        "    \"\"\"\n",
        "    root = Path(root)\n",
        "    raw = root / \"data\" / \"task1\" / \"raw\" / split\n",
        "    id_file = root / \"data\" / \"task1\" / \"image_splits\" / f\"{split}.txt\"\n",
        "\n",
        "    src_file = raw / f\"{split}.{src_lang}\"\n",
        "    tgt_file = raw / f\"{split}.{tgt_lang}\"\n",
        "\n",
        "    print(f\"üîé Checking files for {split} {src_lang}‚Üí{tgt_lang}\")\n",
        "    print(\"   \", src_file)\n",
        "    print(\"   \", tgt_file)\n",
        "    print(\"   \", id_file)\n",
        "\n",
        "    if not src_file.exists() or not tgt_file.exists() or not id_file.exists():\n",
        "        print(f\"‚ùå Missing one or more files for {split} ({src_lang}‚Üí{tgt_lang})\")\n",
        "        return [], [], []\n",
        "\n",
        "    ids = [l.strip() for l in open(id_file, encoding=\"utf-8\") if l.strip()]\n",
        "    src = [l.strip() for l in open(src_file, encoding=\"utf-8\") if l.strip()]\n",
        "    tgt = [l.strip() for l in open(tgt_file, encoding=\"utf-8\") if l.strip()]\n",
        "\n",
        "    n = min(len(ids), len(src), len(tgt), limit)\n",
        "    print(f\"‚úÖ Loaded {n} samples ({split}: {src_lang}‚Üí{tgt_lang})\")\n",
        "    return ids[:n], src[:n], tgt[:n]\n",
        "\n",
        "# ============================================================== #\n",
        "# TRAINING + EVAL HELPERS\n",
        "# ============================================================== #\n",
        "\n",
        "def compute_bleu_multimodal(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, pv, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Multimodal BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "def compute_bleu_text(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Text-only BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "# ------------------ TRAIN MULTIMODAL ------------------ #\n",
        "\n",
        "def train_multimodal_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = MultiModalModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [MULTIMODAL] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[MM Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, pv, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, pv, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (multimodal)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Multimodal avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating multimodal on validation...\")\n",
        "        bleu = compute_bleu_multimodal(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "            save_dir = Path(config.save_dir)\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            save_path = save_dir / f\"siglip_fusion_lora_{src_lang}_{tgt_lang}_mm_best.pt\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"   üíæ Saved best MULTIMODAL model ‚Üí {save_path}\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping MULTIMODAL {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished MULTIMODAL training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ------------------ TRAIN TEXT-ONLY ------------------ #\n",
        "\n",
        "def train_text_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = TextOnlyModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [TEXT-ONLY] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[TXT Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (text-only)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Text-only avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating TEXT-ONLY on validation...\")\n",
        "        bleu = compute_bleu_text(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "            save_dir = Path(config.save_dir)\n",
        "            save_dir.mkdir(parents=True, exist_ok=True)\n",
        "            save_path = save_dir / f\"mbart_lora_{src_lang}_{tgt_lang}_text_best.pt\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"   üíæ Saved best TEXT-ONLY model ‚Üí {save_path}\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping TEXT-ONLY {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished TEXT-ONLY training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ============================================================== #\n",
        "# MAIN\n",
        "# ============================================================== #\n",
        "\n",
        "def main():\n",
        "    # Optional: remap data_root via Drive symlink\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        config.data_root = mount_and_link_dataset()\n",
        "\n",
        "    os.makedirs(config.save_dir, exist_ok=True)\n",
        "\n",
        "    print(\"üîÑ Loading MBart tokenizer & SigLIP processor...\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "        \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "    )\n",
        "    image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "    # Save config\n",
        "    cfg_path = Path(config.save_dir) / \"config_siglip_fusion_lora.json\"\n",
        "    with open(cfg_path, \"w\") as f:\n",
        "        json.dump(asdict(config), f, indent=2)\n",
        "    print(f\"üíæ Config saved at: {cfg_path}\")\n",
        "\n",
        "    results_multimodal = {}\n",
        "    results_textonly = {}\n",
        "\n",
        "    for src, tgt in config.directions:\n",
        "        print(\"\\n======================================================================\")\n",
        "        print(f\"üèÅ LANGUAGE PAIR: {src.upper()} ‚Üí {tgt.upper()}\")\n",
        "        print(\"======================================================================\")\n",
        "\n",
        "        tokenizer.src_lang = LANG_CODES[src]\n",
        "        tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "        train_ids, train_src, train_tgt = load_split(\n",
        "            config.data_root, \"train\", src, tgt, config.max_train_samples\n",
        "        )\n",
        "        val_ids, val_src, val_tgt = load_split(\n",
        "            config.data_root, \"val\", src, tgt, config.max_val_samples\n",
        "        )\n",
        "\n",
        "        if len(train_ids) == 0:\n",
        "            print(f\"‚ö†Ô∏è Skipping {src}‚Üí{tgt} (no data)\")\n",
        "            continue\n",
        "\n",
        "        img_root = Path(config.data_root) / config.image_dir\n",
        "\n",
        "        # Datasets\n",
        "        train_mm = MultiModalDataset(\n",
        "            train_ids, train_src, train_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "        val_mm = MultiModalDataset(\n",
        "            val_ids, val_src, val_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "\n",
        "        train_txt = TextOnlyDataset(train_src, train_tgt, tokenizer)\n",
        "        val_txt = TextOnlyDataset(val_src, val_tgt, tokenizer)\n",
        "\n",
        "        # ----- Train MULTIMODAL -----\n",
        "        mm_bleu = train_multimodal_model(src, tgt, tokenizer, train_mm, val_mm)\n",
        "        results_multimodal[f\"{src}_{tgt}\"] = mm_bleu\n",
        "\n",
        "        # ----- Train TEXT-ONLY -----\n",
        "        txt_bleu = train_text_model(src, tgt, tokenizer, train_txt, val_txt)\n",
        "        results_textonly[f\"{src}_{tgt}\"] = txt_bleu\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (MULTIMODAL):\")\n",
        "    for k, v in results_multimodal.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (TEXT-ONLY):\")\n",
        "    for k, v in results_textonly.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeojP8Mqr4dB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxI1KnWu76RR",
        "outputId": "e662b151-8877-4453-bcaf-78b7752c7f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "üîó Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Found dataset at: /content/drive/MyDrive/dataset/multi30k-dataset\n",
            "üîó Symlink created ‚Üí /content/multi30k-dataset\n",
            "üíæ Drive save dir: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "üîÑ Loading MBart tokenizer & SigLIP processor...\n",
            "üíæ Config saved (local) at: /content/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "üíæ Config saved (drive) at: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: EN ‚Üí DE\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üíde)\n",
            "üîé Checking files for val en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: en‚Üíde)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [3:33:36<00:00,  1.71s/it, loss=1.92]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9342\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.08\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:50<00:00,  6.30it/s, loss=0.53]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8313\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.59\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:12<00:00,  6.18it/s, loss=0.963]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7708\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 41.38\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:13<00:00,  6.18it/s, loss=0.562]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7269\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.00\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:08<00:00,  6.21it/s, loss=0.424]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6927\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.84\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:14<00:00,  6.18it/s, loss=0.531]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6671\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 42.92\n",
            "‚úÖ Finished MULTIMODAL training en‚Üíde | Best BLEU: 42.84\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:43<00:00,  8.49it/s, loss=0.674]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.9582\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 39.66\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:48<00:00,  8.44it/s, loss=0.429]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8744\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.11\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:49<00:00,  8.43it/s, loss=0.868]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8423\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.24\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:47<00:00,  8.45it/s, loss=0.823]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8189\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.61\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:47<00:00,  8.45it/s, loss=0.434]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8048\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.90\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî en‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:50<00:00,  8.42it/s, loss=0.583]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7954\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 40.75\n",
            "‚úÖ Finished TEXT-ONLY training en‚Üíde | Best BLEU: 40.90\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: EN ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üífr)\n",
            "üîé Checking files for val en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: en‚Üífr)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:06<00:00,  6.22it/s, loss=0.273]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8575\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 51.56\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:07<00:00,  6.21it/s, loss=0.352]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7151\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 53.22\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:28<00:00,  6.11it/s, loss=0.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6495\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 55.73\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:27<00:00,  6.11it/s, loss=0.46]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6041\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 55.87\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:06<00:00,  6.22it/s, loss=0.128]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.5695\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 56.03\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:07<00:00,  6.21it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.5434\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 56.68\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "‚úÖ Finished MULTIMODAL training en‚Üífr | Best BLEU: 56.68\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:53<00:00,  8.39it/s, loss=0.861]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.9013\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 48.05\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:56<00:00,  8.36it/s, loss=0.442]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7792\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 50.77\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:55<00:00,  8.37it/s, loss=0.598]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7350\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.70\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:55<00:00,  8.37it/s, loss=0.728]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7100\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.99\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:54<00:00,  8.38it/s, loss=0.81]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.6938\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 52.85\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî en‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train en->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:55<00:00,  8.37it/s, loss=0.141]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.6816\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 52.80\n",
            "‚úÖ Finished TEXT-ONLY training en‚Üífr | Best BLEU: 52.85\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: DE ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üíen)\n",
            "üîé Checking files for val de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: de‚Üíen)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:09<00:00,  6.20it/s, loss=0.692]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8817\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 44.57\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:09<00:00,  6.20it/s, loss=0.437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7957\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 45.61\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:33<00:00,  6.08it/s, loss=1.56]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7478\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 45.92\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:05<00:00,  6.22it/s, loss=0.832]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7068\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 46.79\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:28<00:00,  6.10it/s, loss=0.599]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6727\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 47.40\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:27<00:00,  6.11it/s, loss=0.927]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6466\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 47.24\n",
            "‚úÖ Finished MULTIMODAL training de‚Üíen | Best BLEU: 47.40\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:52<00:00,  8.40it/s, loss=0.751]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8841\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 44.24\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:53<00:00,  8.40it/s, loss=0.925]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8269\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.08\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:52<00:00,  8.40it/s, loss=0.518]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8013\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 45.40\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:50<00:00,  8.42it/s, loss=0.541]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7846\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 46.02\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:53<00:00,  8.39it/s, loss=0.582]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7737\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 46.17\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî de‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:48<00:00,  8.44it/s, loss=0.679]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7655\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 46.47\n",
            "‚úÖ Finished TEXT-ONLY training de‚Üíen | Best BLEU: 46.02\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: DE ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üífr)\n",
            "üîé Checking files for val de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: de‚Üífr)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:57<00:00,  6.26it/s, loss=0.487]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.2159\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 36.00\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:03<00:00,  6.23it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.0409\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 38.56\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:18<00:00,  6.16it/s, loss=0.581]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9680\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 39.85\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:59<00:00,  6.25it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9124\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.49\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:49<00:00,  6.30it/s, loss=0.789]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8721\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.96\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:28<00:00,  6.42it/s, loss=0.631]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8444\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 40.98\n",
            "‚úÖ Finished MULTIMODAL training de‚Üífr | Best BLEU: 40.49\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:32<00:00,  8.60it/s, loss=0.967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.2708\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 33.55\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:55<00:00,  8.37it/s, loss=0.394]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.1103\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 36.01\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:53<00:00,  8.39it/s, loss=0.833]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.0596\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 37.34\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:54<00:00,  8.38it/s, loss=1.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.0287\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 38.19\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:57<00:00,  8.36it/s, loss=0.754]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.0093\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 38.51\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî de‚Üífr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train de->fr]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:57<00:00,  8.36it/s, loss=1.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.9989\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 38.37\n",
            "‚úÖ Finished TEXT-ONLY training de‚Üífr | Best BLEU: 38.19\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: FR ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: fr‚Üíen)\n",
            "üîé Checking files for val fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: fr‚Üíen)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:03<00:00,  6.23it/s, loss=0.803]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8398\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 50.35\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:06<00:00,  6.22it/s, loss=0.186]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7411\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 51.65\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:28<00:00,  6.11it/s, loss=0.442]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6874\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 52.87\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:29<00:00,  6.10it/s, loss=0.711]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6475\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 53.90\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:25<00:00,  6.12it/s, loss=0.889]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6167\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 53.98\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 3498/7500 [09:20<10:56,  6.10it/s, loss=0.289]"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# üåç MULTIMODAL TRANSLATION + SIGLIP + LORA + FUSION vs TEXT-ONLY\n",
        "#  - Multi30K (data/task1/raw + image_splits)\n",
        "#  - SigLIP vision encoder (google/siglip-base-patch16-224)\n",
        "#  - mBART-50 text model with LoRA on attention (q_proj, v_proj)\n",
        "#  - Better fusion: Transformer-based fusion over [IMG + TEXT]\n",
        "#  - Also trains text-only mBART+LoRA baseline for comparison\n",
        "#  - Saves models in BOTH Colab and Google Drive\n",
        "# ==============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    os.system(\"pip install -q transformers peft accelerate\")\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ DEVICE ------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ============================================================== #\n",
        "# CONFIG\n",
        "# ============================================================== #\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Paths\n",
        "    data_root: str = \"/content/multi30k-dataset\"\n",
        "    image_dir: str = \"flickr30k-images\"\n",
        "\n",
        "    # Local Colab save dir\n",
        "    save_dir: str = \"/content/multimodal_translation_models_siglip_lora_fusion\"\n",
        "    # Drive save dir (we'll ensure it exists if Drive is mounted)\n",
        "    drive_save_dir: str = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "\n",
        "    # Training\n",
        "    max_length: int = 64\n",
        "    batch_size: int = 2          # small for VRAM safety\n",
        "    learning_rate: float = 3e-5\n",
        "    num_epochs: int = 6\n",
        "    patience: int = 3\n",
        "    min_delta: float = 0.5       # BLEU improvement threshold to reset patience\n",
        "    use_amp: bool = True\n",
        "\n",
        "    # Data limits\n",
        "    max_train_samples: int = 15000\n",
        "    max_val_samples: int = 1000\n",
        "\n",
        "    # Optim\n",
        "    warmup_steps: int = 100\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # Vision model (SigLIP)\n",
        "    vision_model_name: str = \"google/siglip-base-patch16-224\"\n",
        "\n",
        "    # LoRA\n",
        "    use_lora: bool = True\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.1\n",
        "    lora_targets: List[str] = None\n",
        "\n",
        "    # Language directions\n",
        "    directions: List[Tuple[str, str]] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lora_targets is None:\n",
        "            # Attn projections in mBART encoder+decoder\n",
        "            self.lora_targets = [\"q_proj\", \"v_proj\"]\n",
        "        if self.directions is None:\n",
        "            self.directions = [\n",
        "                (\"en\", \"de\"),\n",
        "                (\"en\", \"fr\"),\n",
        "                (\"de\", \"en\"),\n",
        "                (\"de\", \"fr\"),\n",
        "                (\"fr\", \"en\"),\n",
        "                (\"fr\", \"de\"),\n",
        "            ]\n",
        "\n",
        "config = Config()\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# Global metric (avoid re-loading each epoch)\n",
        "sacrebleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ============================================================== #\n",
        "# OPTIONAL: DRIVE MOUNT + SYMLINK (if you want)\n",
        "# ============================================================== #\n",
        "\n",
        "def mount_and_link_dataset():\n",
        "    \"\"\"\n",
        "    Mounts Google Drive and links /content/multi30k-dataset to your folder.\n",
        "    Safe: no directory scanning, just checks existence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "    except Exception:\n",
        "        print(\"‚ÑπÔ∏è Not running in Colab / no google.colab, skipping mount.\")\n",
        "        return config.data_root\n",
        "\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    candidate_paths = [\n",
        "        \"/content/drive/MyDrive/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/dataset/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/multi30k-dataset\",\n",
        "    ]\n",
        "\n",
        "    dataset_path = None\n",
        "    for p in candidate_paths:\n",
        "        if os.path.exists(p):\n",
        "            dataset_path = p\n",
        "            print(f\"‚úÖ Found dataset at: {p}\")\n",
        "            break\n",
        "\n",
        "    if dataset_path is None:\n",
        "        print(\"‚ùå Multi30K dataset not found in default locations. Using existing:\", config.data_root)\n",
        "        return config.data_root\n",
        "\n",
        "    if os.path.islink(\"/content/multi30k-dataset\") or os.path.exists(\"/content/multi30k-dataset\"):\n",
        "        os.system(\"rm -rf /content/multi30k-dataset\")\n",
        "\n",
        "    os.symlink(dataset_path, \"/content/multi30k-dataset\")\n",
        "    print(\"üîó Symlink created ‚Üí /content/multi30k-dataset\")\n",
        "    return \"/content/multi30k-dataset\"\n",
        "\n",
        "# ============================================================== #\n",
        "# IMAGE LOADER (NO DIR LISTING)\n",
        "# ============================================================== #\n",
        "\n",
        "def safe_load_image(image_id: str, root: Path) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads one image by ID without listing directories.\n",
        "    Multi30K image IDs in image_splits are usually like \"1234567890.jpg\" or \"1234567890\".\n",
        "    We try: id, id.jpg, id.jpeg, id.png.\n",
        "    \"\"\"\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[: -len(ext)]\n",
        "            break\n",
        "\n",
        "    candidates = [\n",
        "        f\"{base}.jpg\",\n",
        "        f\"{base}.jpeg\",\n",
        "        f\"{base}.png\",\n",
        "        base,\n",
        "    ]\n",
        "\n",
        "    for name in candidates:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # Fallback: dummy gray image\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "# ============================================================== #\n",
        "# LORA HELPER\n",
        "# ============================================================== #\n",
        "\n",
        "def apply_lora_to_mbart(mbart: MBartForConditionalGeneration) -> MBartForConditionalGeneration:\n",
        "    \"\"\"\n",
        "    Wraps mBART with LoRA on attention projections.\n",
        "    \"\"\"\n",
        "    if not config.use_lora:\n",
        "        print(\"‚ÑπÔ∏è LoRA disabled; training full mBART (heavier).\")\n",
        "        return mbart\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    peft_model = get_peft_model(mbart, lora_cfg)\n",
        "    print(\"‚úÖ LoRA applied to mBART (targets:\", config.lora_targets, \")\")\n",
        "    peft_model.print_trainable_parameters()\n",
        "    return peft_model\n",
        "\n",
        "# ============================================================== #\n",
        "# FUSION BLOCK (BETTER THAN PLAIN CONCAT)\n",
        "# ============================================================== #\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Transformer-based fusion over [IMG_TOKEN + TEXT_TOKENS].\n",
        "    Lets the image token attend to text and vice versa.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dim_ff: int = 2048, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed: torch.Tensor, text_embed: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        img_embed: [B,1,d_model]\n",
        "        text_embed: [B,L,d_model]\n",
        "        returns fused: [B,1+L,d_model]\n",
        "        \"\"\"\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)  # [B,1+L,d]\n",
        "        x = self.encoder(x)                            # fuse via self-attention\n",
        "        return x\n",
        "\n",
        "# ============================================================== #\n",
        "# MULTIMODAL MODEL (SIGLIP + MBART + LORA + FUSION)\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # SigLIP vision encoder (vision-only)\n",
        "        print(f\"üîÑ Loading SigLIP vision model: {config.vision_model_name}\")\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "\n",
        "        # Freeze SigLIP to save memory & compute\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # SigLIP vision hidden size\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        print(\"üìê SigLIP vision hidden size:\", vision_dim)\n",
        "\n",
        "        # mBART-50 text model\n",
        "        print(\"üîÑ Loading mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "\n",
        "        # Apply LoRA on mBART\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "        # Shared text embeddings (LoRA-safe)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        # Project SigLIP CLS ‚Üí mBART hidden size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "\n",
        "        # Fusion block\n",
        "        self.fusion = FusionBlock(d_model=self.mbart.config.d_model, nhead=8, dim_ff=2048, dropout=0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        # 1) SigLIP image features (CLS token)\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]   # [B, hidden_dim]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)               # [B,1,d_model]\n",
        "\n",
        "        # 2) Text embeddings from mBART shared embedding matrix\n",
        "        text_embed = self.text_emb(input_ids)                      # [B,L,d_model]\n",
        "\n",
        "        # 3) Transformer-based fusion\n",
        "        fused = self.fusion(img_embed, text_embed)                 # [B,1+L,d_model]\n",
        "\n",
        "        # 4) Attention mask (add image token)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        # 5) mBART forward using inputs_embeds\n",
        "        outputs = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, pixel_values, tokenizer):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)\n",
        "        text_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, text_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# TEXT-ONLY MODEL (MBART + LORA)\n",
        "# ============================================================== #\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"üîÑ Loading text-only mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer):\n",
        "        gen_ids = self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# DATASETS\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, image_ids, src, tgt, tokenizer, image_processor, img_root):\n",
        "        self.ids = image_ids\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "        self.img_proc = image_processor\n",
        "        self.img_root = img_root\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        img = safe_load_image(img_id, self.img_root)\n",
        "        pv = self.img_proc(images=img, return_tensors=\"pt\")[\"pixel_values\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"pixel_values\": pv,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "class TextOnlyDataset(Dataset):\n",
        "    def __init__(self, src, tgt, tokenizer):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "# ============================================================== #\n",
        "# LOAD SPLIT\n",
        "# ============================================================== #\n",
        "\n",
        "def load_split(root, split, src_lang, tgt_lang, limit):\n",
        "    \"\"\"\n",
        "    Expects:\n",
        "      root/data/task1/raw/{split}/{split}.{lang}\n",
        "      root/data/task1/image_splits/{split}.txt\n",
        "    \"\"\"\n",
        "    root = Path(root)\n",
        "    raw = root / \"data\" / \"task1\" / \"raw\" / split\n",
        "    id_file = root / \"data\" / \"task1\" / \"image_splits\" / f\"{split}.txt\"\n",
        "\n",
        "    src_file = raw / f\"{split}.{src_lang}\"\n",
        "    tgt_file = raw / f\"{split}.{tgt_lang}\"\n",
        "\n",
        "    print(f\"üîé Checking files for {split} {src_lang}‚Üí{tgt_lang}\")\n",
        "    print(\"   \", src_file)\n",
        "    print(\"   \", tgt_file)\n",
        "    print(\"   \", id_file)\n",
        "\n",
        "    if not src_file.exists() or not tgt_file.exists() or not id_file.exists():\n",
        "        print(f\"‚ùå Missing one or more files for {split} ({src_lang}‚Üí{tgt_lang})\")\n",
        "        return [], [], []\n",
        "\n",
        "    ids = [l.strip() for l in open(id_file, encoding=\"utf-8\") if l.strip()]\n",
        "    src = [l.strip() for l in open(src_file, encoding=\"utf-8\") if l.strip()]\n",
        "    tgt = [l.strip() for l in open(tgt_file, encoding=\"utf-8\") if l.strip()]\n",
        "\n",
        "    n = min(len(ids), len(src), len(tgt), limit)\n",
        "    print(f\"‚úÖ Loaded {n} samples ({split}: {src_lang}‚Üí{tgt_lang})\")\n",
        "    return ids[:n], src[:n], tgt[:n]\n",
        "\n",
        "# ============================================================== #\n",
        "# TRAINING + EVAL HELPERS\n",
        "# ============================================================== #\n",
        "\n",
        "def compute_bleu_multimodal(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, pv, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Multimodal BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "def compute_bleu_text(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Text-only BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "# ------------------ TRAIN MULTIMODAL ------------------ #\n",
        "\n",
        "def train_multimodal_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds,\n",
        "                           local_save_dir: Path, drive_save_dir: Path | None):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = MultiModalModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [MULTIMODAL] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[MM Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, pv, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, pv, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (multimodal)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Multimodal avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating multimodal on validation...\")\n",
        "        bleu = compute_bleu_multimodal(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = f\"siglip_fusion_lora_{src_lang}_{tgt_lang}_mm_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best MULTIMODAL model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best MULTIMODAL model (drive) ‚Üí {drive_path}\")\n",
        "\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping MULTIMODAL {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished MULTIMODAL training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ------------------ TRAIN TEXT-ONLY ------------------ #\n",
        "\n",
        "def train_text_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds,\n",
        "                     local_save_dir: Path, drive_save_dir: Path | None):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = TextOnlyModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [TEXT-ONLY] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[TXT Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (text-only)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Text-only avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating TEXT-ONLY on validation...\")\n",
        "        bleu = compute_bleu_text(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = f\"mbart_lora_{src_lang}_{tgt_lang}_text_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best TEXT-ONLY model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best TEXT-ONLY model (drive) ‚Üí {drive_path}\")\n",
        "\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping TEXT-ONLY {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished TEXT-ONLY training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ============================================================== #\n",
        "# MAIN\n",
        "# ============================================================== #\n",
        "\n",
        "def main():\n",
        "    # Optional: remap data_root via Drive symlink\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        config.data_root = mount_and_link_dataset()\n",
        "\n",
        "    # Local save dir (Colab)\n",
        "    local_save_dir = Path(config.save_dir)\n",
        "    local_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Drive save dir (if Drive is mounted)\n",
        "    drive_save_dir = None\n",
        "    drive_root = Path(\"/content/drive/MyDrive\")\n",
        "    if drive_root.exists():\n",
        "        drive_save_dir = Path(config.drive_save_dir)\n",
        "        drive_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"üíæ Drive save dir: {drive_save_dir}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Drive not mounted or /content/drive/MyDrive missing; will only save locally.\")\n",
        "\n",
        "    print(\"üîÑ Loading MBart tokenizer & SigLIP processor...\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "        \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "    )\n",
        "    image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "    # Save config (local + drive)\n",
        "    cfg = asdict(config)\n",
        "    cfg_path_local = local_save_dir / \"config_siglip_fusion_lora.json\"\n",
        "    with open(cfg_path_local, \"w\") as f:\n",
        "        json.dump(cfg, f, indent=2)\n",
        "    print(f\"üíæ Config saved (local) at: {cfg_path_local}\")\n",
        "\n",
        "    if drive_save_dir is not None:\n",
        "        cfg_path_drive = drive_save_dir / \"config_siglip_fusion_lora.json\"\n",
        "        with open(cfg_path_drive, \"w\") as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        print(f\"üíæ Config saved (drive) at: {cfg_path_drive}\")\n",
        "\n",
        "    results_multimodal = {}\n",
        "    results_textonly = {}\n",
        "\n",
        "    for src, tgt in config.directions:\n",
        "        print(\"\\n======================================================================\")\n",
        "        print(f\"üèÅ LANGUAGE PAIR: {src.upper()} ‚Üí {tgt.upper()}\")\n",
        "        print(\"======================================================================\")\n",
        "\n",
        "        tokenizer.src_lang = LANG_CODES[src]\n",
        "        tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "        train_ids, train_src, train_tgt = load_split(\n",
        "            config.data_root, \"train\", src, tgt, config.max_train_samples\n",
        "        )\n",
        "        val_ids, val_src, val_tgt = load_split(\n",
        "            config.data_root, \"val\", src, tgt, config.max_val_samples\n",
        "        )\n",
        "\n",
        "        if len(train_ids) == 0:\n",
        "            print(f\"‚ö†Ô∏è Skipping {src}‚Üí{tgt} (no data)\")\n",
        "            continue\n",
        "\n",
        "        img_root = Path(config.data_root) / config.image_dir\n",
        "\n",
        "        # Datasets\n",
        "        train_mm = MultiModalDataset(\n",
        "            train_ids, train_src, train_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "        val_mm = MultiModalDataset(\n",
        "            val_ids, val_src, val_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "\n",
        "        train_txt = TextOnlyDataset(train_src, train_tgt, tokenizer)\n",
        "        val_txt = TextOnlyDataset(val_src, val_tgt, tokenizer)\n",
        "\n",
        "        # ----- Train MULTIMODAL -----\n",
        "        mm_bleu = train_multimodal_model(\n",
        "            src, tgt, tokenizer, train_mm, val_mm,\n",
        "            local_save_dir=local_save_dir,\n",
        "            drive_save_dir=drive_save_dir,\n",
        "        )\n",
        "        results_multimodal[f\"{src}_{tgt}\"] = mm_bleu\n",
        "\n",
        "        # ----- Train TEXT-ONLY -----\n",
        "        txt_bleu = train_text_model(\n",
        "            src, tgt, tokenizer, train_txt, val_txt,\n",
        "            local_save_dir=local_save_dir,\n",
        "            drive_save_dir=drive_save_dir,\n",
        "        )\n",
        "        results_textonly[f\"{src}_{tgt}\"] = txt_bleu\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (MULTIMODAL):\")\n",
        "    for k, v in results_multimodal.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (TEXT-ONLY):\")\n",
        "    for k, v in results_textonly.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjqyfwVBhe_z",
        "outputId": "0383c8e7-d1d2-4777-f7c8-55976294cf3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "üîó Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Found dataset at: /content/drive/MyDrive/dataset/multi30k-dataset\n",
            "üîó Symlink created ‚Üí /content/multi30k-dataset\n",
            "üíæ Drive save dir: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "üîÑ Loading MBart tokenizer & SigLIP processor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Config saved (local) at: /content/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "üíæ Config saved (drive) at: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: FR ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: fr‚Üíen)\n",
            "üîé Checking files for val fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: fr‚Üíen)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [2:00:04<00:00,  1.04it/s, loss=1.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.8408\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 50.29\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:14<00:00,  6.18it/s, loss=0.808]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.7377\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 51.69\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:48<00:00,  6.31it/s, loss=0.859]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6863\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 52.63\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:33<00:00,  6.39it/s, loss=0.391]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6450\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 52.88\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:11<00:00,  6.19it/s, loss=0.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.6112\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 52.98\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:00<00:00,  6.57it/s, loss=0.817]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.5871\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 53.24\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "‚úÖ Finished MULTIMODAL training fr‚Üíen | Best BLEU: 53.24\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:23<00:00,  8.69it/s, loss=0.542]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.8561\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 48.67\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:25<00:00,  8.67it/s, loss=0.891]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7879\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 49.92\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:18<00:00,  8.73it/s, loss=0.469]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7583\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 50.62\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:11<00:00,  8.81it/s, loss=0.733]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7401\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.07\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:31<00:00,  8.61it/s, loss=1.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7253\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.75\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî fr‚Üíen\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->en]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:27<00:00,  8.65it/s, loss=0.335]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 0.7179\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 51.73\n",
            "‚úÖ Finished TEXT-ONLY training fr‚Üíen | Best BLEU: 51.75\n",
            "\n",
            "======================================================================\n",
            "üèÅ LANGUAGE PAIR: FR ‚Üí DE\n",
            "======================================================================\n",
            "üîé Checking files for train fr‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: fr‚Üíde)\n",
            "üîé Checking files for val fr‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 1000 samples (val: fr‚Üíde)\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:48<00:00,  6.31it/s, loss=1.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.2667\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 31.35\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:24<00:00,  6.44it/s, loss=1.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.1166\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 34.03\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [20:01<00:00,  6.24it/s, loss=1.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 1.0440\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 36.08\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:52<00:00,  6.29it/s, loss=0.416]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9897\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 35.82\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:23<00:00,  6.45it/s, loss=0.848]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9461\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 36.46\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [19:26<00:00,  6.43it/s, loss=0.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg train loss: 0.9192\n",
            "   üîç Evaluating multimodal on validation...\n",
            "   üîµ Multimodal BLEU: 36.23\n",
            "üõë Early stopping MULTIMODAL fr‚Üíde at epoch 6\n",
            "‚úÖ Finished MULTIMODAL training fr‚Üíde | Best BLEU: 36.08\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:11<00:00,  8.81it/s, loss=1.89]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.3255\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 29.45\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:05<00:00,  8.87it/s, loss=1.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.1915\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 31.27\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:04<00:00,  8.88it/s, loss=2.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.1483\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 32.29\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:16<00:00,  8.75it/s, loss=0.809]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.1225\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 33.13\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:10<00:00,  8.82it/s, loss=1.77]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.1009\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 33.12\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî fr‚Üíde\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train fr->de]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [14:10<00:00,  8.82it/s, loss=0.967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg train loss: 1.0904\n",
            "   üîç Evaluating TEXT-ONLY on validation...\n",
            "   üîµ Text-only BLEU: 33.21\n",
            "‚úÖ Finished TEXT-ONLY training fr‚Üíde | Best BLEU: 33.13\n",
            "\n",
            "üìä FINAL BLEU SCORES (MULTIMODAL):\n",
            "  fr_en: 53.24\n",
            "  fr_de: 36.08\n",
            "\n",
            "üìä FINAL BLEU SCORES (TEXT-ONLY):\n",
            "  fr_en: 51.75\n",
            "  fr_de: 33.13\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# üåç MULTIMODAL TRANSLATION + SIGLIP + LORA + FUSION vs TEXT-ONLY\n",
        "#  - Multi30K (data/task1/raw + image_splits)\n",
        "#  - SigLIP vision encoder (google/siglip-base-patch16-224)\n",
        "#  - mBART-50 text model with LoRA on attention (q_proj, v_proj)\n",
        "#  - Better fusion: Transformer-based fusion over [IMG + TEXT]\n",
        "#  - Also trains text-only mBART+LoRA baseline for comparison\n",
        "#  - Saves models in BOTH Colab and Google Drive\n",
        "# ==============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    os.system(\"pip install -q transformers peft accelerate\")\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ DEVICE ------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ============================================================== #\n",
        "# CONFIG\n",
        "# ============================================================== #\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Paths\n",
        "    data_root: str = \"/content/multi30k-dataset\"\n",
        "    image_dir: str = \"flickr30k-images\"\n",
        "\n",
        "    # Local Colab save dir\n",
        "    save_dir: str = \"/content/multimodal_translation_models_siglip_lora_fusion\"\n",
        "    # Drive save dir (we'll ensure it exists if Drive is mounted)\n",
        "    drive_save_dir: str = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "\n",
        "    # Training\n",
        "    max_length: int = 64\n",
        "    batch_size: int = 2          # small for VRAM safety\n",
        "    learning_rate: float = 3e-5\n",
        "    num_epochs: int = 6\n",
        "    patience: int = 3\n",
        "    min_delta: float = 0.5       # BLEU improvement threshold to reset patience\n",
        "    use_amp: bool = True\n",
        "\n",
        "    # Data limits\n",
        "    max_train_samples: int = 15000\n",
        "    max_val_samples: int = 1000\n",
        "\n",
        "    # Optim\n",
        "    warmup_steps: int = 100\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # Vision model (SigLIP)\n",
        "    vision_model_name: str = \"google/siglip-base-patch16-224\"\n",
        "\n",
        "    # LoRA\n",
        "    use_lora: bool = True\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.1\n",
        "    lora_targets: List[str] = None\n",
        "\n",
        "    # Language directions\n",
        "    directions: List[Tuple[str, str]] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lora_targets is None:\n",
        "            # Attn projections in mBART encoder+decoder\n",
        "            self.lora_targets = [\"q_proj\", \"v_proj\"]\n",
        "        if self.directions is None:\n",
        "            self.directions = [\n",
        "                (\"fr\", \"en\"),\n",
        "                (\"fr\", \"de\"),\n",
        "            ]\n",
        "\n",
        "config = Config()\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# Global metric (avoid re-loading each epoch)\n",
        "sacrebleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ============================================================== #\n",
        "# OPTIONAL: DRIVE MOUNT + SYMLINK (if you want)\n",
        "# ============================================================== #\n",
        "\n",
        "def mount_and_link_dataset():\n",
        "    \"\"\"\n",
        "    Mounts Google Drive and links /content/multi30k-dataset to your folder.\n",
        "    Safe: no directory scanning, just checks existence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "    except Exception:\n",
        "        print(\"‚ÑπÔ∏è Not running in Colab / no google.colab, skipping mount.\")\n",
        "        return config.data_root\n",
        "\n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    candidate_paths = [\n",
        "        \"/content/drive/MyDrive/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/dataset/multi30k-dataset\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/multi30k-dataset\",\n",
        "    ]\n",
        "\n",
        "    dataset_path = None\n",
        "    for p in candidate_paths:\n",
        "        if os.path.exists(p):\n",
        "            dataset_path = p\n",
        "            print(f\"‚úÖ Found dataset at: {p}\")\n",
        "            break\n",
        "\n",
        "    if dataset_path is None:\n",
        "        print(\"‚ùå Multi30K dataset not found in default locations. Using existing:\", config.data_root)\n",
        "        return config.data_root\n",
        "\n",
        "    if os.path.islink(\"/content/multi30k-dataset\") or os.path.exists(\"/content/multi30k-dataset\"):\n",
        "        os.system(\"rm -rf /content/multi30k-dataset\")\n",
        "\n",
        "    os.symlink(dataset_path, \"/content/multi30k-dataset\")\n",
        "    print(\"üîó Symlink created ‚Üí /content/multi30k-dataset\")\n",
        "    return \"/content/multi30k-dataset\"\n",
        "\n",
        "# ============================================================== #\n",
        "# IMAGE LOADER (NO DIR LISTING)\n",
        "# ============================================================== #\n",
        "\n",
        "def safe_load_image(image_id: str, root: Path) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads one image by ID without listing directories.\n",
        "    Multi30K image IDs in image_splits are usually like \"1234567890.jpg\" or \"1234567890\".\n",
        "    We try: id, id.jpg, id.jpeg, id.png.\n",
        "    \"\"\"\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[: -len(ext)]\n",
        "            break\n",
        "\n",
        "    candidates = [\n",
        "        f\"{base}.jpg\",\n",
        "        f\"{base}.jpeg\",\n",
        "        f\"{base}.png\",\n",
        "        base,\n",
        "    ]\n",
        "\n",
        "    for name in candidates:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # Fallback: dummy gray image\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "# ============================================================== #\n",
        "# LORA HELPER\n",
        "# ============================================================== #\n",
        "\n",
        "def apply_lora_to_mbart(mbart: MBartForConditionalGeneration) -> MBartForConditionalGeneration:\n",
        "    \"\"\"\n",
        "    Wraps mBART with LoRA on attention projections.\n",
        "    \"\"\"\n",
        "    if not config.use_lora:\n",
        "        print(\"‚ÑπÔ∏è LoRA disabled; training full mBART (heavier).\")\n",
        "        return mbart\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    peft_model = get_peft_model(mbart, lora_cfg)\n",
        "    print(\"‚úÖ LoRA applied to mBART (targets:\", config.lora_targets, \")\")\n",
        "    peft_model.print_trainable_parameters()\n",
        "    return peft_model\n",
        "\n",
        "# ============================================================== #\n",
        "# FUSION BLOCK (BETTER THAN PLAIN CONCAT)\n",
        "# ============================================================== #\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Transformer-based fusion over [IMG_TOKEN + TEXT_TOKENS].\n",
        "    Lets the image token attend to text and vice versa.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dim_ff: int = 2048, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed: torch.Tensor, text_embed: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        img_embed: [B,1,d_model]\n",
        "        text_embed: [B,L,d_model]\n",
        "        returns fused: [B,1+L,d_model]\n",
        "        \"\"\"\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)  # [B,1+L,d]\n",
        "        x = self.encoder(x)                            # fuse via self-attention\n",
        "        return x\n",
        "\n",
        "# ============================================================== #\n",
        "# MULTIMODAL MODEL (SIGLIP + MBART + LORA + FUSION)\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # SigLIP vision encoder (vision-only)\n",
        "        print(f\"üîÑ Loading SigLIP vision model: {config.vision_model_name}\")\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "\n",
        "        # Freeze SigLIP to save memory & compute\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # SigLIP vision hidden size\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        print(\"üìê SigLIP vision hidden size:\", vision_dim)\n",
        "\n",
        "        # mBART-50 text model\n",
        "        print(\"üîÑ Loading mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "\n",
        "        # Apply LoRA on mBART\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "        # Shared text embeddings (LoRA-safe)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        # Project SigLIP CLS ‚Üí mBART hidden size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "\n",
        "        # Fusion block\n",
        "        self.fusion = FusionBlock(d_model=self.mbart.config.d_model, nhead=8, dim_ff=2048, dropout=0.1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        # 1) SigLIP image features (CLS token)\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]   # [B, hidden_dim]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)               # [B,1,d_model]\n",
        "\n",
        "        # 2) Text embeddings from mBART shared embedding matrix\n",
        "        text_embed = self.text_emb(input_ids)                      # [B,L,d_model]\n",
        "\n",
        "        # 3) Transformer-based fusion\n",
        "        fused = self.fusion(img_embed, text_embed)                 # [B,1+L,d_model]\n",
        "\n",
        "        # 4) Attention mask (add image token)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        # 5) mBART forward using inputs_embeds\n",
        "        outputs = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, pixel_values, tokenizer):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)\n",
        "        text_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, text_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# TEXT-ONLY MODEL (MBART + LORA)\n",
        "# ============================================================== #\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"üîÑ Loading text-only mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer):\n",
        "        gen_ids = self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ============================================================== #\n",
        "# DATASETS\n",
        "# ============================================================== #\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, image_ids, src, tgt, tokenizer, image_processor, img_root):\n",
        "        self.ids = image_ids\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "        self.img_proc = image_processor\n",
        "        self.img_root = img_root\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        img = safe_load_image(img_id, self.img_root)\n",
        "        pv = self.img_proc(images=img, return_tensors=\"pt\")[\"pixel_values\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"pixel_values\": pv,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "class TextOnlyDataset(Dataset):\n",
        "    def __init__(self, src, tgt, tokenizer):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src[idx]\n",
        "        tgt = self.tgt[idx]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src,\n",
        "            max_length=config.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt,\n",
        "                max_length=config.max_length,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels,\n",
        "            \"target_text\": tgt,\n",
        "        }\n",
        "\n",
        "# ============================================================== #\n",
        "# LOAD SPLIT\n",
        "# ============================================================== #\n",
        "\n",
        "def load_split(root, split, src_lang, tgt_lang, limit):\n",
        "    \"\"\"\n",
        "    Expects:\n",
        "      root/data/task1/raw/{split}/{split}.{lang}\n",
        "      root/data/task1/image_splits/{split}.txt\n",
        "    \"\"\"\n",
        "    root = Path(root)\n",
        "    raw = root / \"data\" / \"task1\" / \"raw\" / split\n",
        "    id_file = root / \"data\" / \"task1\" / \"image_splits\" / f\"{split}.txt\"\n",
        "\n",
        "    src_file = raw / f\"{split}.{src_lang}\"\n",
        "    tgt_file = raw / f\"{split}.{tgt_lang}\"\n",
        "\n",
        "    print(f\"üîé Checking files for {split} {src_lang}‚Üí{tgt_lang}\")\n",
        "    print(\"   \", src_file)\n",
        "    print(\"   \", tgt_file)\n",
        "    print(\"   \", id_file)\n",
        "\n",
        "    if not src_file.exists() or not tgt_file.exists() or not id_file.exists():\n",
        "        print(f\"‚ùå Missing one or more files for {split} ({src_lang}‚Üí{tgt_lang})\")\n",
        "        return [], [], []\n",
        "\n",
        "    ids = [l.strip() for l in open(id_file, encoding=\"utf-8\") if l.strip()]\n",
        "    src = [l.strip() for l in open(src_file, encoding=\"utf-8\") if l.strip()]\n",
        "    tgt = [l.strip() for l in open(tgt_file, encoding=\"utf-8\") if l.strip()]\n",
        "\n",
        "    n = min(len(ids), len(src), len(tgt), limit)\n",
        "    print(f\"‚úÖ Loaded {n} samples ({split}: {src_lang}‚Üí{tgt_lang})\")\n",
        "    return ids[:n], src[:n], tgt[:n]\n",
        "\n",
        "# ============================================================== #\n",
        "# TRAINING + EVAL HELPERS\n",
        "# ============================================================== #\n",
        "\n",
        "def compute_bleu_multimodal(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, pv, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Multimodal BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "def compute_bleu_text(model, loader, tokenizer):\n",
        "    model.eval()\n",
        "    preds, refs = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            tgt = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True) # write the translations in file and\n",
        "\n",
        "            preds.extend(decoded)\n",
        "            refs.extend([[t] for t in tgt])\n",
        "\n",
        "    bleu = sacrebleu_metric.compute(predictions=preds, references=refs)[\"score\"]\n",
        "    print(f\"   üîµ Text-only BLEU: {bleu:.2f}\")\n",
        "    return bleu\n",
        "\n",
        "# ------------------ TRAIN MULTIMODAL ------------------ #\n",
        "\n",
        "def train_multimodal_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds,\n",
        "                           local_save_dir: Path, drive_save_dir: Path | None):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = MultiModalModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [MULTIMODAL] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[MM Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, pv, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, pv, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (multimodal)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Multimodal avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating multimodal on validation...\")\n",
        "        bleu = compute_bleu_multimodal(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = f\"siglip_fusion_lora_{src_lang}_{tgt_lang}_mm_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best MULTIMODAL model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best MULTIMODAL model (drive) ‚Üí {drive_path}\")\n",
        "\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping MULTIMODAL {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished MULTIMODAL training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ------------------ TRAIN TEXT-ONLY ------------------ #\n",
        "\n",
        "def train_text_model(src_lang, tgt_lang, tokenizer, train_ds, val_ds,\n",
        "                     local_save_dir: Path, drive_save_dir: Path | None):\n",
        "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=config.batch_size)\n",
        "\n",
        "    model = TextOnlyModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = len(train_loader) * config.num_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=max(total_steps, 1),\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [TEXT-ONLY] Epoch {epoch}/{config.num_epochs} ‚Äî {src_lang}‚Üí{tgt_lang}\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"[TXT Train {src_lang}->{tgt_lang}]\")\n",
        "        for batch in loop:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"labels\"].to(device)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (text-only)\")\n",
        "            break\n",
        "\n",
        "        avg_loss = total_loss / max(len(train_loader), 1)\n",
        "        print(f\"   üîª Text-only avg train loss: {avg_loss:.4f}\")\n",
        "\n",
        "        print(\"   üîç Evaluating TEXT-ONLY on validation...\")\n",
        "        bleu = compute_bleu_text(model, val_loader, tokenizer)\n",
        "\n",
        "        improved = bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = f\"mbart_lora_{src_lang}_{tgt_lang}_text_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best TEXT-ONLY model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best TEXT-ONLY model (drive) ‚Üí {drive_path}\")\n",
        "\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping TEXT-ONLY {src_lang}‚Üí{tgt_lang} at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished TEXT-ONLY training {src_lang}‚Üí{tgt_lang} | Best BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "# ============================================================== #\n",
        "# MAIN\n",
        "# ============================================================== #\n",
        "\n",
        "def main():\n",
        "    # Optional: remap data_root via Drive symlink\n",
        "    if os.path.exists(\"/content/drive\"):\n",
        "        config.data_root = mount_and_link_dataset()\n",
        "\n",
        "    # Local save dir (Colab)\n",
        "    local_save_dir = Path(config.save_dir)\n",
        "    local_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Drive save dir (if Drive is mounted)\n",
        "    drive_save_dir = None\n",
        "    drive_root = Path(\"/content/drive/MyDrive\")\n",
        "    if drive_root.exists():\n",
        "        drive_save_dir = Path(config.drive_save_dir)\n",
        "        drive_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"üíæ Drive save dir: {drive_save_dir}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Drive not mounted or /content/drive/MyDrive missing; will only save locally.\")\n",
        "\n",
        "    print(\"üîÑ Loading MBart tokenizer & SigLIP processor...\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "        \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "    )\n",
        "    image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "    # Save config (local + drive)\n",
        "    cfg = asdict(config)\n",
        "    cfg_path_local = local_save_dir / \"config_siglip_fusion_lora.json\"\n",
        "    with open(cfg_path_local, \"w\") as f:\n",
        "        json.dump(cfg, f, indent=2)\n",
        "    print(f\"üíæ Config saved (local) at: {cfg_path_local}\")\n",
        "\n",
        "    if drive_save_dir is not None:\n",
        "        cfg_path_drive = drive_save_dir / \"config_siglip_fusion_lora.json\"\n",
        "        with open(cfg_path_drive, \"w\") as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        print(f\"üíæ Config saved (drive) at: {cfg_path_drive}\")\n",
        "\n",
        "    results_multimodal = {}\n",
        "    results_textonly = {}\n",
        "\n",
        "    for src, tgt in config.directions:\n",
        "        print(\"\\n======================================================================\")\n",
        "        print(f\"üèÅ LANGUAGE PAIR: {src.upper()} ‚Üí {tgt.upper()}\")\n",
        "        print(\"======================================================================\")\n",
        "\n",
        "        tokenizer.src_lang = LANG_CODES[src]\n",
        "        tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "        train_ids, train_src, train_tgt = load_split(\n",
        "            config.data_root, \"train\", src, tgt, config.max_train_samples\n",
        "        )\n",
        "        val_ids, val_src, val_tgt = load_split(\n",
        "            config.data_root, \"val\", src, tgt, config.max_val_samples\n",
        "        )\n",
        "\n",
        "        if len(train_ids) == 0:\n",
        "            print(f\"‚ö†Ô∏è Skipping {src}‚Üí{tgt} (no data)\")\n",
        "            continue\n",
        "\n",
        "        img_root = Path(config.data_root) / config.image_dir\n",
        "\n",
        "        # Datasets\n",
        "        train_mm = MultiModalDataset(\n",
        "            train_ids, train_src, train_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "        val_mm = MultiModalDataset(\n",
        "            val_ids, val_src, val_tgt,\n",
        "            tokenizer, image_processor, img_root\n",
        "        )\n",
        "\n",
        "        train_txt = TextOnlyDataset(train_src, train_tgt, tokenizer)\n",
        "        val_txt = TextOnlyDataset(val_src, val_tgt, tokenizer)\n",
        "\n",
        "        # ----- Train MULTIMODAL -----\n",
        "        mm_bleu = train_multimodal_model(\n",
        "            src, tgt, tokenizer, train_mm, val_mm,\n",
        "            local_save_dir=local_save_dir,\n",
        "            drive_save_dir=drive_save_dir,\n",
        "        )\n",
        "        results_multimodal[f\"{src}_{tgt}\"] = mm_bleu\n",
        "\n",
        "        # ----- Train TEXT-ONLY -----\n",
        "        txt_bleu = train_text_model(\n",
        "            src, tgt, tokenizer, train_txt, val_txt,\n",
        "            local_save_dir=local_save_dir,\n",
        "            drive_save_dir=drive_save_dir,\n",
        "        )\n",
        "        results_textonly[f\"{src}_{tgt}\"] = txt_bleu\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (MULTIMODAL):\")\n",
        "    for k, v in results_multimodal.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "    print(\"\\nüìä FINAL BLEU SCORES (TEXT-ONLY):\")\n",
        "    for k, v in results_textonly.items():\n",
        "        print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPuurzEsfc7X",
        "outputId": "4fb4e66d-3d57-492a-bf58-7581f096ba70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "MODEL_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "TEST_DIR : /content/drive/MyDrive/dataset/multi30k-dataset/data/task1/raw/test_2016_flickr\n",
            "SPLIT_FILE: /content/drive/MyDrive/dataset/multi30k-dataset/data/task1/image_splits/test_2016_flickr.txt\n",
            "IMG_ROOT: /content/drive/MyDrive/dataset/multi30k-dataset/flickr30k-images\n",
            "OUT_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions\n",
            "\n",
            "===== Evaluating en ‚Üí de =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_de_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [16:08<00:00,  1.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_en_de.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_en_de.txt\n",
            "BLEU MM  = 40.38\n",
            "BLEU TXT = 38.55\n",
            "\n",
            "===== Evaluating en ‚Üí fr =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_en_fr_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [17:08<00:00,  1.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_en_fr.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_en_fr.txt\n",
            "BLEU MM  = 57.29\n",
            "BLEU TXT = 54.02\n",
            "\n",
            "===== Evaluating de ‚Üí en =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_en_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [14:20<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_de_en.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_de_en.txt\n",
            "BLEU MM  = 46.17\n",
            "BLEU TXT = 45.04\n",
            "\n",
            "===== Evaluating de ‚Üí fr =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_fr_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_de_fr_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [16:55<00:00,  1.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_de_fr.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_de_fr.txt\n",
            "BLEU MM  = 39.51\n",
            "BLEU TXT = 37.01\n",
            "\n",
            "===== Evaluating fr ‚Üí en =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_en_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [14:37<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_fr_en.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_fr_en.txt\n",
            "BLEU MM  = 54.34\n",
            "BLEU TXT = 51.68\n",
            "\n",
            "===== Evaluating fr ‚Üí de =====\n",
            "üìå Using MM: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_de_mm_best.pt\n",
            "üìå Using TXT: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_fr_de_text_best.pt\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [15:58<00:00,  1.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ JSON saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_fr_de.json\n",
            "üíæ TXT saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_predictions/predictions_fr_de.txt\n",
            "BLEU MM  = 33.87\n",
            "BLEU TXT = 32.17\n",
            "Saved BLEU summary.\n",
            "{'en->de': {'mm': 40.38295475881235, 'txt': 38.55443359709484}, 'en->fr': {'mm': 57.29245656795444, 'txt': 54.021818840298465}, 'de->en': {'mm': 46.170166716423005, 'txt': 45.040496619688085}, 'de->fr': {'mm': 39.51088858195834, 'txt': 37.00733032947563}, 'fr->en': {'mm': 54.3362125592121, 'txt': 51.67768653929201}, 'fr->de': {'mm': 33.86687639457443, 'txt': 32.17351310984113}}\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# üåç EVAL: SIGLIP + MBART + LORA (MULTIMODAL vs TEXT-ONLY)\n",
        "#  - Loads models from Drive\n",
        "#  - Uses test_2017_flickr split from Multi30K\n",
        "#  - Saves merged JSON per pair (Option B)\n",
        "#  - Saves readable TXT per pair\n",
        "#  - Saves BLEU\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image, ImageFile\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except:\n",
        "    !pip install -q transformers peft accelerate\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ Mount Drive ------------------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------ Paths ------------------\n",
        "MODEL_DIR = Path(\"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\")\n",
        "TEST_DIR  = Path(\"/content/drive/MyDrive/dataset/multi30k-dataset/data/task1/raw/test_2016_flickr\")\n",
        "SPLIT_FILE = Path(\"/content/drive/MyDrive/dataset/multi30k-dataset/data/task1/image_splits/test_2016_flickr.txt\")\n",
        "IMG_ROOT = Path(\"/content/drive/MyDrive/dataset/multi30k-dataset/flickr30k-images\")\n",
        "OUT_DIR  = MODEL_DIR / \"test2016_predictions\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"TEST_DIR :\", TEST_DIR)\n",
        "print(\"SPLIT_FILE:\", SPLIT_FILE)\n",
        "print(\"IMG_ROOT:\", IMG_ROOT)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "\n",
        "# ------------------ Load saved training config ------------------\n",
        "cfg_path = MODEL_DIR / \"config_siglip_fusion_lora.json\"\n",
        "import types\n",
        "config_dict = json.load(open(cfg_path))\n",
        "config = types.SimpleNamespace(**config_dict)\n",
        "\n",
        "config.directions = [\n",
        "    (\"en\", \"de\"),\n",
        "    (\"en\", \"fr\"),\n",
        "    (\"de\", \"en\"),\n",
        "    (\"de\", \"fr\"),\n",
        "    (\"fr\", \"en\"),\n",
        "    (\"fr\", \"de\"),\n",
        "]\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# ------------------ Safe image loader ------------------\n",
        "def safe_load_image(image_id: str, root: Path):\n",
        "    base = image_id.strip().replace(\"\\n\", \"\")\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[:-len(ext)]\n",
        "            break\n",
        "    for name in [base+\".jpg\", base+\".jpeg\", base+\".png\"]:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                pass\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ------------------ LoRA helper ------------------\n",
        "def apply_lora_to_mbart(mbart):\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    return get_peft_model(mbart, lora_cfg)\n",
        "\n",
        "# ------------------ Fusion block ------------------\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8, dim_feedforward=2048,\n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed, text_embed):\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "# ------------------ MultiModal Model ------------------\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Loading SigLIP:\", config.vision_model_name)\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        print(\"Loading MBART...\")\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel_values, tokenizer):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:,0,:]\n",
        "        img = self.proj(vis).unsqueeze(1)\n",
        "        txt = self.text_emb(input_ids)\n",
        "        fused = self.fusion(img, txt)\n",
        "        fused_mask = torch.cat([torch.ones((input_ids.size(0),1),device=device), mask], dim=1)\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ------------------ Text-only Model ------------------\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tokenizer):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=3,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ------------------ Load test files ------------------\n",
        "def load_test(src, tgt):\n",
        "    ids = open(SPLIT_FILE).read().splitlines()\n",
        "    src_txt = open(TEST_DIR / f\"test_2016_flickr.{src}\").read().splitlines()\n",
        "    tgt_txt = open(TEST_DIR / f\"test_2016_flickr.{tgt}\").read().splitlines()\n",
        "    n = min(len(ids), len(src_txt), len(tgt_txt))\n",
        "    return ids[:n], src_txt[:n], tgt_txt[:n]\n",
        "\n",
        "# ------------------ Evaluate one pair ------------------\n",
        "def evaluate_pair(src, tgt):\n",
        "    print(f\"\\n===== Evaluating {src} ‚Üí {tgt} =====\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ids, src_txt, tgt_txt = load_test(src, tgt)\n",
        "\n",
        "    # Load models\n",
        "    mm_path = MODEL_DIR / f\"siglip_fusion_lora_{src}_{tgt}_mm_best.pt\"\n",
        "    txt_path = MODEL_DIR / f\"mbart_lora_{src}_{tgt}_text_best.pt\"\n",
        "\n",
        "    print(\"üìå Using MM:\", mm_path)\n",
        "    print(\"üìå Using TXT:\", txt_path)\n",
        "\n",
        "    mm = MultiModalModel().to(device)\n",
        "    txt = TextOnlyModel().to(device)\n",
        "\n",
        "    mm.load_state_dict(torch.load(mm_path, map_location=device))\n",
        "    txt.load_state_dict(torch.load(txt_path, map_location=device))\n",
        "\n",
        "    mm.eval()\n",
        "    txt.eval()\n",
        "\n",
        "    results = []\n",
        "    refs = [[t] for t in tgt_txt]\n",
        "    preds_mm, preds_txt = [], []\n",
        "\n",
        "    for i in tqdm(range(len(ids))):\n",
        "        enc = tokenizer(src_txt[i], max_length=config.max_length, truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "        input_ids = enc[\"input_ids\"].to(device)\n",
        "        mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "        img = safe_load_image(ids[i], IMG_ROOT)\n",
        "        pixel = image_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            mm_out = mm.generate(input_ids, mask, pixel, tokenizer)\n",
        "            txt_out = txt.generate(input_ids, mask, tokenizer)\n",
        "\n",
        "        mm_pred = tokenizer.decode(mm_out[0], skip_special_tokens=True)\n",
        "        txt_pred = tokenizer.decode(txt_out[0], skip_special_tokens=True)\n",
        "\n",
        "        preds_mm.append(mm_pred)\n",
        "        preds_txt.append(txt_pred)\n",
        "\n",
        "        results.append({\n",
        "            \"image_id\": ids[i],\n",
        "            \"source\": src_txt[i],\n",
        "            \"target\": tgt_txt[i],\n",
        "            \"prediction_multimodal\": mm_pred,\n",
        "            \"prediction_textonly\": txt_pred\n",
        "        })\n",
        "\n",
        "    # Save merged JSON (Option B)\n",
        "    json_path = OUT_DIR / f\"predictions_{src}_{tgt}.json\"\n",
        "    json.dump(results, open(json_path, \"w\"), indent=2, ensure_ascii=False)\n",
        "    print(\"üíæ JSON saved:\", json_path)\n",
        "\n",
        "    # Save clean TXT\n",
        "    txt_path_out = OUT_DIR / f\"predictions_{src}_{tgt}.txt\"\n",
        "    with open(txt_path_out, \"w\") as f:\n",
        "        for r in results:\n",
        "            f.write(f\"{r['image_id']}\\n\")\n",
        "            f.write(f\"SRC : {r['source']}\\n\")\n",
        "            f.write(f\"TRG : {r['target']}\\n\")\n",
        "            f.write(f\"MM  : {r['prediction_multimodal']}\\n\")\n",
        "            f.write(f\"TXT : {r['prediction_textonly']}\\n\")\n",
        "            f.write(\"-\"*60 + \"\\n\")\n",
        "    print(\"üíæ TXT saved:\", txt_path_out)\n",
        "\n",
        "    # BLEU\n",
        "    sacre = evaluate.load(\"sacrebleu\")\n",
        "    bleu_mm = sacre.compute(predictions=preds_mm, references=refs)[\"score\"]\n",
        "    bleu_txt = sacre.compute(predictions=preds_txt, references=refs)[\"score\"]\n",
        "\n",
        "    print(f\"BLEU MM  = {bleu_mm:.2f}\")\n",
        "    print(f\"BLEU TXT = {bleu_txt:.2f}\")\n",
        "\n",
        "    return bleu_mm, bleu_txt\n",
        "\n",
        "# ------------------ Run all ------------------\n",
        "all_scores = {}\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "for src, tgt in config.directions:\n",
        "    mm_bleu, txt_bleu = evaluate_pair(src, tgt)\n",
        "    all_scores[f\"{src}->{tgt}\"] = {\"mm\": mm_bleu, \"txt\": txt_bleu}\n",
        "\n",
        "json.dump(all_scores, open(OUT_DIR/\"bleu_scores.json\",\"w\"), indent=2)\n",
        "print(\"Saved BLEU summary.\")\n",
        "print(all_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ys5qQPin_s"
      },
      "outputs": [],
      "source": [
        "## Traning the models with all language sets (Unified Model Trining)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqOIeARXr364"
      },
      "outputs": [],
      "source": [
        "# Training again with same setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3nrK10P-N-Y",
        "outputId": "2e893fb3-66f7-4c27-9776-d0dee3f65c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# üåç MULTIMODAL TRANSLATION (SIGLIP + MBART + LORA FUSION)\n",
        "# Optimized for A100\n",
        "# ==============================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Any\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# üöÄ A100 performance boost\n",
        "# --------------------------------------------------------------\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# DEVICE\n",
        "# --------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# METRICS\n",
        "# --------------------------------------------------------------\n",
        "sacrebleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# HF + PEFT imports\n",
        "# --------------------------------------------------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except:\n",
        "    os.system(\"pip install -q transformers peft accelerate evaluate\")\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "        get_linear_schedule_with_warmup,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# CONFIG (Optimized for A100)\n",
        "# --------------------------------------------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Paths\n",
        "    data_root: str = \"/content/multi30k-dataset-local\"\n",
        "    image_dir: str = \"flickr30k-images\"\n",
        "\n",
        "    save_dir: str = \"/content/multimodal_translation_models_siglip_lora_fusion\"\n",
        "    drive_save_dir: str = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "\n",
        "    # Training\n",
        "    max_length: int = 64\n",
        "    batch_size: int = 32\n",
        "    learning_rate: float = 3e-5\n",
        "    num_epochs: int = 6\n",
        "    patience: int = 3\n",
        "    min_delta: float = 0.5\n",
        "    use_amp: bool = True\n",
        "\n",
        "    # Data size per direction\n",
        "    max_train_samples: int = 15000\n",
        "    max_val_samples: int = 200\n",
        "\n",
        "    # Optimization\n",
        "    warmup_steps: int = 100\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # Dataloader (A100 optimized)\n",
        "    num_workers: int = 4\n",
        "    pin_memory: bool = True\n",
        "\n",
        "    # Vision + LoRA\n",
        "    vision_model_name: str = \"google/siglip-base-patch16-224\"\n",
        "    use_lora: bool = True\n",
        "    lora_r: int = 8\n",
        "    lora_alpha: int = 16\n",
        "    lora_dropout: float = 0.1\n",
        "    lora_targets: List[str] = None\n",
        "\n",
        "    directions: List[Tuple[str, str]] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.lora_targets is None:\n",
        "            self.lora_targets = [\"q_proj\", \"v_proj\"]\n",
        "        if self.directions is None:\n",
        "            self.directions = [\n",
        "                (\"en\", \"de\"),\n",
        "                (\"en\", \"fr\"),\n",
        "                (\"de\", \"en\"),\n",
        "                (\"de\", \"fr\"),\n",
        "                (\"fr\", \"en\"),\n",
        "                (\"fr\", \"de\"),\n",
        "            ]\n",
        "\n",
        "config = Config()\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# üöÄ Copy dataset from Google Drive ‚Üí LOCAL SSD (/content)\n",
        "#     HUGE SPEEDUP (20√ó faster images)\n",
        "# --------------------------------------------------------------\n",
        "def copy_dataset_to_local():\n",
        "    drive_dataset = Path(\"/content/drive/MyDrive/dataset/multi30k-dataset\")\n",
        "    local_dataset = Path(\"/content/multi30k-dataset-local\")\n",
        "\n",
        "    if drive_dataset.exists() and not local_dataset.exists():\n",
        "        print(\"üìÇ Copying dataset from Drive ‚Üí /content (one-time)...\")\n",
        "        shutil.copytree(drive_dataset, local_dataset)\n",
        "        print(\"‚úÖ Copy complete.\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è Local dataset already exists or Drive missing.\")\n",
        "\n",
        "    config.data_root = str(local_dataset)\n",
        "    print(\"üìå Using LOCAL dataset:\", config.data_root)\n",
        "    return config.data_root\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwi4cG5N-NuN"
      },
      "outputs": [],
      "source": [
        "# ==============================================================\n",
        "# IMAGE LOADER (NO DIR LISTING, FAST)\n",
        "# ==============================================================\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def safe_load_image(image_id: str, root: Path) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads one image by ID without listing directories.\n",
        "    Multi30K image IDs in image_splits are usually like \"1234567890.jpg\" or \"1234567890\".\n",
        "    We try: id, id.jpg, id.jpeg, id.png.\n",
        "    \"\"\"\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[: -len(ext)]\n",
        "            break\n",
        "\n",
        "    candidates = [\n",
        "        f\"{base}.jpg\",\n",
        "        f\"{base}.jpeg\",\n",
        "        f\"{base}.png\",\n",
        "        base,\n",
        "    ]\n",
        "\n",
        "    for name in candidates:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # Fallback: dummy gray image (should almost never happen)\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# LORA HELPER\n",
        "# ==============================================================\n",
        "\n",
        "def apply_lora_to_mbart(mbart: MBartForConditionalGeneration) -> MBartForConditionalGeneration:\n",
        "    \"\"\"\n",
        "    Wraps mBART with LoRA on attention projections.\n",
        "    \"\"\"\n",
        "    if not config.use_lora:\n",
        "        print(\"‚ÑπÔ∏è LoRA disabled; training full mBART (heavier).\")\n",
        "        return mbart\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    peft_model = get_peft_model(mbart, lora_cfg)\n",
        "    print(\"‚úÖ LoRA applied to mBART (targets:\", config.lora_targets, \")\")\n",
        "    peft_model.print_trainable_parameters()\n",
        "    return peft_model\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# FUSION BLOCK\n",
        "# ==============================================================\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer-based fusion over [IMG_TOKEN + TEXT_TOKENS].\n",
        "    Lets the image token attend to text and vice versa.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dim_ff: int = 2048, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_ff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed: torch.Tensor, text_embed: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        img_embed: [B,1,d_model]\n",
        "        text_embed: [B,L,d_model]\n",
        "        returns fused: [B,1+L,d_model]\n",
        "        \"\"\"\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)  # [B,1+L,d]\n",
        "        x = self.encoder(x)                            # fuse via self-attention\n",
        "        return x\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# MULTIMODAL MODEL (SIGLIP + MBART + LORA + FUSION)\n",
        "# ==============================================================\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # SigLIP vision encoder (vision-only)\n",
        "        print(f\"üîÑ Loading SigLIP vision model: {config.vision_model_name}\")\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "\n",
        "        # Freeze SigLIP to save memory & compute\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # SigLIP vision hidden size\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        print(\"üìê SigLIP vision hidden size:\", vision_dim)\n",
        "\n",
        "        # mBART-50 text model\n",
        "        print(\"üîÑ Loading mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "\n",
        "        # Apply LoRA on mBART\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "        # Shared text embeddings (LoRA-safe)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        # Project SigLIP CLS ‚Üí mBART hidden size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "\n",
        "        # Fusion block\n",
        "        self.fusion = FusionBlock(\n",
        "            d_model=self.mbart.config.d_model,\n",
        "            nhead=8,\n",
        "            dim_ff=2048,\n",
        "            dropout=0.1,\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        # 1) SigLIP image features (CLS token)\n",
        "        with torch.no_grad():  # vision backbone is frozen\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]   # [B, hidden_dim]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)               # [B,1,d_model]\n",
        "\n",
        "        # 2) Text embeddings from mBART shared embedding matrix\n",
        "        text_embed = self.text_emb(input_ids)                      # [B,L,d_model]\n",
        "\n",
        "        # 3) Transformer-based fusion\n",
        "        fused = self.fusion(img_embed, text_embed)                 # [B,1+L,d_model]\n",
        "\n",
        "        # 4) Attention mask (add image token)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=input_ids.device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        # 5) mBART forward using inputs_embeds\n",
        "        outputs = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, pixel_values, tokenizer,\n",
        "                 max_length: int | None = None, num_beams: int = 5):\n",
        "        \"\"\"\n",
        "        Generation wrapper used during BLEU evaluation.\n",
        "        Assumes tokenizer.src_lang / tokenizer.tgt_lang already set.\n",
        "        \"\"\"\n",
        "        if max_length is None:\n",
        "            max_length = config.max_length\n",
        "\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vision_outputs = self.vision(pixel_values=pixel_values)\n",
        "            img_feat = vision_outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(img_feat).unsqueeze(1)\n",
        "        text_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, text_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((batch_size, 1), device=input_ids.device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# TEXT-ONLY MODEL (MBART + LORA)\n",
        "# ==============================================================\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"üîÑ Loading text-only mBART-50 many-to-many...\")\n",
        "        base_mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base_mbart)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer,\n",
        "                 max_length: int | None = None, num_beams: int = 5):\n",
        "        \"\"\"\n",
        "        Generation wrapper used during BLEU evaluation.\n",
        "        Assumes tokenizer.src_lang / tokenizer.tgt_lang already set.\n",
        "        \"\"\"\n",
        "        if max_length is None:\n",
        "            max_length = config.max_length\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            early_stopping=True,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Pdc_CJ0-NqB"
      },
      "outputs": [],
      "source": [
        "# ==============================================================\n",
        "# DATASETS (MIXED MULTILINGUAL)\n",
        "# ==============================================================\n",
        "\n",
        "class MixedMultiModalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Single dataset that contains samples from ALL directions.\n",
        "    Each sample has its own src_lang / tgt_lang.\n",
        "    \"\"\"\n",
        "    def __init__(self, samples: List[Dict[str, Any]],\n",
        "                 tokenizer: MBart50TokenizerFast,\n",
        "                 image_processor: SiglipProcessor,\n",
        "                 img_root: Path):\n",
        "        self.samples = samples\n",
        "        self.tok = tokenizer\n",
        "        self.img_proc = image_processor\n",
        "        self.img_root = img_root\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        img_id = s[\"img_id\"]\n",
        "        src = s[\"src\"]\n",
        "        tgt = s[\"tgt\"]\n",
        "        src_lang = s[\"src_lang\"]\n",
        "        tgt_lang = s[\"tgt_lang\"]\n",
        "\n",
        "        # Set tokenizer languages for this example\n",
        "        self.tok.src_lang = LANG_CODES[src_lang]\n",
        "        self.tok.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "        # Encode source\n",
        "        enc = self.tok(\n",
        "            src, max_length=config.max_length,\n",
        "            padding=\"max_length\", truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Encode target\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt, max_length=config.max_length,\n",
        "                padding=\"max_length\", truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze(0)\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        # FAST‚ÄîLoad image from LOCAL SSD\n",
        "        img = safe_load_image(img_id, self.img_root)\n",
        "        pv = self.img_proc(images=img, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels,\n",
        "            \"pixel_values\": pv,\n",
        "            \"target_text\": tgt,\n",
        "            \"direction\": f\"{src_lang}->{tgt_lang}\",\n",
        "        }\n",
        "\n",
        "\n",
        "class MixedTextOnlyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Text-only dataset containing samples from ALL directions.\n",
        "    \"\"\"\n",
        "    def __init__(self, samples: List[Dict[str, Any]],\n",
        "                 tokenizer: MBart50TokenizerFast):\n",
        "        self.samples = samples\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.samples[idx]\n",
        "        src = s[\"src\"]\n",
        "        tgt = s[\"tgt\"]\n",
        "        src_lang = s[\"src_lang\"]\n",
        "        tgt_lang = s[\"tgt_lang\"]\n",
        "\n",
        "        self.tok.src_lang = LANG_CODES[src_lang]\n",
        "        self.tok.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "        enc = self.tok(\n",
        "            src, max_length=config.max_length,\n",
        "            padding=\"max_length\", truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        with self.tok.as_target_tokenizer():\n",
        "            dec = self.tok(\n",
        "                tgt, max_length=config.max_length,\n",
        "                padding=\"max_length\", truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "        labels = dec[\"input_ids\"].squeeze(0)\n",
        "        labels[labels == self.tok.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels,\n",
        "            \"target_text\": tgt,\n",
        "            \"direction\": f\"{src_lang}->{tgt_lang}\",\n",
        "        }\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# LOAD SPLITTED DATA FROM local dataset\n",
        "# ==============================================================\n",
        "\n",
        "def load_split(root, split, src_lang, tgt_lang, limit):\n",
        "    \"\"\"\n",
        "    Loads data from: root/data/task1/raw/{split}/{split}.{lang}\n",
        "    And image IDs from root/data/task1/image_splits/{split}.txt\n",
        "    \"\"\"\n",
        "    root = Path(root)\n",
        "    raw = root / \"data\" / \"task1\" / \"raw\" / split\n",
        "    id_file = root / \"data\" / \"task1\" / \"image_splits\" / f\"{split}.txt\"\n",
        "\n",
        "    src_file = raw / f\"{split}.{src_lang}\"\n",
        "    tgt_file = raw / f\"{split}.{tgt_lang}\"\n",
        "\n",
        "    print(f\"üîé Checking files for {split} {src_lang}‚Üí{tgt_lang}\")\n",
        "    print(\"   \", src_file)\n",
        "    print(\"   \", tgt_file)\n",
        "    print(\"   \", id_file)\n",
        "\n",
        "    if not src_file.exists() or not tgt_file.exists() or not id_file.exists():\n",
        "        print(f\"‚ùå Missing one or more files for {split} ({src_lang}‚Üí{tgt_lang})\")\n",
        "        return [], [], []\n",
        "\n",
        "    ids = [l.strip() for l in open(id_file, encoding=\"utf-8\") if l.strip()]\n",
        "    src = [l.strip() for l in open(src_file, encoding=\"utf-8\") if l.strip()]\n",
        "    tgt = [l.strip() for l in open(tgt_file, encoding=\"utf-8\") if l.strip()]\n",
        "\n",
        "    n = min(len(ids), len(src), len(tgt), limit)\n",
        "    print(f\"‚úÖ Loaded {n} samples ({split}: {src_lang}‚Üí{tgt_lang})\")\n",
        "    return ids[:n], src[:n], tgt[:n]\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# FAST BLEU FOR MULTIMODAL\n",
        "# ==============================================================\n",
        "\n",
        "def compute_bleu_multimodal(model: nn.Module,\n",
        "                            dataset: Dataset,\n",
        "                            tokenizer: MBart50TokenizerFast):\n",
        "    model.eval()\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    preds_all, refs_all = [], []\n",
        "    preds_by_dir = {}\n",
        "    refs_by_dir = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"[MM BLEU]\", leave=False):\n",
        "            direction = batch[\"direction\"][0]\n",
        "            src_lang, tgt_lang = direction.split(\"->\")\n",
        "\n",
        "            tokenizer.src_lang = LANG_CODES[src_lang]\n",
        "            tokenizer.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            pv = batch[\"pixel_values\"].to(device)\n",
        "            tgt_texts = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, pv, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            pred = decoded[0]\n",
        "            ref = tgt_texts[0]\n",
        "\n",
        "            preds_all.append(pred)\n",
        "            refs_all.append([ref])\n",
        "\n",
        "            preds_by_dir.setdefault(direction, []).append(pred)\n",
        "            refs_by_dir.setdefault(direction, []).append([ref])\n",
        "\n",
        "    overall_bleu = sacrebleu_metric.compute(predictions=preds_all,\n",
        "                                            references=refs_all)[\"score\"]\n",
        "\n",
        "    bleu_by_dir = {}\n",
        "    print(\"\\n   üìä Multimodal BLEU by direction:\")\n",
        "    for direction, preds in preds_by_dir.items():\n",
        "        refs = refs_by_dir[direction]\n",
        "        score = sacrebleu_metric.compute(predictions=preds,\n",
        "                                         references=refs)[\"score\"]\n",
        "        bleu_by_dir[direction] = score\n",
        "        print(f\"     ‚Ä¢ {direction}: {score:.2f}\")\n",
        "\n",
        "    print(f\"   üîµ Multimodal OVERALL BLEU: {overall_bleu:.2f}\")\n",
        "    return overall_bleu, bleu_by_dir\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# FAST BLEU FOR TEXT-ONLY\n",
        "# ==============================================================\n",
        "\n",
        "def compute_bleu_text(model: nn.Module,\n",
        "                      dataset: Dataset,\n",
        "                      tokenizer: MBart50TokenizerFast):\n",
        "    model.eval()\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    preds_all, refs_all = [], []\n",
        "    preds_by_dir = {}\n",
        "    refs_by_dir = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"[TXT BLEU]\", leave=False):\n",
        "            direction = batch[\"direction\"][0]\n",
        "            src_lang, tgt_lang = direction.split(\"->\")\n",
        "\n",
        "            tokenizer.src_lang = LANG_CODES[src_lang]\n",
        "            tokenizer.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            tgt_texts = batch[\"target_text\"]\n",
        "\n",
        "            gen_ids = model.generate(ids, mask, tokenizer)\n",
        "            decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
        "\n",
        "            pred = decoded[0]\n",
        "            ref = tgt_texts[0]\n",
        "\n",
        "            preds_all.append(pred)\n",
        "            refs_all.append([ref])\n",
        "\n",
        "            preds_by_dir.setdefault(direction, []).append(pred)\n",
        "            refs_by_dir.setdefault(direction, []).append([ref])\n",
        "\n",
        "    overall_bleu = sacrebleu_metric.compute(predictions=preds_all,\n",
        "                                            references=refs_all)[\"score\"]\n",
        "\n",
        "    bleu_by_dir = {}\n",
        "    print(\"\\n   üìä Text-only BLEU by direction:\")\n",
        "    for direction, preds in preds_by_dir.items():\n",
        "        refs = refs_by_dir[direction]\n",
        "        score = sacrebleu_metric.compute(predictions=preds,\n",
        "                                         references=refs)[\"score\"]\n",
        "        bleu_by_dir[direction] = score\n",
        "        print(f\"     ‚Ä¢ {direction}: {score:.2f}\")\n",
        "\n",
        "    print(f\"   üîµ Text-only OVERALL BLEU: {overall_bleu:.2f}\")\n",
        "    return overall_bleu, bleu_by_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0nrOeSU-NmM"
      },
      "outputs": [],
      "source": [
        "# ==============================================================\n",
        "# TRAINING LOOPS (A100-OPTIMIZED, BLEU EARLY STOPPING)\n",
        "# ==============================================================\n",
        "\n",
        "def make_train_loader(dataset: Dataset) -> DataLoader:\n",
        "    \"\"\"\n",
        "    Fast DataLoader tuned for A100 on Colab Pro+.\n",
        "    \"\"\"\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4,          # A100 can handle this\n",
        "        pin_memory=True,        # faster host‚ÜíGPU transfers\n",
        "        persistent_workers=True # keeps workers alive between epochs\n",
        "    )\n",
        "\n",
        "\n",
        "def train_multimodal_model(\n",
        "    tokenizer: MBart50TokenizerFast,\n",
        "    train_ds: Dataset,\n",
        "    val_ds: Dataset,\n",
        "    local_save_dir: Path,\n",
        "    drive_save_dir: Path | None,\n",
        "):\n",
        "    # ---------- DataLoader ----------\n",
        "    train_loader = make_train_loader(train_ds)\n",
        "\n",
        "    # ---------- Model / Optim / Sched ----------\n",
        "    model = MultiModalModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = max(len(train_loader) * config.num_epochs, 1)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    # ---------- TRAIN LOOP ----------\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [MULTIMODAL] Epoch {epoch}/{config.num_epochs} ‚Äî ALL 6 DIRECTIONS\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=\"[MM Train MIXED]\", mininterval=1.0)\n",
        "        for batch in loop:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            lbl = batch[\"labels\"].to(device, non_blocking=True)\n",
        "            pv = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, pv, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, pv, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (multimodal)\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"   üîª Multimodal avg TRAIN loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # ---------- VALIDATION BLEU + EARLY STOP ----------\n",
        "        overall_bleu, _ = compute_bleu_multimodal(model, val_ds, tokenizer)\n",
        "\n",
        "        improved = overall_bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = overall_bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = \"siglip_fusion_lora_all6_mm_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best MULTIMODAL model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best MULTIMODAL model (drive) ‚Üí {drive_path}\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"   ‚è∏ No BLEU improvement. patience={no_improve}/{config.patience}\")\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping MULTIMODAL training at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished MULTIMODAL training | Best OVERALL BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n",
        "\n",
        "\n",
        "def train_text_model(\n",
        "    tokenizer: MBart50TokenizerFast,\n",
        "    train_ds: Dataset,\n",
        "    val_ds: Dataset,\n",
        "    local_save_dir: Path,\n",
        "    drive_save_dir: Path | None,\n",
        "):\n",
        "    # ---------- DataLoader ----------\n",
        "    train_loader = make_train_loader(train_ds)\n",
        "\n",
        "    # ---------- Model / Optim / Sched ----------\n",
        "    model = TextOnlyModel().to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = torch.optim.AdamW(params, lr=config.learning_rate)\n",
        "\n",
        "    total_steps = max(len(train_loader) * config.num_epochs, 1)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        opt,\n",
        "        num_warmup_steps=config.warmup_steps,\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if config.use_amp and device.type == \"cuda\" else None\n",
        "\n",
        "    best_bleu = 0.0\n",
        "    no_improve = 0\n",
        "\n",
        "    # ---------- TRAIN LOOP ----------\n",
        "    for epoch in range(1, config.num_epochs + 1):\n",
        "        print(f\"\\nüìç [TEXT-ONLY] Epoch {epoch}/{config.num_epochs} ‚Äî ALL 6 DIRECTIONS\")\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=\"[TXT Train MIXED]\", mininterval=1.0)\n",
        "        for batch in loop:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            lbl = batch[\"labels\"].to(device, non_blocking=True)\n",
        "\n",
        "            try:\n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        out = model(ids, mask, labels=lbl)\n",
        "                        loss = out.loss\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    scaler.step(opt)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    out = model(ids, mask, labels=lbl)\n",
        "                    loss = out.loss\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(params, config.max_grad_norm)\n",
        "                    opt.step()\n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e).lower():\n",
        "                    print(\"‚ö†Ô∏è CUDA OOM on this batch, skipping.\")\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "            scheduler.step()\n",
        "            total_loss += float(loss)\n",
        "            loop.set_postfix(loss=float(loss))\n",
        "\n",
        "        if len(train_loader) == 0:\n",
        "            print(\"‚ö†Ô∏è No batches in train_loader (text-only)\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f\"   üîª Text-only avg TRAIN loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # ---------- VALIDATION BLEU + EARLY STOP ----------\n",
        "        overall_bleu, _ = compute_bleu_text(model, val_ds, tokenizer)\n",
        "\n",
        "        improved = overall_bleu > best_bleu + config.min_delta\n",
        "        if improved:\n",
        "            best_bleu = overall_bleu\n",
        "            no_improve = 0\n",
        "\n",
        "            filename = \"mbart_lora_all6_text_best.pt\"\n",
        "            local_path = local_save_dir / filename\n",
        "            torch.save(model.state_dict(), local_path)\n",
        "            print(f\"   üíæ Saved best TEXT-ONLY model (local) ‚Üí {local_path}\")\n",
        "\n",
        "            if drive_save_dir is not None:\n",
        "                drive_path = drive_save_dir / filename\n",
        "                torch.save(model.state_dict(), drive_path)\n",
        "                print(f\"   üíæ Saved best TEXT-ONLY model (drive) ‚Üí {drive_path}\")\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"   ‚è∏ No BLEU improvement. patience={no_improve}/{config.patience}\")\n",
        "\n",
        "        if no_improve >= config.patience:\n",
        "            print(f\"üõë Early stopping TEXT-ONLY training at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Finished TEXT-ONLY training | Best OVERALL BLEU: {best_bleu:.2f}\")\n",
        "    return best_bleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woi_Adjk0fd0",
        "outputId": "25269c6b-cc5d-4d05-bd4c-6657c75dfca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Info ‚Üí GPU 0: NVIDIA A100-SXM4-80GB (UUID: GPU-dd22b5a6-5b92-1ecb-39d1-b97b837b1dcf)\n",
            "\n",
            "‚úÖ Great! Premium GPU detected.\n",
            "Using device: cuda\n",
            "üìÅ Local dataset found ‚Üí using /content/multi30k-dataset\n",
            "üìå Using dataset: /content/multi30k-dataset\n",
            "üíæ Drive save dir: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "üîÑ Loading MBart tokenizer & SigLIP processor...\n",
            "üíæ Config saved (local) at: /content/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora_all6.json\n",
            "üíæ Config saved (drive) at: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora_all6.json\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: EN ‚Üí DE\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üíde)\n",
            "üîé Checking files for val en‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: en‚Üíde)\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: EN ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: en‚Üífr)\n",
            "üîé Checking files for val en‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: en‚Üífr)\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: DE ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üíen)\n",
            "üîé Checking files for val de‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: de‚Üíen)\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: DE ‚Üí FR\n",
            "======================================================================\n",
            "üîé Checking files for train de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: de‚Üífr)\n",
            "üîé Checking files for val de‚Üífr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: de‚Üífr)\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: FR ‚Üí EN\n",
            "======================================================================\n",
            "üîé Checking files for train fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: fr‚Üíen)\n",
            "üîé Checking files for val fr‚Üíen\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.en\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: fr‚Üíen)\n",
            "\n",
            "======================================================================\n",
            "üèÅ LOADING DATA FOR: FR ‚Üí DE\n",
            "======================================================================\n",
            "üîé Checking files for train fr‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/train/train.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/train.txt\n",
            "‚úÖ Loaded 15000 samples (train: fr‚Üíde)\n",
            "üîé Checking files for val fr‚Üíde\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.fr\n",
            "    /content/multi30k-dataset/data/task1/raw/val/val.de\n",
            "    /content/multi30k-dataset/data/task1/image_splits/val.txt\n",
            "‚úÖ Loaded 200 samples (val: fr‚Üíde)\n",
            "\n",
            "üì¶ TOTAL train samples (ALL directions): 90000\n",
            "üì¶ TOTAL val samples   (ALL directions): 1200\n",
            "üóÇ Building PyTorch datasets...\n",
            "\n",
            "üöÄ Starting MULTIMODAL training...\n",
            "üîÑ Loading SigLIP vision model: google/siglip-base-patch16-224\n",
            "üìê SigLIP vision hidden size: 768\n",
            "üîÑ Loading mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 1/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [51:11<00:00,  1.09s/it, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 1.1299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 39.41\n",
            "     ‚Ä¢ en->fr: 46.90\n",
            "     ‚Ä¢ de->en: 42.53\n",
            "     ‚Ä¢ de->fr: 33.34\n",
            "     ‚Ä¢ fr->en: 47.03\n",
            "     ‚Ä¢ fr->de: 31.17\n",
            "   üîµ Multimodal OVERALL BLEU: 40.46\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 2/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [07:52<00:00,  5.96it/s, loss=0.927]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 1.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.27\n",
            "     ‚Ä¢ en->fr: 48.75\n",
            "     ‚Ä¢ de->en: 43.24\n",
            "     ‚Ä¢ de->fr: 36.53\n",
            "     ‚Ä¢ fr->en: 47.96\n",
            "     ‚Ä¢ fr->de: 32.21\n",
            "   üîµ Multimodal OVERALL BLEU: 41.83\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 3/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [08:00<00:00,  5.85it/s, loss=1.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 0.9613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.75\n",
            "     ‚Ä¢ en->fr: 51.01\n",
            "     ‚Ä¢ de->en: 43.56\n",
            "     ‚Ä¢ de->fr: 37.52\n",
            "     ‚Ä¢ fr->en: 50.36\n",
            "     ‚Ä¢ fr->de: 33.49\n",
            "   üîµ Multimodal OVERALL BLEU: 43.11\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 4/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [07:58<00:00,  5.88it/s, loss=0.746]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 0.9339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.93\n",
            "     ‚Ä¢ en->fr: 51.79\n",
            "     ‚Ä¢ de->en: 43.78\n",
            "     ‚Ä¢ de->fr: 38.27\n",
            "     ‚Ä¢ fr->en: 50.71\n",
            "     ‚Ä¢ fr->de: 33.51\n",
            "   üîµ Multimodal OVERALL BLEU: 43.65\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 5/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [07:58<00:00,  5.88it/s, loss=0.732]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 0.9157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 41.01\n",
            "     ‚Ä¢ en->fr: 52.03\n",
            "     ‚Ä¢ de->en: 44.97\n",
            "     ‚Ä¢ de->fr: 39.68\n",
            "     ‚Ä¢ fr->en: 50.93\n",
            "     ‚Ä¢ fr->de: 33.81\n",
            "   üîµ Multimodal OVERALL BLEU: 44.22\n",
            "   üíæ Saved best MULTIMODAL model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "   üíæ Saved best MULTIMODAL model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_all6_mm_best.pt\n",
            "\n",
            "üìç [MULTIMODAL] Epoch 6/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MM Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [07:57<00:00,  5.89it/s, loss=0.985]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Multimodal avg TRAIN loss: 0.9046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Multimodal BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.48\n",
            "     ‚Ä¢ en->fr: 52.81\n",
            "     ‚Ä¢ de->en: 44.72\n",
            "     ‚Ä¢ de->fr: 39.91\n",
            "     ‚Ä¢ fr->en: 50.28\n",
            "     ‚Ä¢ fr->de: 34.42\n",
            "   üîµ Multimodal OVERALL BLEU: 44.25\n",
            "   ‚è∏ No BLEU improvement. patience=1/3\n",
            "‚úÖ Finished MULTIMODAL training | Best OVERALL BLEU: 44.22\n",
            "\n",
            "üöÄ Starting TEXT-ONLY training...\n",
            "üîÑ Loading text-only mBART-50 many-to-many...\n",
            "‚úÖ LoRA applied to mBART (targets: ['q_proj', 'v_proj'] )\n",
            "trainable params: 1,179,648 || all params: 612,059,136 || trainable%: 0.1927\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 1/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:52<00:00,  7.99it/s, loss=1.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 1.1721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 37.92\n",
            "     ‚Ä¢ en->fr: 45.61\n",
            "     ‚Ä¢ de->en: 41.47\n",
            "     ‚Ä¢ de->fr: 30.87\n",
            "     ‚Ä¢ fr->en: 45.44\n",
            "     ‚Ä¢ fr->de: 28.68\n",
            "   üîµ Text-only OVERALL BLEU: 38.67\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 2/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:58<00:00,  7.85it/s, loss=1.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 1.0541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 38.99\n",
            "     ‚Ä¢ en->fr: 46.60\n",
            "     ‚Ä¢ de->en: 41.84\n",
            "     ‚Ä¢ de->fr: 33.11\n",
            "     ‚Ä¢ fr->en: 46.13\n",
            "     ‚Ä¢ fr->de: 30.38\n",
            "   üîµ Text-only OVERALL BLEU: 39.91\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 3/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:53<00:00,  7.97it/s, loss=1.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 1.0238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 39.09\n",
            "     ‚Ä¢ en->fr: 48.03\n",
            "     ‚Ä¢ de->en: 42.64\n",
            "     ‚Ä¢ de->fr: 34.69\n",
            "     ‚Ä¢ fr->en: 46.58\n",
            "     ‚Ä¢ fr->de: 31.22\n",
            "   üîµ Text-only OVERALL BLEU: 40.80\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 4/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:57<00:00,  7.88it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 1.0067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.03\n",
            "     ‚Ä¢ en->fr: 48.66\n",
            "     ‚Ä¢ de->en: 42.89\n",
            "     ‚Ä¢ de->fr: 34.79\n",
            "     ‚Ä¢ fr->en: 46.91\n",
            "     ‚Ä¢ fr->de: 30.67\n",
            "   üîµ Text-only OVERALL BLEU: 41.06\n",
            "   ‚è∏ No BLEU improvement. patience=1/3\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 5/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:54<00:00,  7.94it/s, loss=1.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 0.9959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 39.74\n",
            "     ‚Ä¢ en->fr: 49.67\n",
            "     ‚Ä¢ de->en: 42.80\n",
            "     ‚Ä¢ de->fr: 35.24\n",
            "     ‚Ä¢ fr->en: 46.75\n",
            "     ‚Ä¢ fr->de: 31.83\n",
            "   üîµ Text-only OVERALL BLEU: 41.45\n",
            "   üíæ Saved best TEXT-ONLY model (local) ‚Üí /content/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "   üíæ Saved best TEXT-ONLY model (drive) ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/mbart_lora_all6_text_best.pt\n",
            "\n",
            "üìç [TEXT-ONLY] Epoch 6/6 ‚Äî ALL 6 DIRECTIONS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[TXT Train MIXED]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2813/2813 [05:59<00:00,  7.82it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   üîª Text-only avg TRAIN loss: 0.9905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   üìä Text-only BLEU by direction:\n",
            "     ‚Ä¢ en->de: 40.10\n",
            "     ‚Ä¢ en->fr: 49.97\n",
            "     ‚Ä¢ de->en: 42.53\n",
            "     ‚Ä¢ de->fr: 35.20\n",
            "     ‚Ä¢ fr->en: 46.97\n",
            "     ‚Ä¢ fr->de: 31.78\n",
            "   üîµ Text-only OVERALL BLEU: 41.55\n",
            "   ‚è∏ No BLEU improvement. patience=1/3\n",
            "‚úÖ Finished TEXT-ONLY training | Best OVERALL BLEU: 41.45\n",
            "\n",
            "üìä FINAL BEST BLEU SCORES\n",
            "   üåà Multimodal (ALL dirs): 44.22\n",
            "   ‚ú® Text-only (ALL dirs):  41.45\n",
            "\n",
            "üéâ Training Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# MAIN (FINAL A100-OPTIMIZED VERSION)\n",
        "# ==============================================================\n",
        "\n",
        "def check_gpu():\n",
        "    \"\"\"Prints GPU details and warns if NOT A100/H100.\"\"\"\n",
        "    import subprocess\n",
        "    try:\n",
        "        gpu_info = subprocess.check_output(\"nvidia-smi -L\", shell=True).decode()\n",
        "        print(\"GPU Info ‚Üí\", gpu_info)\n",
        "        if \"A100\" not in gpu_info and \"H100\" not in gpu_info:\n",
        "            print(\"‚ö†Ô∏è WARNING: You did NOT receive an A100/H100\")\n",
        "            print(\"Training will be 10‚Äì20√ó slower. Restart runtime.\")\n",
        "        else:\n",
        "            print(\"‚úÖ Great! Premium GPU detected.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Could not check GPU:\", e)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # -------------------------------\n",
        "    # GPU Check\n",
        "    # -------------------------------\n",
        "    check_gpu()\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # -------------------------------\n",
        "    # DATASET FIX ‚Üí Use local folder if already present\n",
        "    # -------------------------------\n",
        "    local_dataset = \"/content/multi30k-dataset\"\n",
        "    drive_dataset = \"/content/drive/MyDrive/dataset/multi30k-dataset\"\n",
        "    local_fast_dataset = \"/content/multi30k-dataset-local\"  # Used only if needed\n",
        "\n",
        "    if os.path.exists(local_dataset):\n",
        "        print(\"üìÅ Local dataset found ‚Üí using /content/multi30k-dataset\")\n",
        "        config.data_root = local_dataset\n",
        "\n",
        "    elif os.path.exists(drive_dataset):\n",
        "        # Copy ONCE to high-speed local storage\n",
        "        print(\"üìÇ Copying dataset from Drive ‚Üí /content (fast SSD)...\")\n",
        "        shutil.copytree(drive_dataset, local_fast_dataset)\n",
        "        print(\"‚úÖ Dataset copy complete.\")\n",
        "        config.data_root = local_fast_dataset\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå No dataset found! Please upload multi30k-dataset.\")\n",
        "        return\n",
        "\n",
        "    print(\"üìå Using dataset:\", config.data_root)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Create save dirs\n",
        "    # -------------------------------\n",
        "    local_save_dir = Path(config.save_dir)\n",
        "    local_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    drive_save_dir = None\n",
        "    drive_root = Path(\"/content/drive/MyDrive\")\n",
        "    if drive_root.exists():\n",
        "        drive_save_dir = Path(config.drive_save_dir)\n",
        "        drive_save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"üíæ Drive save dir: {drive_save_dir}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Google Drive missing ‚Äî will only save locally.\")\n",
        "\n",
        "    # -------------------------------\n",
        "    # Load tokenizer & SigLIP processor\n",
        "    # -------------------------------\n",
        "    print(\"üîÑ Loading MBart tokenizer & SigLIP processor...\")\n",
        "    tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "        \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "    )\n",
        "    image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Save config (local + drive)\n",
        "    # -------------------------------\n",
        "    cfg = asdict(config)\n",
        "    cfg_path_local = local_save_dir / \"config_siglip_fusion_lora_all6.json\"\n",
        "    with open(cfg_path_local, \"w\") as f:\n",
        "        json.dump(cfg, f, indent=2)\n",
        "    print(f\"üíæ Config saved (local) at: {cfg_path_local}\")\n",
        "\n",
        "    if drive_save_dir is not None:\n",
        "        cfg_path_drive = drive_save_dir / \"config_siglip_fusion_lora_all6.json\"\n",
        "        with open(cfg_path_drive, \"w\") as f:\n",
        "            json.dump(cfg, f, indent=2)\n",
        "        print(f\"üíæ Config saved (drive) at: {cfg_path_drive}\")\n",
        "\n",
        "    # -------------------------------\n",
        "    # Load ALL 6 directions\n",
        "    # -------------------------------\n",
        "    train_samples = []\n",
        "    val_samples = []\n",
        "\n",
        "    for src, tgt in config.directions:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"üèÅ LOADING DATA FOR: {src.upper()} ‚Üí {tgt.upper()}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        train_ids, train_src, train_tgt = load_split(\n",
        "            config.data_root, \"train\", src, tgt, config.max_train_samples\n",
        "        )\n",
        "        val_ids, val_src, val_tgt = load_split(\n",
        "            config.data_root, \"val\", src, tgt, config.max_val_samples\n",
        "        )\n",
        "\n",
        "        for img_id, s_txt, t_txt in zip(train_ids, train_src, train_tgt):\n",
        "            train_samples.append({\n",
        "                \"img_id\": img_id,\n",
        "                \"src\": s_txt,\n",
        "                \"tgt\": t_txt,\n",
        "                \"src_lang\": src,\n",
        "                \"tgt_lang\": tgt,\n",
        "            })\n",
        "\n",
        "        for img_id, s_txt, t_txt in zip(val_ids, val_src, val_tgt):\n",
        "            val_samples.append({\n",
        "                \"img_id\": img_id,\n",
        "                \"src\": s_txt,\n",
        "                \"tgt\": t_txt,\n",
        "                \"src_lang\": src,\n",
        "                \"tgt_lang\": tgt,\n",
        "            })\n",
        "\n",
        "    print(f\"\\nüì¶ TOTAL train samples (ALL directions): {len(train_samples)}\")\n",
        "    print(f\"üì¶ TOTAL val samples   (ALL directions): {len(val_samples)}\")\n",
        "\n",
        "    if len(train_samples) == 0 or len(val_samples) == 0:\n",
        "        print(\"‚ùå No data loaded. Check dataset path.\")\n",
        "        return\n",
        "\n",
        "    img_root = Path(config.data_root) / config.image_dir\n",
        "\n",
        "    # -------------------------------\n",
        "    # Build datasets\n",
        "    # -------------------------------\n",
        "    print(\"üóÇ Building PyTorch datasets...\")\n",
        "    train_mm = MixedMultiModalDataset(train_samples, tokenizer, image_processor, img_root)\n",
        "    val_mm   = MixedMultiModalDataset(val_samples, tokenizer, image_processor, img_root)\n",
        "\n",
        "    train_txt = MixedTextOnlyDataset(train_samples, tokenizer)\n",
        "    val_txt   = MixedTextOnlyDataset(val_samples, tokenizer)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Train MULTIMODAL\n",
        "    # -------------------------------\n",
        "    print(\"\\nüöÄ Starting MULTIMODAL training...\")\n",
        "    best_mm_bleu = train_multimodal_model(\n",
        "        tokenizer,\n",
        "        train_mm,\n",
        "        val_mm,\n",
        "        local_save_dir,\n",
        "        drive_save_dir,\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Train TEXT-ONLY\n",
        "    # -------------------------------\n",
        "    print(\"\\nüöÄ Starting TEXT-ONLY training...\")\n",
        "    best_txt_bleu = train_text_model(\n",
        "        tokenizer,\n",
        "        train_txt,\n",
        "        val_txt,\n",
        "        local_save_dir,\n",
        "        drive_save_dir,\n",
        "    )\n",
        "\n",
        "    # -------------------------------\n",
        "    # Final summary\n",
        "    # -------------------------------\n",
        "    print(\"\\nüìä FINAL BEST BLEU SCORES\")\n",
        "    print(f\"   üåà Multimodal (ALL dirs): {best_mm_bleu:.2f}\")\n",
        "    print(f\"   ‚ú® Text-only (ALL dirs):  {best_txt_bleu:.2f}\")\n",
        "    print(\"\\nüéâ Training Completed Successfully!\")\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# ENTRY POINT\n",
        "# ==============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCSlGnyukyB3"
      },
      "outputs": [],
      "source": [
        "#testing with test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ee26dc7265f643549fb8a123e11ceee2",
            "dfe09ba34a1f470390dc9752b31088a5",
            "0338ee6cd456495f927ac13794f74580",
            "8f0ca78958e5486a9ada4f1404c377a9",
            "2824da3b61f94192bfc730103b209e40",
            "9a8ce7491a8c4cbbb66f10c0dd6ca25b",
            "ca0b84c612934a81ab1b0e29f5f4c932",
            "3db1f76fbcc746e19f901f04e18c74fd",
            "dd5b46af47304638ba8226944e118f05",
            "da60ebf35b3045f6815bf4a95df4e5b3",
            "adfce349c8914d73aca98214755613d5",
            "d6352956785c41d69c16c2f4c932451b",
            "310915fc47a74b43917113d3df98dc75",
            "d3d37cd5a6354061812131abb1b6c2d8",
            "8639027519094e8ba398d5de4356a43f",
            "b6ecdc71deee4705ae82dacea74f5985",
            "955dec69ef66432bb14862b35bf3d0f9",
            "8aa1abddbcbc47cabc34189d59b75415",
            "93cefe21bb1c4f2ca8a966bd796fa1d0",
            "16738a350272410687e0771b846b8490",
            "4c775586e9934efd8787817a0d0284f7",
            "37fd1d74a3354616a983369b3b391424",
            "40954e5acfbe41fbb684192d3018a42b",
            "13a4f65fe18b4c75bca39eec8e1fd88c",
            "bdca8d2d36ac4560b54dc8fff17caf5c",
            "f004b5964f0d4fb69060a727f94598b7",
            "0a77930da1944443885b3e1c8288d513",
            "a5955e99027d49e7b21f6acc1c4b65bc",
            "0b9503d756554b9aa6138a327f1559c5",
            "cee12272836345acb52fec4441e39d1d",
            "64b059f6e6d84a9bb85bef1f0568a13d",
            "065f61de3fc84e9081c76e3447e97c2d",
            "45f2d438b0db494b838325d88387b30c",
            "0b98358bc84a45fdbeecadc1d9835fe0",
            "4f1c6d0881f84f27b080439464e54e2a",
            "657f706698c349699b2b4197c9f7ea73",
            "bf8ee0e4c19a43d1b03c28b3cb755a5c",
            "ee4e47b7240a495b80d4d985cd9dbfa1",
            "24897badff594c26becefb450bb0dc32",
            "29e4caa6d00e4d108addd6c449f9c180",
            "8ad347bf85ea4398aa6256d9c6fbfffe",
            "b62e2676869e4153af765e5c40aae712",
            "7b1f4c63a5404680b141380abca3707b",
            "f8aded6c8da04a01bee2a7aa6c97cee2",
            "0312c79425fa440cb31155f6cd3b26bf",
            "e809c6e1789e40f4bb2257576ff7a5ed",
            "8102b2725c444e5c8c249e027363e07a",
            "c91acd80da19416eb951e06acd891bb8",
            "d43e6ad0227f4e499dda96d801ac522f",
            "13daf82f4e924cb68591cba902496d28",
            "1e31b7738b0948a2829fe53157595cc0",
            "bb19e49cd2c24ceaa27cb30c8175a92e",
            "1054ccffe4684952840169568a363f66",
            "068cb71c294c4a4abbd9980d9a131917",
            "50747bcc68fc4c16af25d18fd9c010f2",
            "b388787fecb446a1b3629f81b4e70c05",
            "94bc683d342c4b69ac5d6e2769edf607",
            "efc1b581808b43549e7c028dc467ed52",
            "d6e39a968d0b4de2b258faf9ddf56d4c",
            "a7084c843c32443eaae26450df0dc8a3",
            "09648870a3c646c59ae2472f69322668",
            "ebf65ed63cff47fc8cc481cb3464203f",
            "7284e5d040154be5a8213b43a285c7db",
            "3c64a53138cc44298e7b3afd772bbe70",
            "680cccbd456d44488fbabb8352382a5d",
            "96a70470f6af4565a49617f16f5891e8",
            "20a06c4ef4514dfaad4e4cce8104cf36",
            "e21158f1f77b49f6aa3b82602f73f070",
            "f39024eda5b74e7081bed2f8720567a5",
            "32d8ab1d835342acbf2f59df779696e0",
            "f3f61afd46374557963f1106bed46958",
            "2f6aa45ab4664d5e8c3045731198d3b9",
            "550abb6168d840b79ffdd27e9a357396",
            "82c82362271c4a7480fc2d1259db162c",
            "4144ecce8fbc48fbb3efd497436b32ee",
            "0c72415451324987b78db9f98bd3e133",
            "522f4ea7f4ca4f759abda3eff04dd532",
            "88135b50a5ff43498a8927f47cdfbdbb",
            "6b9e73c5b6be4349ac2762fa25695561",
            "dd44f8315b1f415da7f0658e01dd20a8",
            "6fc309fd76824db1b42290f673151d7f",
            "ea872156c37e446da3c118a344455965",
            "2269db8978d44eb09c76be8d15a27f83",
            "6d819e2ea45a43fd9af17995989b8c53",
            "75faf4d3a34341269c46367dc3e93c2b",
            "856b79b158254c44b4a2f2d9c345167e",
            "ed07f7a399f941e09d7ac3f6c82cca6e",
            "a22e20e410ee466b8ba7752fd20056be",
            "0677d631b1564ab796ae4dd1bf4009b3",
            "d95930dd5efd443a862f2ec8ce584335",
            "d292d6a4cf584056a4eb42a1f96e472b",
            "f889d3f9bce84ab0a4be318141ba4762",
            "7e12af3fbfe24cf28d050138aa0ed225",
            "73b82781d977412cbe566d45115395b3",
            "65c428704bdd4951a4ca14a82ebe17d0",
            "265dc91599af4166a31a1e081cca5990",
            "52daf14c1bde43f89f7902cc734be539",
            "93611efa688640cbb9a4df5a2be51019",
            "f56aa9eea7d44048a24bb306eaad6611",
            "c37485ee85d24ee8825af336f818c89f",
            "35dcaf345b6146ff945c1bcbdf3fa3ab",
            "b8b887eb5c224325a73f447a4e358d49",
            "cd1842e4811841d7b776afa14a4714db",
            "c9900f1038064d9980b2dbe81ad1194d",
            "d08037b7740a42679d18d8f09d8e1832",
            "b9048856d0674347aa994e65ccce1dae",
            "701bb12af3574157957985dd03b4a881",
            "78ee347eb1be4cbab3fa0d497bc7b772",
            "7c6ab5fd871d4683a71d84781f82c1df",
            "ddacbcf75ea94b2ca99dec9cf0d2c0f1",
            "6c7805aa83964361b88cbc53e62b5a55",
            "6ce0d9076f9a4b66a9de38a86b08b166",
            "c6e334d4ac3d430eb59aca0325b14e4c",
            "dae375b95ec94b00bf71b3039f55240e",
            "507a70dd03dd48658d1712296c440785",
            "bffabc017f9d4566a9879a7c2654cf14",
            "b1c06764155e48f1b424c922ab95e2a3",
            "73b24f4b6d954a8a83fdef7acb97ebaa",
            "8ed14b43b00e4a728508936f103c642b",
            "fbbcb8289b154591a8508be5fc40370b",
            "3e77c084d6e74521a3c5e31dedd02382",
            "0d89d17fe57f4dcbbcaa0707f7774e50",
            "f7b26ef0f80340d982985bb7cf2b66ce",
            "da50889622124fd191e30537ae832498",
            "c8602548205e44d6af022ebb714e319e",
            "c12c0935de0d421db904da033f8dc474",
            "d9a29fb51778465fbcd3c9e2ba46eaa9",
            "ae5d71fe88fa4687956e06d8413a1228",
            "ea1be469f5f24a128565d470524dca1e",
            "a21db26faa17424fb4ef0783345a82c3",
            "f6def134edcb4847b7c1af28547c302f",
            "5edabb58d2964ae9b526e5a43d93c053",
            "6e4a9dc77658449ab5b440a9036c71fc",
            "6577d6b09d0943b388a5aedea0475d05",
            "665fe121914d4f378b34efe28b0f7bdd",
            "538bc83886a641b9bff536a2f9c83d29",
            "160260d58c944a9d8cab4291c26aecef",
            "de3cb146b16d4d2aa11b0c2cfc36d16f",
            "4821421edf7e4a768b5fe498b897c469",
            "7ae5677c37bc47cc9b77388ad89159d7",
            "dedfea2321644deaafc0f2277230273a",
            "692f77351a3d43c6ba96311e9060505c",
            "40a0568b23ed4f3db596c3fe9323ebca",
            "6bdd9d4deedc411cac127402388bd988",
            "eef52bca57984cafb36101d315d95a3a",
            "8befc8d9ecce4ae28a22e23ae33438a9",
            "cb5c42a1fab44429be7ac104e44ea6c7",
            "b0abc34d3e384060be7a62d738c607a9",
            "1103b8ed1b9f4863a2640050b666ecb2",
            "ceb0199adae946198b8f8158956aa006",
            "ee16cc853cd549af9c2bc275bf6210e1",
            "3415cea7e11b47af8e297c8a3708f923",
            "6561c2f3d276439b9407d953585f9e82",
            "74d8c92b77d9423baf983c8f41cc6926"
          ]
        },
        "id": "m5DX1dZYnaiu",
        "outputId": "f98c8825-e24b-49e3-c1ee-0cd335b4d303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "MODEL_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "TEST_DIR: /content/drive/MyDrive/dataset/multi30k-dataset/data/task1/raw/test_2016_flickr\n",
            "OUT_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee26dc7265f643549fb8a123e11ceee2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6352956785c41d69c16c2f4c932451b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40954e5acfbe41fbb684192d3018a42b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b98358bc84a45fdbeecadc1d9835fe0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0312c79425fa440cb31155f6cd3b26bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b388787fecb446a1b3629f81b4e70c05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/711 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20a06c4ef4514dfaad4e4cce8104cf36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88135b50a5ff43498a8927f47cdfbdbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0677d631b1564ab796ae4dd1bf4009b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================\n",
            "   EVAL: en ‚Üí de\n",
            "============================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c37485ee85d24ee8825af336f818c89f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c7805aa83964361b88cbc53e62b5a55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/813M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d89d17fe57f4dcbbcaa0707f7774e50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4a9dc77658449ab5b440a9036c71fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [29:11<00:00,  1.75s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_de.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_de.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bdd9d4deedc411cac127402388bd988",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU (MM ): 37.74\n",
            "BLEU (TXT): 37.18\n",
            "\n",
            "============================\n",
            "   EVAL: en ‚Üí fr\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [17:41<00:00,  1.06s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_fr.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_fr.txt\n",
            "BLEU (MM ): 50.71\n",
            "BLEU (TXT): 47.77\n",
            "\n",
            "============================\n",
            "   EVAL: de ‚Üí en\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [14:48<00:00,  1.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_en.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_en.txt\n",
            "BLEU (MM ): 44.38\n",
            "BLEU (TXT): 43.73\n",
            "\n",
            "============================\n",
            "   EVAL: de ‚Üí fr\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [17:24<00:00,  1.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_fr.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_fr.txt\n",
            "BLEU (MM ): 37.67\n",
            "BLEU (TXT): 34.54\n",
            "\n",
            "============================\n",
            "   EVAL: fr ‚Üí en\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [15:02<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_en.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_en.txt\n",
            "BLEU (MM ): 52.08\n",
            "BLEU (TXT): 48.28\n",
            "\n",
            "============================\n",
            "   EVAL: fr ‚Üí de\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [16:36<00:00,  1.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_de.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_de.txt\n",
            "BLEU (MM ): 32.82\n",
            "BLEU (TXT): 30.40\n",
            "\n",
            "==============================\n",
            "FINAL BLEU SCORES (ALL 6)\n",
            "==============================\n",
            "{\n",
            "  \"en->de\": {\n",
            "    \"mm\": 37.737588759500774,\n",
            "    \"txt\": 37.184791873340004\n",
            "  },\n",
            "  \"en->fr\": {\n",
            "    \"mm\": 50.71343796951792,\n",
            "    \"txt\": 47.770452343421255\n",
            "  },\n",
            "  \"de->en\": {\n",
            "    \"mm\": 44.381857532012006,\n",
            "    \"txt\": 43.73382710635367\n",
            "  },\n",
            "  \"de->fr\": {\n",
            "    \"mm\": 37.6747671364791,\n",
            "    \"txt\": 34.544032013223585\n",
            "  },\n",
            "  \"fr->en\": {\n",
            "    \"mm\": 52.083662830704604,\n",
            "    \"txt\": 48.28086343390184\n",
            "  },\n",
            "  \"fr->de\": {\n",
            "    \"mm\": 32.82178041558421,\n",
            "    \"txt\": 30.40316470775001\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# üåç FINAL EVALUATION SCRIPT (ALL 6 DIRECTIONS)\n",
        "# - Multimodal vs Text-only\n",
        "# - Loads all6_best models\n",
        "# - Evaluates test_2016_flickr (or 2017)\n",
        "# - Saves BLEU + JSON + TXT\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image, ImageFile\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except:\n",
        "    %pip install -q transformers peft accelerate\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ MOUNT DRIVE ------------------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# üîß PATHS\n",
        "# ================================================================\n",
        "ROOT = Path(\"/content/drive/MyDrive\")\n",
        "\n",
        "MODEL_DIR = ROOT / \"multimodal_translation_models_siglip_lora_fusion\"\n",
        "DATASET = ROOT / \"dataset/multi30k-dataset\"\n",
        "TEST_DIR = DATASET / \"data/task1/raw/test_2016_flickr\"\n",
        "SPLIT_FILE = DATASET / \"data/task1/image_splits/test_2016_flickr.txt\"\n",
        "IMG_ROOT = DATASET / \"flickr30k-images\"\n",
        "\n",
        "OUT_DIR = MODEL_DIR / \"test2016_all6_eval\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"TEST_DIR:\", TEST_DIR)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "\n",
        "# ================================================================\n",
        "# LOAD CONFIG\n",
        "# ================================================================\n",
        "cfg_path = MODEL_DIR / \"config_siglip_fusion_lora_all6.json\"\n",
        "config_dict = json.load(open(cfg_path))\n",
        "import types\n",
        "config = types.SimpleNamespace(**config_dict)\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "DIRECTIONS = [\n",
        "    (\"en\", \"de\"),\n",
        "    (\"en\", \"fr\"),\n",
        "    (\"de\", \"en\"),\n",
        "    (\"de\", \"fr\"),\n",
        "    (\"fr\", \"en\"),\n",
        "    (\"fr\", \"de\"),\n",
        "]\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load_image(image_id: str, root: Path):\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[:-len(ext)]\n",
        "            break\n",
        "    for name in [base+\".jpg\", base+\".jpeg\", base+\".png\"]:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                pass\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# LORA APPLIER\n",
        "# ================================================================\n",
        "def apply_lora_to_mbart(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "# ================================================================\n",
        "# FUSION MODEL\n",
        "# ================================================================\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8, dim_feedforward=2048,\n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        x = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "        for p in self.vision.parameters(): p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        vis_dim = self.vision.config.hidden_size\n",
        "        self.proj = nn.Linear(vis_dim, self.mbart.config.d_model)\n",
        "\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel, tok):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel).last_hidden_state[:,0,:]\n",
        "        img = self.proj(vis).unsqueeze(1)\n",
        "        txt = self.text_emb(input_ids)\n",
        "        fused = self.fusion(img, txt)\n",
        "        fused_mask = torch.cat([torch.ones((input_ids.size(0),1),device=device), mask], dim=1)\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=4,\n",
        "            forced_bos_token_id=tok.lang_code_to_id[tok.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TEXT ONLY MODEL\n",
        "# ================================================================\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tok):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=4,\n",
        "            forced_bos_token_id=tok.lang_code_to_id[tok.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# LOAD TEST SPLIT\n",
        "# ================================================================\n",
        "def load_test(src, tgt):\n",
        "    ids = open(SPLIT_FILE).read().splitlines()\n",
        "    src_txt = open(TEST_DIR / f\"test_2016_flickr.{src}\").read().splitlines()\n",
        "    tgt_txt = open(TEST_DIR / f\"test_2016_flickr.{tgt}\").read().splitlines()\n",
        "    n = min(len(ids), len(src_txt), len(tgt_txt))\n",
        "    return ids[:n], src_txt[:n], tgt_txt[:n]\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATE ONE DIRECTION\n",
        "# ================================================================\n",
        "def evaluate_direction(src, tgt):\n",
        "    print(f\"\\n============================\")\n",
        "    print(f\"   EVAL: {src} ‚Üí {tgt}\")\n",
        "    print(f\"============================\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ids, src_txt, tgt_txt = load_test(src, tgt)\n",
        "    refs = [[t] for t in tgt_txt]\n",
        "\n",
        "    # ---- LOAD MODELS ----\n",
        "    mm = MultiModalModel().to(device)\n",
        "    txt = TextOnlyModel().to(device)\n",
        "\n",
        "    mm.load_state_dict(torch.load(MODEL_DIR/\"siglip_fusion_lora_all6_mm_best.pt\"))\n",
        "    txt.load_state_dict(torch.load(MODEL_DIR/\"mbart_lora_all6_text_best.pt\"))\n",
        "\n",
        "    mm.eval()\n",
        "    txt.eval()\n",
        "\n",
        "    preds_mm, preds_txt = [], []\n",
        "    results = []\n",
        "\n",
        "    for i in tqdm(range(len(ids))):\n",
        "        enc = tokenizer(src_txt[i], max_length=config.max_length,\n",
        "                        padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        ids_t = enc[\"input_ids\"].to(device)\n",
        "        mask_t = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "        img = safe_load_image(ids[i], IMG_ROOT)\n",
        "        pixel = image_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            mm_out = mm.generate(ids_t, mask_t, pixel, tokenizer)\n",
        "            txt_out = txt.generate(ids_t, mask_t, tokenizer)\n",
        "\n",
        "        mm_pred = tokenizer.decode(mm_out[0], skip_special_tokens=True)\n",
        "        txt_pred = tokenizer.decode(txt_out[0], skip_special_tokens=True)\n",
        "\n",
        "        preds_mm.append(mm_pred)\n",
        "        preds_txt.append(txt_pred)\n",
        "\n",
        "        results.append({\n",
        "            \"image_id\": ids[i],\n",
        "            \"source\": src_txt[i],\n",
        "            \"target\": tgt_txt[i],\n",
        "            \"mm\": mm_pred,\n",
        "            \"txt\": txt_pred,\n",
        "        })\n",
        "\n",
        "    # ---- SAVE JSON + TXT ----\n",
        "    json_path = OUT_DIR / f\"pred_{src}_{tgt}.json\"\n",
        "    txt_path = OUT_DIR / f\"pred_{src}_{tgt}.txt\"\n",
        "\n",
        "    json.dump(results, open(json_path,\"w\"), indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(txt_path,\"w\") as f:\n",
        "        for r in results:\n",
        "            f.write(f\"{r['image_id']}\\nSRC: {r['source']}\\nTRG: {r['target']}\\nMM:  {r['mm']}\\nTXT: {r['txt']}\\n\")\n",
        "            f.write(\"-\"*50+\"\\n\")\n",
        "\n",
        "    print(\"Saved:\", json_path)\n",
        "    print(\"Saved:\", txt_path)\n",
        "\n",
        "    sacre = evaluate.load(\"sacrebleu\")\n",
        "    bleu_mm  = sacre.compute(predictions=preds_mm,  references=refs)[\"score\"]\n",
        "    bleu_txt = sacre.compute(predictions=preds_txt, references=refs)[\"score\"]\n",
        "\n",
        "    print(f\"BLEU (MM ): {bleu_mm:.2f}\")\n",
        "    print(f\"BLEU (TXT): {bleu_txt:.2f}\")\n",
        "\n",
        "    return bleu_mm, bleu_txt\n",
        "\n",
        "# ================================================================\n",
        "# MAIN LOOP\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "all_scores = {}\n",
        "\n",
        "for src, tgt in DIRECTIONS:\n",
        "    mm, txt = evaluate_direction(src, tgt)\n",
        "    all_scores[f\"{src}->{tgt}\"] = {\"mm\": mm, \"txt\": txt}\n",
        "\n",
        "json.dump(all_scores, open(OUT_DIR/\"bleu_scores_all6.json\",\"w\"), indent=2)\n",
        "print(\"\\n==============================\")\n",
        "print(\"FINAL BLEU SCORES (ALL 6)\")\n",
        "print(\"==============================\")\n",
        "print(json.dumps(all_scores, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9kNVm-Vkx-y",
        "outputId": "e9f27e9e-17e1-49e4-c55b-f56fac30defe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "MODEL_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\n",
            "TEST_DIR: /content/drive/MyDrive/dataset/multi30k-dataset/data/task1/raw/test_2017_flickr\n",
            "OUT_DIR: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval\n",
            "\n",
            "============================\n",
            "   EVAL: en ‚Üí de\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [15:01<00:00,  1.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_de.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_de.txt\n",
            "BLEU (MM ): 35.61\n",
            "BLEU (TXT): 34.50\n",
            "\n",
            "============================\n",
            "   EVAL: en ‚Üí fr\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [16:19<00:00,  1.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_fr.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_en_fr.txt\n",
            "BLEU (MM ): 47.25\n",
            "BLEU (TXT): 44.47\n",
            "\n",
            "============================\n",
            "   EVAL: de ‚Üí en\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [13:42<00:00,  1.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_en.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_en.txt\n",
            "BLEU (MM ): 44.63\n",
            "BLEU (TXT): 43.97\n",
            "\n",
            "============================\n",
            "   EVAL: de ‚Üí fr\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [15:59<00:00,  1.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_fr.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_de_fr.txt\n",
            "BLEU (MM ): 34.07\n",
            "BLEU (TXT): 31.50\n",
            "\n",
            "============================\n",
            "   EVAL: fr ‚Üí en\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [13:50<00:00,  1.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_en.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_en.txt\n",
            "BLEU (MM ): 49.47\n",
            "BLEU (TXT): 48.20\n",
            "\n",
            "============================\n",
            "   EVAL: fr ‚Üí de\n",
            "============================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [15:17<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_de.json\n",
            "Saved: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/test2016_all6_eval/pred_fr_de.txt\n",
            "BLEU (MM ): 28.40\n",
            "BLEU (TXT): 26.32\n",
            "\n",
            "==============================\n",
            "FINAL BLEU SCORES (ALL 6)\n",
            "==============================\n",
            "{\n",
            "  \"en->de\": {\n",
            "    \"mm\": 35.61013176172457,\n",
            "    \"txt\": 34.500881811447705\n",
            "  },\n",
            "  \"en->fr\": {\n",
            "    \"mm\": 47.24741638028822,\n",
            "    \"txt\": 44.47445665424448\n",
            "  },\n",
            "  \"de->en\": {\n",
            "    \"mm\": 44.63137357351859,\n",
            "    \"txt\": 43.97010664008739\n",
            "  },\n",
            "  \"de->fr\": {\n",
            "    \"mm\": 34.066932741835714,\n",
            "    \"txt\": 31.504558856623845\n",
            "  },\n",
            "  \"fr->en\": {\n",
            "    \"mm\": 49.46800114316033,\n",
            "    \"txt\": 48.197099758381796\n",
            "  },\n",
            "  \"fr->de\": {\n",
            "    \"mm\": 28.40282792786313,\n",
            "    \"txt\": 26.319047874492725\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# üåç FINAL EVALUATION SCRIPT (ALL 6 DIRECTIONS)\n",
        "# - Multimodal vs Text-only\n",
        "# - Loads all6_best models\n",
        "# - Evaluates test_2016_flickr (or 2017)\n",
        "# - Saves BLEU + JSON + TXT\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image, ImageFile\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# ------------------ HF + PEFT imports ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "except:\n",
        "    %pip install -q transformers peft accelerate\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ------------------ MOUNT DRIVE ------------------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# üîß PATHS\n",
        "# ================================================================\n",
        "ROOT = Path(\"/content/drive/MyDrive\")\n",
        "\n",
        "MODEL_DIR = ROOT / \"multimodal_translation_models_siglip_lora_fusion\"\n",
        "DATASET = ROOT / \"dataset/multi30k-dataset\"\n",
        "TEST_DIR = DATASET / \"data/task1/raw/test_2017_flickr\"\n",
        "SPLIT_FILE = DATASET / \"data/task1/image_splits/test_2017_flickr.txt\"\n",
        "IMG_ROOT = DATASET / \"flickr30k-images\"\n",
        "\n",
        "OUT_DIR = MODEL_DIR / \"test2016_all6_eval\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"TEST_DIR:\", TEST_DIR)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "\n",
        "# ================================================================\n",
        "# LOAD CONFIG\n",
        "# ================================================================\n",
        "cfg_path = MODEL_DIR / \"config_siglip_fusion_lora_all6.json\"\n",
        "config_dict = json.load(open(cfg_path))\n",
        "import types\n",
        "config = types.SimpleNamespace(**config_dict)\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "DIRECTIONS = [\n",
        "    (\"en\", \"de\"),\n",
        "    (\"en\", \"fr\"),\n",
        "    (\"de\", \"en\"),\n",
        "    (\"de\", \"fr\"),\n",
        "    (\"fr\", \"en\"),\n",
        "    (\"fr\", \"de\"),\n",
        "]\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load_image(image_id: str, root: Path):\n",
        "    base = image_id.strip()\n",
        "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
        "        if base.endswith(ext):\n",
        "            base = base[:-len(ext)]\n",
        "            break\n",
        "    for name in [base+\".jpg\", base+\".jpeg\", base+\".png\"]:\n",
        "        fp = root / name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                pass\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# LORA APPLIER\n",
        "# ================================================================\n",
        "def apply_lora_to_mbart(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "# ================================================================\n",
        "# FUSION MODEL\n",
        "# ================================================================\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8, dim_feedforward=2048,\n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        x = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(config.vision_model_name)\n",
        "        for p in self.vision.parameters(): p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        vis_dim = self.vision.config.hidden_size\n",
        "        self.proj = nn.Linear(vis_dim, self.mbart.config.d_model)\n",
        "\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel, tok):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel).last_hidden_state[:,0,:]\n",
        "        img = self.proj(vis).unsqueeze(1)\n",
        "        txt = self.text_emb(input_ids)\n",
        "        fused = self.fusion(img, txt)\n",
        "        fused_mask = torch.cat([torch.ones((input_ids.size(0),1),device=device), mask], dim=1)\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=4,\n",
        "            forced_bos_token_id=tok.lang_code_to_id[tok.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TEXT ONLY MODEL\n",
        "# ================================================================\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tok):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            max_length=config.max_length,\n",
        "            num_beams=4,\n",
        "            forced_bos_token_id=tok.lang_code_to_id[tok.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# LOAD TEST SPLIT\n",
        "# ================================================================\n",
        "def load_test(src, tgt):\n",
        "    ids = open(SPLIT_FILE).read().splitlines()\n",
        "    src_txt = open(TEST_DIR / f\"test_2017_flickr.{src}\").read().splitlines()\n",
        "    tgt_txt = open(TEST_DIR / f\"test_2017_flickr.{tgt}\").read().splitlines()\n",
        "    n = min(len(ids), len(src_txt), len(tgt_txt))\n",
        "    return ids[:n], src_txt[:n], tgt_txt[:n]\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATE ONE DIRECTION\n",
        "# ================================================================\n",
        "def evaluate_direction(src, tgt):\n",
        "    print(f\"\\n============================\")\n",
        "    print(f\"   EVAL: {src} ‚Üí {tgt}\")\n",
        "    print(f\"============================\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ids, src_txt, tgt_txt = load_test(src, tgt)\n",
        "    refs = [[t] for t in tgt_txt]\n",
        "\n",
        "    # ---- LOAD MODELS ----\n",
        "    mm = MultiModalModel().to(device)\n",
        "    txt = TextOnlyModel().to(device)\n",
        "\n",
        "    mm.load_state_dict(torch.load(MODEL_DIR/\"siglip_fusion_lora_all6_mm_best.pt\"))\n",
        "    txt.load_state_dict(torch.load(MODEL_DIR/\"mbart_lora_all6_text_best.pt\"))\n",
        "\n",
        "    mm.eval()\n",
        "    txt.eval()\n",
        "\n",
        "    preds_mm, preds_txt = [], []\n",
        "    results = []\n",
        "\n",
        "    for i in tqdm(range(len(ids))):\n",
        "        enc = tokenizer(src_txt[i], max_length=config.max_length,\n",
        "                        padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        ids_t = enc[\"input_ids\"].to(device)\n",
        "        mask_t = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "        img = safe_load_image(ids[i], IMG_ROOT)\n",
        "        pixel = image_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            mm_out = mm.generate(ids_t, mask_t, pixel, tokenizer)\n",
        "            txt_out = txt.generate(ids_t, mask_t, tokenizer)\n",
        "\n",
        "        mm_pred = tokenizer.decode(mm_out[0], skip_special_tokens=True)\n",
        "        txt_pred = tokenizer.decode(txt_out[0], skip_special_tokens=True)\n",
        "\n",
        "        preds_mm.append(mm_pred)\n",
        "        preds_txt.append(txt_pred)\n",
        "\n",
        "        results.append({\n",
        "            \"image_id\": ids[i],\n",
        "            \"source\": src_txt[i],\n",
        "            \"target\": tgt_txt[i],\n",
        "            \"mm\": mm_pred,\n",
        "            \"txt\": txt_pred,\n",
        "        })\n",
        "\n",
        "    # ---- SAVE JSON + TXT ----\n",
        "    json_path = OUT_DIR / f\"pred_{src}_{tgt}.json\"\n",
        "    txt_path = OUT_DIR / f\"pred_{src}_{tgt}.txt\"\n",
        "\n",
        "    json.dump(results, open(json_path,\"w\"), indent=2, ensure_ascii=False)\n",
        "\n",
        "    with open(txt_path,\"w\") as f:\n",
        "        for r in results:\n",
        "            f.write(f\"{r['image_id']}\\nSRC: {r['source']}\\nTRG: {r['target']}\\nMM:  {r['mm']}\\nTXT: {r['txt']}\\n\")\n",
        "            f.write(\"-\"*50+\"\\n\")\n",
        "\n",
        "    print(\"Saved:\", json_path)\n",
        "    print(\"Saved:\", txt_path)\n",
        "\n",
        "    sacre = evaluate.load(\"sacrebleu\")\n",
        "    bleu_mm  = sacre.compute(predictions=preds_mm,  references=refs)[\"score\"]\n",
        "    bleu_txt = sacre.compute(predictions=preds_txt, references=refs)[\"score\"]\n",
        "\n",
        "    print(f\"BLEU (MM ): {bleu_mm:.2f}\")\n",
        "    print(f\"BLEU (TXT): {bleu_txt:.2f}\")\n",
        "\n",
        "    return bleu_mm, bleu_txt\n",
        "\n",
        "# ================================================================\n",
        "# MAIN LOOP\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "image_processor = SiglipProcessor.from_pretrained(config.vision_model_name)\n",
        "\n",
        "all_scores = {}\n",
        "\n",
        "for src, tgt in DIRECTIONS:\n",
        "    mm, txt = evaluate_direction(src, tgt)\n",
        "    all_scores[f\"{src}->{tgt}\"] = {\"mm\": mm, \"txt\": txt}\n",
        "\n",
        "json.dump(all_scores, open(OUT_DIR/\"bleu_scores_all6.json\",\"w\"), indent=2)\n",
        "print(\"\\n==============================\")\n",
        "print(\"FINAL BLEU SCORES (ALL 6)\")\n",
        "print(\"==============================\")\n",
        "print(json.dumps(all_scores, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGxkMoKUlcp6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-KSeBaR77s8"
      },
      "outputs": [],
      "source": [
        "## Testing the models with e-commerce dataset (Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "S_Kj20HW8pOi",
        "outputId": "16bbb4a4-7f33-401c-e9ac-7fae81f382cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "MODEL_DIR: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion\n",
            "Saving eval to: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_eval_en_de\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2156345570.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m# LOAD ONLY VAL SPLIT OF E-COMMERCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mECOMM_TSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"set_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv'"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# üîç EVALUATE PRETRAINED EN‚ÜíDE MODELS ON E-COMMERCE DATA (NO TRAINING)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import types\n",
        "import pandas as pd\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "# ------------------ HF + PEFT ------------------\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast, MBartForConditionalGeneration,\n",
        "    SiglipVisionModel, SiglipProcessor\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# BLEU metric\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ------------------ COLAB DRIVE ------------------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "# PRETRAINED MODEL DIRECTORY (shared drive actual path)\n",
        "MODEL_DIR = Path(\n",
        "    \"/content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/\"\n",
        "    \"multimodal_translation_models_siglip_lora_fusion\"\n",
        ")\n",
        "\n",
        "print(\"MODEL_DIR:\", MODEL_DIR)\n",
        "\n",
        "# E-commerce dataset\n",
        "ECOMM_TSV = (\n",
        "    \"/content/drive/MyDrive/Dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/\"\n",
        "    \"listingtitles_with_matched_images.en-de.tsv\"\n",
        ")\n",
        "ECOMM_IMG_DIR = (\n",
        "    \"/content/drive/MyDrive/Dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        ")\n",
        "\n",
        "# Output directory\n",
        "EVAL_DIR = MODEL_DIR / \"ecomm_eval_en_de\"\n",
        "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Saving eval to:\", EVAL_DIR)\n",
        "\n",
        "# ================================================================\n",
        "# LOAD TRAINING CONFIG (LoRA hyperparams)\n",
        "# ================================================================\n",
        "cfg_path = MODEL_DIR / \"config_siglip_fusion_lora_all6.json\"\n",
        "config_dict = json.load(open(cfg_path))\n",
        "config = types.SimpleNamespace(**config_dict)\n",
        "\n",
        "MAX_LEN = config.max_length\n",
        "vision_model_name = config.vision_model_name\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\"}\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load_image(filename: Any):\n",
        "    filename = str(filename)\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = Path(ECOMM_IMG_DIR) / split / filename\n",
        "        if fp.exists():\n",
        "            try: return Image.open(fp).convert(\"RGB\")\n",
        "            except: pass\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "# ================================================================\n",
        "# LORA / FUSION MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8, dim_feedforward=2048,\n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed, text_embed):\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "def apply_lora_to_mbart(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r, lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(vision_model_name)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(\n",
        "            self.vision.config.hidden_size,\n",
        "            self.mbart.config.d_model\n",
        "        )\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel_values, tokenizer):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_embed = self.proj(vis).unsqueeze(1)\n",
        "        txt_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, txt_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0),1), device=device), mask], dim=1\n",
        "        )\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tokenizer):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# LOAD TOKENIZER + SIGLIP PROCESSOR\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "image_processor = SiglipProcessor.from_pretrained(vision_model_name)\n",
        "\n",
        "tokenizer.src_lang = LANG_CODES[\"en\"]\n",
        "tokenizer.tgt_lang = LANG_CODES[\"de\"]\n",
        "\n",
        "# ================================================================\n",
        "# LOAD ONLY VAL SPLIT OF E-COMMERCE\n",
        "# ================================================================\n",
        "df = pd.read_csv(ECOMM_TSV, sep=\"\\t\")\n",
        "df = df[df[\"set_name\"].str.lower().isin([\"val\", \"validation\", \"valid\"])]\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(\"VAL rows:\", len(df))\n",
        "\n",
        "# ================================================================\n",
        "# LOAD MODELS\n",
        "# ================================================================\n",
        "mm_ckpt  = MODEL_DIR / \"siglip_fusion_lora_en_de_mm_best.pt\"\n",
        "txt_ckpt = MODEL_DIR / \"mbart_lora_en_de_text_best.pt\"\n",
        "\n",
        "print(\"Loading MM:\", mm_ckpt)\n",
        "print(\"Loading TXT:\", txt_ckpt)\n",
        "\n",
        "mm_model = MultiModalModel().to(device)\n",
        "txt_model = TextOnlyModel().to(device)\n",
        "\n",
        "mm_model.load_state_dict(torch.load(mm_ckpt, map_location=device))\n",
        "txt_model.load_state_dict(torch.load(txt_ckpt, map_location=device))\n",
        "\n",
        "mm_model.eval()\n",
        "txt_model.eval()\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "preds_mm = []\n",
        "preds_txt = []\n",
        "refs = []\n",
        "srcs = []\n",
        "imgs = []\n",
        "\n",
        "for i in tqdm(range(len(df)), desc=\"Evaluating EN‚ÜíDE\"):\n",
        "    row = df.iloc[i]\n",
        "    src = str(row[\"source\"])\n",
        "    tgt = str(row[\"target\"])\n",
        "    img_file = row[\"image_file\"]\n",
        "\n",
        "    refs.append(tgt)\n",
        "    srcs.append(src)\n",
        "    imgs.append(img_file)\n",
        "\n",
        "    enc = tokenizer(src, padding=\"max_length\", truncation=True,\n",
        "                    max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # ---- multimodal ----\n",
        "    img = safe_load_image(img_file)\n",
        "    pixel = image_processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "    gen_mm = mm_model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], pixel, tokenizer)\n",
        "    preds_mm.append(tokenizer.decode(gen_mm[0], skip_special_tokens=True))\n",
        "\n",
        "    # ---- text-only ----\n",
        "    gen_txt = txt_model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer)\n",
        "    preds_txt.append(tokenizer.decode(gen_txt[0], skip_special_tokens=True))\n",
        "\n",
        "# ================================================================\n",
        "# COMPUTE BLEU\n",
        "# ================================================================\n",
        "bleu_mm = sacrebleu.compute(predictions=preds_mm,  references=[refs])[\"score\"]\n",
        "bleu_txt = sacrebleu.compute(predictions=preds_txt, references=[refs])[\"score\"]\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"‚≠ê EN ‚Üí DE FINAL BLEU SCORES\")\n",
        "print(\"==============================\")\n",
        "print(f\"Multimodal: {bleu_mm:.2f}\")\n",
        "print(f\"Text-only: {bleu_txt:.2f}\")\n",
        "\n",
        "# ================================================================\n",
        "# SAVE RESULTS\n",
        "# ================================================================\n",
        "pd.DataFrame({\n",
        "    \"src\": srcs,\n",
        "    \"gold\": refs,\n",
        "    \"mm_pred\": preds_mm,\n",
        "    \"txt_pred\": preds_txt,\n",
        "    \"image_file\": imgs\n",
        "}).to_csv(EVAL_DIR / \"preds_en_de.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "with open(EVAL_DIR / \"bleu_en_de.txt\", \"w\") as f:\n",
        "    f.write(f\"MM:  {bleu_mm:.4f}\\nTXT: {bleu_txt:.4f}\\n\")\n",
        "\n",
        "print(\"Saved predictions and BLEU scores in:\", EVAL_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoCSYsC6LZA6"
      },
      "outputs": [],
      "source": [
        "#Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zQ1YtWl410T",
        "outputId": "eba78a95-eb94-46fa-dbca-762b62ab4cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Loading TSV: /content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Translating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [11:33:12<00:00,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Saved updated TSV with French translations at:\n",
            "/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\n",
            "Test file: /content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Multimodal EN+DE+Image ‚Üí FR translation and TSV augmentation\n",
        "# - Robust to broken/missing Google Drive image files\n",
        "# ================================================================\n",
        "\n",
        "!pip install -q openai pillow pandas tqdm\n",
        "\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageFile\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 1. Helper: encode image as base64\n",
        "# ------------------------------------------------\n",
        "def encode_image(image_path: str) -> str:\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 2. Multimodal translator EN+DE+Image ‚Üí FR\n",
        "# ------------------------------------------------\n",
        "def multimodal_translate_to_french(en_caption: str, de_caption: str, image_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses GPT-4o multimodal to produce a single French caption\n",
        "    based on EN + DE + product image.\n",
        "    \"\"\"\n",
        "    img_b64 = encode_image(image_path)\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "You are a multimodal product translation system.\n",
        "\n",
        "You receive:\n",
        "- A product image\n",
        "- An English caption\n",
        "- A German caption\n",
        "\n",
        "Your job:\n",
        "- Understand the image (category, color, materials, brand, attributes)\n",
        "- Merge meaning from both English + German text\n",
        "- Correct mistakes using the image\n",
        "- Output ONLY one final French translation\n",
        "- No explanation, no analysis ‚Äî only the translated French text.\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "English caption: {en_caption}\n",
        "German caption: {de_caption}\n",
        "\"\"\"\n",
        "\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": [{\"type\": \"input_text\", \"text\": system_prompt}]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"input_text\", \"text\": user_prompt},\n",
        "                    {\n",
        "                        \"type\": \"input_image\",\n",
        "                        \"image_url\": f\"data:image/jpeg;base64,{img_b64}\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return resp.output_text.strip()\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 3. Robust image finder (no crashing on I/O errors)\n",
        "# ------------------------------------------------\n",
        "def find_or_placeholder_image(images_root: str, image_filename: str, placeholder_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Try to locate image_filename in train/val/test under images_root.\n",
        "    If anything fails (I/O error, missing file, etc.), return placeholder.\n",
        "    \"\"\"\n",
        "    if image_filename is None or str(image_filename).lower() == \"nan\":\n",
        "        return placeholder_path\n",
        "\n",
        "    image_filename = str(image_filename).strip()\n",
        "    base = Path(images_root)\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        candidate = base / split / image_filename\n",
        "        try:\n",
        "            # Even .is_file() may raise OSError on Google Drive ‚Üí catch it\n",
        "            if candidate.is_file():\n",
        "                return candidate\n",
        "        except OSError:\n",
        "            # Skip problematic path and continue searching\n",
        "            continue\n",
        "\n",
        "    # If we reach here, no usable image was found\n",
        "    return placeholder_path\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 4. Main function: add French column to TSV\n",
        "# ------------------------------------------------\n",
        "def add_french_to_tsv(tsv_path: str, images_root: str, limit: int | None = None) -> str:\n",
        "    \"\"\"\n",
        "    - Loads existing TSV (EN/DE/image)\n",
        "    - Adds 'french' column generated by GPT-4o using EN+DE+Image\n",
        "    - Saves new TSV in same folder with *_with_french.tsv suffix\n",
        "    \"\"\"\n",
        "    tsv_path = Path(tsv_path)\n",
        "    print(\"Loading TSV:\", tsv_path)\n",
        "\n",
        "    df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
        "\n",
        "    if limit is not None:\n",
        "        df = df.head(limit)\n",
        "\n",
        "    # Prepare a persistent placeholder image\n",
        "    placeholder = Path(\"placeholder_grey_224.jpg\")\n",
        "    if not placeholder.exists():\n",
        "        Image.new(\"RGB\", (224, 224), (128, 128, 128)).save(placeholder)\n",
        "\n",
        "    french_captions: list[str] = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Translating\"):\n",
        "        en_caption = str(row[\"source\"])\n",
        "        de_caption = str(row[\"target\"])\n",
        "        image_file = row.get(\"image_file\", None)\n",
        "\n",
        "        # Find or fallback to placeholder (no I/O crash)\n",
        "        img_path = find_or_placeholder_image(images_root, image_file, placeholder)\n",
        "\n",
        "        try:\n",
        "            fr_caption = multimodal_translate_to_french(\n",
        "                en_caption=en_caption,\n",
        "                de_caption=de_caption,\n",
        "                image_path=str(img_path),\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # In case of any model/API error, fall back to EN or DE\n",
        "            print(f\"\\n[WARN] Row {idx} translation failed: {e}\")\n",
        "            fr_caption = en_caption  # or f\"{en_caption} / {de_caption}\"\n",
        "\n",
        "        french_captions.append(fr_caption)\n",
        "\n",
        "    df[\"french\"] = french_captions\n",
        "\n",
        "    out_path = tsv_path.with_name(tsv_path.stem + \"_with_french.tsv\")\n",
        "    df.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Saved updated TSV with French translations at:\")\n",
        "    print(str(out_path))\n",
        "\n",
        "    return str(out_path)\n",
        "\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 5. Run on your paths\n",
        "# ------------------------------------------------\n",
        "TSV = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv\"\n",
        "IMAGES = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        "\n",
        "# Test on a small subset first\n",
        "out_test = add_french_to_tsv(TSV, IMAGES, limit=7500)\n",
        "print(\"Test file:\", out_test)\n",
        "\n",
        "# When happy, run on full dataset (commented out for now)\n",
        "# out_full = add_french_to_tsv(TSV, IMAGES, limit=None)\n",
        "# print(\"Full file:\", out_full)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Igp5H56otK"
      },
      "outputs": [],
      "source": [
        "#French Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi7PtkVu63fR",
        "outputId": "20629c8d-799f-4795-bfec-e2cf4c21f30d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# PART 1 ‚Äî IMPORTS, CONFIG, PATHS, UTILITIES\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ------------------ Install Dependencies if Missing ------------------\n",
        "try:\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "    import evaluate\n",
        "except:\n",
        "    !pip install -q transformers peft accelerate sentencepiece evaluate\n",
        "    from transformers import (\n",
        "        MBart50TokenizerFast,\n",
        "        MBartForConditionalGeneration,\n",
        "        SiglipVisionModel,\n",
        "        SiglipProcessor,\n",
        "    )\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "    import evaluate\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ------------------ MOUNT DRIVE ------------------\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------ IMPORTANT PATHS ------------------\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\")\n",
        "\n",
        "ECOMM_TSV = (\n",
        "    \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/\"\n",
        "    \"listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "IMG_ROOT = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        "\n",
        "OUT_DIR = BASE_DIR / \"ecomm_finetuned\"\n",
        "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "EVAL_DIR = OUT_DIR / \"evals\"\n",
        "EVAL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ------------------ TRAINING CONFIG ------------------\n",
        "BATCH_SIZE  = 8\n",
        "MAX_LEN     = 128\n",
        "LR          = 2e-4\n",
        "EPOCHS      = 6\n",
        "\n",
        "MAX_TRAIN_SAMPLES = 15000\n",
        "MAX_VAL_SAMPLES   = 2000\n",
        "\n",
        "LANG_CODES = {\n",
        "    \"en\": \"en_XX\",\n",
        "    \"de\": \"de_DE\",\n",
        "    \"fr\": \"fr_XX\"\n",
        "}\n",
        "\n",
        "VISION_MODEL_NAME = \"google/siglip-base-patch16-224\"   # Multi30K-compatible\n",
        "\n",
        "# ------------------ SAFE IMAGE LOADING ------------------\n",
        "def safe_load_image(image_name):\n",
        "    if not isinstance(image_name, str):\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    image_name = image_name.strip()\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = Path(IMG_ROOT) / split / image_name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ------------------ LORA CONFIG ------------------\n",
        "def apply_lora(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJjTRgCx_STK"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# PART 2 ‚Äî MODELS, DATASET, COLLATE, TRAINING LOOP\n",
        "# ================================================================\n",
        "\n",
        "# ------------------ FUSION BLOCK ------------------\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        x = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "# ------------------ MULTIMODAL MODEL ------------------\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Loading SigLIP-Base (224)...\")\n",
        "        self.vision = SiglipVisionModel.from_pretrained(VISION_MODEL_NAME)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        print(\"Loading MBART50 + LORA...\")\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, pixel_values, labels):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_emb = self.proj(vis).unsqueeze(1)\n",
        "        txt_emb = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_emb, txt_emb)\n",
        "\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0),1), device=device), attn_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        out = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return out\n",
        "\n",
        "    def generate(self, input_ids, attn_mask, pixel_values, tokenizer):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_emb = self.proj(vis).unsqueeze(1)\n",
        "        txt_emb = self.text_emb(input_ids)\n",
        "        fused = self.fusion(img_emb, txt_emb)\n",
        "\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0),1), device=device), attn_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen\n",
        "\n",
        "# ------------------ TEXT-ONLY MODEL ------------------\n",
        "class TextOnlyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, labels):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attn_mask, tokenizer):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "\n",
        "class EcommDataset(Dataset):\n",
        "    def __init__(self, split, src_lang, tgt_lang, limit=None):\n",
        "        df = pd.read_csv(ECOMM_TSV, sep=\"\\t\")\n",
        "        df[\"set_name\"] = df[\"set_name\"].str.lower()\n",
        "\n",
        "        # Filter rows that have FR data available\n",
        "        df = df[df[\"target\"].notna() & df[\"source\"].notna()]\n",
        "\n",
        "        # If NO VAL exists ‚Üí auto split\n",
        "        has_val = any(df[\"set_name\"].isin([\"val\", \"valid\", \"validation\"]))\n",
        "\n",
        "        if not has_val:\n",
        "            # Auto split 90% train, 10% val\n",
        "            df = df[df[\"set_name\"] == \"train\"].reset_index(drop=True)\n",
        "            n = len(df)\n",
        "            split_index = int(n * 0.9)\n",
        "\n",
        "            train_df = df.iloc[:split_index].reset_index(drop=True)\n",
        "            val_df = df.iloc[split_index:].reset_index(drop=True)\n",
        "\n",
        "            if split == \"train\":\n",
        "                df = train_df\n",
        "            elif split == \"val\":\n",
        "                df = val_df\n",
        "            else:\n",
        "                df = val_df  # fallback: test = val\n",
        "        else:\n",
        "            # Standard behavior\n",
        "            if split == \"train\":\n",
        "                df = df[df[\"set_name\"] == \"train\"]\n",
        "            elif split == \"val\":\n",
        "                df = df[df[\"set_name\"].isin([\"val\", \"valid\", \"validation\"])]\n",
        "            else:\n",
        "                df = df[df[\"set_name\"] == \"test\"]\n",
        "\n",
        "        if limit is not None and len(df) > limit:\n",
        "            df = df.sample(n=limit, random_state=42)\n",
        "\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src = src_lang\n",
        "        self.tgt = tgt_lang\n",
        "\n",
        "        print(f\"[{src_lang}->{tgt_lang}] {split} samples:\", len(self.df))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"target\"])\n",
        "\n",
        "        if self.src == \"en\":\n",
        "            return {\"src\": en, \"tgt\": fr, \"img\": row[\"image_file\"]}\n",
        "        else:\n",
        "            return {\"src\": fr, \"tgt\": en, \"img\": row[\"image_file\"]}\n",
        "\n",
        "\n",
        "# ------------------ COLLATE FUNCTION ------------------\n",
        "def make_collate(tokenizer, processor):\n",
        "    def fn(batch):\n",
        "        src = [b[\"src\"] for b in batch]\n",
        "        tgt = [b[\"tgt\"] for b in batch]\n",
        "\n",
        "        enc_src = tokenizer(\n",
        "            src, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        )\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            enc_tgt = tokenizer(\n",
        "                tgt, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "        labels = enc_tgt[\"input_ids\"]\n",
        "        labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        imgs = [safe_load_image(b[\"img\"]) for b in batch]\n",
        "        pixel_values = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc_src[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": enc_src[\"attention_mask\"].to(device),\n",
        "            \"labels\": labels.to(device),\n",
        "            \"pixel_values\": pixel_values.to(device),\n",
        "        }\n",
        "    return fn\n",
        "\n",
        "# ------------------ TRAINING LOOP ------------------\n",
        "def train_one(src, tgt, model_type, tokenizer, processor):\n",
        "    print(f\"\\n==== TRAINING {model_type.upper()} {src}->{tgt} ====\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    train_ds = EcommDataset(\"train\", src, tgt, MAX_TRAIN_SAMPLES)\n",
        "    val_ds   = EcommDataset(\"val\", src, tgt, MAX_VAL_SAMPLES)\n",
        "\n",
        "    loader = DataLoader(\n",
        "        train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "        collate_fn=make_collate(tokenizer, processor),\n",
        "    )\n",
        "    vloader = DataLoader(\n",
        "        val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "        collate_fn=make_collate(tokenizer, processor),\n",
        "    )\n",
        "\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        ckpt = BASE_DIR / f\"siglip_fusion_lora_{src}_{tgt}_mm_best.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        ckpt = BASE_DIR / f\"mbart_lora_{src}_{tgt}_text_best.pt\"\n",
        "\n",
        "    print(\"Loading pretrained checkpoint:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        [p for p in model.parameters() if p.requires_grad], lr=LR\n",
        "    )\n",
        "\n",
        "    best = float(\"inf\")\n",
        "    out_path = OUT_DIR / f\"ecomm_{src}_{tgt}_{model_type}.pt\"\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        print(f\"\\nEpoch {ep}/{EPOCHS}\")\n",
        "\n",
        "        model.train()\n",
        "        total = 0\n",
        "        for batch in tqdm(loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if model_type == \"mm\":\n",
        "                out = model(\n",
        "                    batch[\"input_ids\"], batch[\"attention_mask\"],\n",
        "                    batch[\"pixel_values\"], batch[\"labels\"]\n",
        "                )\n",
        "            else:\n",
        "                out = model(\n",
        "                    batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
        "                )\n",
        "\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        print(\"Train loss:\", total / len(loader))\n",
        "\n",
        "        # ---- VALIDATION ----\n",
        "        model.eval()\n",
        "        vloss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in vloader:\n",
        "                if model_type == \"mm\":\n",
        "                    out = model(\n",
        "                        batch[\"input_ids\"], batch[\"attention_mask\"],\n",
        "                        batch[\"pixel_values\"], batch[\"labels\"]\n",
        "                    )\n",
        "                else:\n",
        "                    out = model(\n",
        "                        batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
        "                    )\n",
        "                vloss += out.loss.item()\n",
        "\n",
        "        vloss /= len(vloader)\n",
        "        print(\"Val loss:\", vloss)\n",
        "\n",
        "        if vloss < best:\n",
        "            best = vloss\n",
        "            torch.save(model.state_dict(), out_path)\n",
        "            print(\"Saved best:\", out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5tGkSdhN_ctc",
        "outputId": "968cd785-98fe-4aa0-f1cb-4865d706527c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MBart50TokenizerFast' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-424564478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMBart50TokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/mbart-large-50-many-to-many-mmt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiglipProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVISION_MODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MBart50TokenizerFast' is not defined"
          ]
        }
      ],
      "source": [
        "def evaluate_one(src, tgt, model_type, tokenizer, processor, max_test=1000):\n",
        "    print(f\"\\n====== EVALUATING {model_type.upper()} {src}->{tgt} =======\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ds = EcommDataset(\"val\", src, tgt, MAX_VAL_SAMPLES)\n",
        "\n",
        "    # Limit test size\n",
        "    if len(ds) > max_test:\n",
        "        ds = [ds[i] for i in range(max_test)]\n",
        "    print(f\"Eval samples: {len(ds)}\")\n",
        "\n",
        "    # Load model\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_txt.pt\"\n",
        "\n",
        "    print(\"Loading:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for sample in tqdm(ds):\n",
        "        src_txt = sample[\"src\"]\n",
        "        tgt_txt = sample[\"tgt\"]\n",
        "        references.append(tgt_txt)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            src_txt, padding=\"max_length\", truncation=True,\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        if model_type == \"mm\":\n",
        "            img = safe_load_image(sample[\"img\"])\n",
        "            pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "            gen = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], pixel, tokenizer)\n",
        "        else:\n",
        "            gen = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer)\n",
        "\n",
        "        pred = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # üî• FIXED BLEU CALCULATION ‚Äî no nested list\n",
        "    bleu = sacrebleu.compute(predictions=predictions, references=references)[\"score\"]\n",
        "\n",
        "    print(\"BLEU:\", bleu)\n",
        "    return bleu\n",
        "# ================================================================\n",
        "# RUN TRAINING + EVALUATION\n",
        "# ================================================================\n",
        "\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "processor = SiglipProcessor.from_pretrained(VISION_MODEL_NAME)\n",
        "\n",
        "# --------------- TRAIN ALL PAIRS ---------------\n",
        "# EN ‚Üî DE\n",
        "#train_one(\"en\", \"de\", \"mm\", tokenizer, processor)\n",
        "#train_one(\"en\", \"de\", \"txt\", tokenizer, processor)\n",
        "#train_one(\"de\", \"en\", \"mm\", tokenizer, processor)\n",
        "#train_one(\"de\", \"en\", \"txt\", tokenizer, processor)\n",
        "\n",
        "# EN ‚Üî FR\n",
        "train_one(\"en\", \"fr\", \"mm\", tokenizer, processor)\n",
        "train_one(\"en\", \"fr\", \"txt\", tokenizer, processor)\n",
        "train_one(\"fr\", \"en\", \"mm\", tokenizer, processor)\n",
        "train_one(\"fr\", \"en\", \"txt\", tokenizer, processor)\n",
        "\n",
        "# --------------- EVALUATE ALL PAIRS ---------------\n",
        "#evaluate_one(\"en\", \"de\", \"mm\", tokenizer, processor)\n",
        "#evaluate_one(\"en\", \"de\", \"txt\", tokenizer, processor)\n",
        "#evaluate_one(\"de\", \"en\", \"mm\", tokenizer, processor)\n",
        "#evaluate_one(\"de\", \"en\", \"txt\", tokenizer, processor)\n",
        "\n",
        "#evaluate_one(\"en\", \"fr\", \"mm\", tokenizer, processor)\n",
        "#evaluate_one(\"en\", \"fr\", \"txt\", tokenizer, processor)\n",
        "#evaluate_one(\"fr\", \"en\", \"mm\", tokenizer, processor)\n",
        "#evaluate_one(\"fr\", \"en\", \"txt\", tokenizer, processor)\n",
        "\n",
        "print(\"\\nüéâ ALL TRAINING + EVALUATION COMPLETED SUCCESSFULLY!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTgsAx9c_qFY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7xIIifi4r4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing"
      ],
      "metadata": {
        "id": "XLkks-IB4rvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "print(\"\\n\".join(os.listdir(folder)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3jJ8YxN4zQc",
        "outputId": "4fae81ee-ca94-4cce-eb95-11c2e2e40223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siglip_fusion_lora_en_de_mm_best.pt\n",
            "mbart_lora_en_de_text_best.pt\n",
            "siglip_fusion_lora_en_fr_mm_best.pt\n",
            "mbart_lora_en_fr_text_best.pt\n",
            "siglip_fusion_lora_de_en_mm_best.pt\n",
            "mbart_lora_de_en_text_best.pt\n",
            "siglip_fusion_lora_de_fr_mm_best.pt\n",
            "mbart_lora_de_fr_text_best.pt\n",
            "config_siglip_fusion_lora.json\n",
            "siglip_fusion_lora_fr_en_mm_best.pt\n",
            "mbart_lora_fr_en_text_best.pt\n",
            "siglip_fusion_lora_fr_de_mm_best.pt\n",
            "mbart_lora_fr_de_text_best.pt\n",
            "test2016_predictions\n",
            "test2017_predictions\n",
            "config_siglip_fusion_lora_all6.json\n",
            "ecomm_finetuned\n",
            "siglip_fusion_lora_all6_mm_best.pt\n",
            "mbart_lora_all6_text_best.pt\n",
            "test2016_all6_eval\n",
            "ecomm_eval_en_de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL TRAINING + EVALUATION SCRIPT (SIGLIP FUSION + LORA)\n",
        "# Supports: en‚Üíde, de‚Üíen, en‚Üífr, fr‚Üíen\n",
        "# Dataset columns:\n",
        "# ['project_name','set_name','image_id','image_file','source','target','french']\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "from transformers import SiglipVisionModel, SiglipProcessor\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# BLEU\n",
        "# ================================================================\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "MODEL_DIR = Path(BASE)\n",
        "OUT_DIR = MODEL_DIR / \"ecomm_finetuned\"\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TSV_FILE = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        "IMG_DIR = Path(\"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\")\n",
        "\n",
        "# Pretrained base checkpoints\n",
        "PRETRAINED = {\n",
        "    \"en_de\": MODEL_DIR / \"siglip_fusion_lora_en_de_mm_best.pt\",\n",
        "    \"de_en\": MODEL_DIR / \"siglip_fusion_lora_de_en_mm_best.pt\",\n",
        "    \"en_fr\": MODEL_DIR / \"siglip_fusion_lora_en_fr_mm_best.pt\",\n",
        "    \"fr_en\": MODEL_DIR / \"siglip_fusion_lora_fr_en_mm_best.pt\"\n",
        "}\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# ================================================================\n",
        "# HYPERPARAMETERS\n",
        "# ================================================================\n",
        "MAX_LEN = 64\n",
        "BATCH = 2\n",
        "LR = 2e-4\n",
        "EPOCHS = 8     # adjust if needed\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOAD\n",
        "# ================================================================\n",
        "def safe_load(img_name):\n",
        "    if not isinstance(img_name, str) or img_name.strip() == \"\":\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    img_name = img_name.strip()\n",
        "\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        fp = IMG_DIR / split / img_name\n",
        "        try:\n",
        "            if fp.exists():\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "        except:\n",
        "            return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# DATASET\n",
        "# ================================================================\n",
        "class ECommerceDataset(Dataset):\n",
        "    def __init__(self, df, src_lang, tgt_lang):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src = src_lang\n",
        "        self.tgt = tgt_lang\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"]).strip()\n",
        "        de = str(row[\"target\"]).strip()\n",
        "        fr = str(row[\"french\"]).strip()\n",
        "        img = row[\"image_file\"]\n",
        "\n",
        "        # SOURCE selection\n",
        "        if self.src == \"en\":   src_text = en\n",
        "        elif self.src == \"de\": src_text = de\n",
        "        else:                  src_text = fr\n",
        "\n",
        "        # TARGET selection\n",
        "        if self.tgt == \"en\":   tgt_text = en\n",
        "        elif self.tgt == \"de\": tgt_text = de\n",
        "        else:                  tgt_text = fr\n",
        "\n",
        "        # Clean None / empty\n",
        "        if src_text is None or src_text == \"nan\": src_text = \"\"\n",
        "        if tgt_text is None or tgt_text == \"nan\": tgt_text = \"\"\n",
        "\n",
        "        return {\"src\": src_text, \"tgt\": tgt_text, \"img\": img}\n",
        "\n",
        "# ================================================================\n",
        "# CREATE TRAIN/TEST SPLITS\n",
        "# ================================================================\n",
        "def load_split(src, tgt, total_samples):\n",
        "\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "\n",
        "    df = df[df[\"set_name\"].str.lower().isin([\"train\",\"test\"])]\n",
        "    df = df[[\"source\",\"target\",\"french\",\"image_file\",\"set_name\"]]\n",
        "\n",
        "    # Remove bad text rows\n",
        "    df = df.dropna(subset=[\"source\",\"target\",\"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # EN‚ÜîDE = 15000 max ‚Üí your dataset = 7500 ‚Üí we use all\n",
        "    train_df = df[df[\"set_name\"]==\"train\"]\n",
        "    test_df  = df[df[\"set_name\"]==\"test\"]\n",
        "\n",
        "    # Train split limit\n",
        "    train_df = train_df.sample(min(len(train_df), int(total_samples*0.8)), random_state=42)\n",
        "    test_df = test_df.sample(min(len(test_df), int(total_samples*0.2)), random_state=42)\n",
        "\n",
        "    print(f\"Train={len(train_df)} Test={len(test_df)} for {src}->{tgt}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# ================================================================\n",
        "# SIGLIP FUSION MODEL (LoRA)\n",
        "# ================================================================\n",
        "def apply_lora(m):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\",\"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(m, cfg)\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8,\n",
        "            dim_feedforward=2048, dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.enc = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        return self.enc(torch.cat([img_emb, txt_emb], dim=1))\n",
        "\n",
        "class SiglipFusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "        for p in self.vision.parameters(): p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.txt_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def forward(self, ids, mask, pixel, labels):\n",
        "        with torch.no_grad():\n",
        "            v = self.vision(pixel).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_e = self.proj(v).unsqueeze(1)\n",
        "        txt_e = self.txt_emb(ids)\n",
        "\n",
        "        fused = self.fusion(img_e, txt_e)\n",
        "        fused_mask = torch.cat([torch.ones((ids.size(0),1), device=device), mask], dim=1)\n",
        "\n",
        "        return self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TOKENIZER + PROCESSOR\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "\n",
        "# ================================================================\n",
        "# COLLATE\n",
        "# ================================================================\n",
        "def collate(batch):\n",
        "    src = [b[\"src\"] for b in batch]\n",
        "    tgt = [b[\"tgt\"] for b in batch]\n",
        "    imgs = [safe_load(b[\"img\"]) for b in batch]\n",
        "\n",
        "    # Tokenize source\n",
        "    enc_src = tokenizer(\n",
        "        src, padding=\"max_length\", truncation=True,\n",
        "        max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Tokenize target\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        enc_tgt = tokenizer(\n",
        "            tgt, padding=\"max_length\", truncation=True,\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    labels = enc_tgt[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    pixel = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": enc_src[\"input_ids\"].to(device),\n",
        "        \"mask\": enc_src[\"attention_mask\"].to(device),\n",
        "        \"labels\": labels.to(device),\n",
        "        \"pixel\": pixel.to(device)\n",
        "    }\n",
        "\n",
        "# ================================================================\n",
        "# TRAINING LOOP\n",
        "# ================================================================\n",
        "def train_direction(src, tgt, key, total_samples):\n",
        "\n",
        "    print(\"\\n===================================================\")\n",
        "    print(f\"üî• TRAINING {src} ‚Üí {tgt} on {total_samples} samples\")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    train_df, test_df = load_split(src, tgt, total_samples)\n",
        "\n",
        "    train_loader = DataLoader(ECommerceDataset(train_df, src, tgt),\n",
        "                              batch_size=BATCH, shuffle=True, collate_fn=collate)\n",
        "    test_ds = ECommerceDataset(test_df, src, tgt)\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    print(\"Loading pretrained checkpoint:\", PRETRAINED[key])\n",
        "    model.load_state_dict(torch.load(PRETRAINED[key], map_location=device), strict=False)\n",
        "\n",
        "    # Freeze all except LoRA weights\n",
        "    for n, p in model.named_parameters():\n",
        "        p.requires_grad = (\"lora\" in n)\n",
        "\n",
        "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "    best = 999999\n",
        "    save_path = OUT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optim.zero_grad()\n",
        "            out = model(batch[\"ids\"], batch[\"mask\"], batch[\"pixel\"], batch[\"labels\"])\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        ep_loss = total / len(train_loader)\n",
        "        print(f\"Epoch {ep} Loss = {ep_loss:.4f}\")\n",
        "\n",
        "        if ep_loss < best:\n",
        "            best = ep_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"Saved best model:\", save_path)\n",
        "\n",
        "    return test_ds\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION\n",
        "# ================================================================\n",
        "def evaluate_direction(src, tgt, test_ds):\n",
        "\n",
        "    print(\"\\n====== Evaluating\", src, \"‚Üí\", tgt, \"======\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    print(\"Loading finetuned model:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs = [], []\n",
        "\n",
        "    for sample in tqdm(test_ds):\n",
        "        src_text = sample[\"src\"]\n",
        "        tgt_text = sample[\"tgt\"]\n",
        "        refs.append(tgt_text)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            src_text, truncation=True, padding=\"max_length\",\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        img = safe_load(sample[\"img\"])\n",
        "        pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            v = model.vision(pixel).last_hidden_state[:,0,:]\n",
        "            img_e = model.proj(v).unsqueeze(1)\n",
        "            txt_e = model.txt_emb(enc[\"input_ids\"])\n",
        "            fused = model.fusion(img_e, txt_e)\n",
        "            fused_mask = torch.cat([torch.ones((1,1), device=device), enc[\"attention_mask\"]], dim=1)\n",
        "\n",
        "            gen = model.mbart.generate(\n",
        "                inputs_embeds=fused,\n",
        "                attention_mask=fused_mask,\n",
        "                num_beams=5,\n",
        "                max_length=MAX_LEN,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=[[r] for r in refs])[\"score\"]\n",
        "    print(\"BLEU:\", bleu)\n",
        "    return bleu\n",
        "\n",
        "# ================================================================\n",
        "# RUN TRAINING FOR ALL 4 DIRECTIONS\n",
        "# ================================================================\n",
        "# Dataset size = 7500 ‚Üí use full\n",
        "SAMPLES = 7500\n",
        "\n",
        "test_en_de = train_direction(\"en\", \"de\", \"en_de\", SAMPLES)\n",
        "#evaluate_direction(\"en\", \"de\", test_en_de)\n",
        "\n",
        "test_de_en = train_direction(\"de\", \"en\", \"de_en\", SAMPLES)\n",
        "#evaluate_direction(\"de\", \"en\", test_de_en)\n",
        "\n",
        "test_en_fr = train_direction(\"en\", \"fr\", \"en_fr\", SAMPLES)\n",
        "#evaluate_direction(\"en\", \"fr\", test_en_fr)\n",
        "\n",
        "test_fr_en = train_direction(\"fr\", \"en\", \"fr_en\", SAMPLES)\n",
        "#evaluate_direction(\"fr\", \"en\", test_fr_en)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a02f91460bc4267b21a914cc7ecf00d",
            "e466432262d440de82879755ad34b98f",
            "f5c15b3c40824fde8c3b56ca3098ba96",
            "049f3d16e66c4af9b9f0f93c1c6019a0",
            "e02ab3f4794245648c01d9df75d70474",
            "15b5588bf3f141a9b9b7b15a4248c3ab",
            "dbc6cea6d70c40e497637470794ad3e5",
            "b78e8cf398a74c65bce15d3e1360fb46",
            "ad3559c3ccdb4c4c96571b25f161972b",
            "ae79e08811554190ad60ba7bc0808daa",
            "a6cb42d18fd442a3ae505784df944176",
            "dcecfe2635f44bf2b981b02ee8eb4d5b",
            "26a14b72f03d4526b8b023895752254a",
            "759c9b470cac48b482fc4320084d0f9a",
            "0a793ed73444428da5332dc0f41351ba",
            "243785bb061f42a5b2cc9c9bfe81b881",
            "0e03626aa4744303803604d6e347af77",
            "ddba7818be1a4d9681731d15678588d5",
            "9c59f393a68c4cdd9cd2a999dcdaa64d",
            "b98884906cf243548f9b8aca8541271c",
            "83884b28ef3e409187c6c749ac1b9881",
            "3b4c6f7ca4074bdb9afe1b72f7ba9176",
            "aa2d439f4ffd461982ee831189fb0293",
            "f30d5bfa19f04139b0c8b9d2d9f845a3",
            "d01f2ca1996e41c896bf0c1f5e3d0a35",
            "74ad6696d36147b39c842e22794b8f77",
            "90bc0d10ebdd409a99bce17169725c12",
            "7a7a36794b1e4bfba0e1ec3f67ce5ad9",
            "5239a4ee8aec467d87956a81d4f647ee",
            "659d53ebac874f0cbc525af12d293361",
            "f671ec55c9334d1eaa26dedfcae5b94f",
            "d8ae4f234d864f1cb6db8624ef9469ee",
            "6fb266a34b2047b89196d1f26f803ec1",
            "22b0a7a93b404aaab41582ac569603d0",
            "e2aba43f29c1474dbea6f066f42a6094",
            "d5aa57b643fe47e9943b8a665bcf5f71",
            "f65a54e7a0724d9c90d22ed396eb5330",
            "793ecdb57e7f47c9ae57e14d58578a52",
            "51eeefcf7ef74e389b2b4f58099ec382",
            "faf895167c534ee0826a1588bf324869",
            "520d6bdf6ce24dd0b752982320a012b8",
            "df288abf838b48dcae664e8a95760dda",
            "00d202af25354b93a056de4ccea93ce7",
            "45cc92ab16b14c21ba02e80454260dff",
            "d8540e67cf2f48f99e218653b66f8007",
            "a1a1aafd9599420893801cc27c027265",
            "871940531f43497da902f168149f6a0d",
            "f41d98c88f0b4f26a9827d6045557860",
            "570793b845724a1189d2ca1c491f9e97",
            "d62058c7fc6a43dfb69bf203fde91259",
            "fe84ce7a74bd44698a4318db61f5c69c",
            "b84aa4ea2ee2428da066e67215ee813a",
            "0a3b5fa90a0849c881a52bb4cfed432c",
            "31b63f0d3be24846b72c8c2d4aba9d4e",
            "ed73a1c2ca284d7891c1566925ead08d",
            "7a81efcc3c084d1a8c66c9fd40e1dc21",
            "9ca2c832ec38401fb56c88467f7b6e23",
            "52a28f04afcb40299a0797ff5fa50577",
            "074864f5abc5411fb48996c96089c797",
            "c3932b7336aa48bb86e12064a25f3f3e",
            "e97a54c081194a728290b8a9511508aa",
            "c75c74b549674d4a806d006c7ecda890",
            "1f642047d356424fb7878afed371f8e0",
            "cb17825fbeae4c0bb8582cae97263dd8",
            "114c321f865b451b90f2c2d1b7a10c91",
            "d8413760d1844a1b96c4899e240713a6",
            "0adfb144a100480c8698046219c0083e",
            "762b1a2797904cdf85ee805ed354f552",
            "9f40f55d74d24946a347de8569ab4b3b",
            "7904458f37c7495e951efb9b0ad56d7b",
            "aeea88b882284431aedf165898621585",
            "272943e4466c4fa6aef5f443a38abf45",
            "82ad021fc8244c89b5c13387bd6ccea7",
            "f0412e77fa7a4e08852b33419a5458d8",
            "9211c0ba359c46f6b0d278ccce68329a",
            "4392c79475944cebbfcc6101343ae1fd",
            "458e76270526405fa6ac3d3f90cf12b5",
            "173b218e980144b9b5d1b795b88a8641",
            "fe59ffe426684a6296e45d9c3dc02464",
            "ed50608804a24a148a1403ac3130d7b9",
            "a8425c0ba6104bf885f47068d51d6c98",
            "2cfa42664b3f45d18df30fa1d0f0caed",
            "5c8cc813c40e4afe9490b18034d791fc",
            "24e4b1bacf01491096a2fef1ca90ffac",
            "8c2464b7b49d477d990377c7e440d0c0",
            "d033e63b8d774e128ab0b8db244f93b2",
            "9637fed26d8d44b1abcfec42755efaae",
            "0d38c3fccffb48f0a5f517e16f7a7e3b",
            "c1bafe197aca4a7f9f2844722cc2aad1",
            "7f76257d971c43d1b1f2478d08656c66",
            "062b456e323849b197d7bb02180af5f3",
            "b3f3942036584c73b767fb882d79cce0",
            "9b9a9fbfbf7348e4923fadcc539656ea",
            "5821a25111c248338421f76a72625475",
            "bbd0534c78434e5ca728c19c513717e0",
            "c93ed162121941089045073f8691a40d",
            "5cd0973dc9124d65b6175591e44950da",
            "628325f94c3a49e6bcc135bf28214aea",
            "8627903678c34811b10775fee4517080",
            "8171858c1ff64010a7c51eaaf80fbd57",
            "8dde4acc6e0b41409c8bc160977e9c24",
            "8cee413d23894fea820033d53d8f2335",
            "861d3460e663491ba1a1d35d36c93b06",
            "f9b56c7768de4f6ebc029599e366dade",
            "8a3adc0b0b0c47158b97b19fbad7f657",
            "37d21542cc1d471fbbfc74d5b4ee7062",
            "a5660c978e344d9191431d532b624d9c",
            "3f3dd6d7f4514f5481d1ab904f71b44a",
            "9a55f1ee782b49bca977dce644a9ac9b",
            "da3466df754645c38679126e38c89bfd",
            "721ecdbd9740409cb1f7b2cfa883d6d6",
            "4fc5484cd7c94d4cb411f9e894a0168a",
            "f815ff9d38604b20b03bf2f5c3226bb4",
            "ed2524f2939f48c8b13e4939c2f7ac92",
            "ec6c44f2425d4bfc89e2e9843a942da0",
            "628954d116c64f15b9158544009b2a81",
            "dc45f2b13988415d86ef83a678c34767",
            "c3d61d66be68486cb4c9b50e8fced3fa",
            "fcb35cab7c054d15bbb3a57be4ee163e",
            "5df35cf6d8f14e5a93df67e668a518db",
            "1843fdbdecf64164a65e56fc1a8652b4",
            "1268f17fda424faca7211457e0d90816",
            "494d213123264d399aaa0698482c661b",
            "63cd1016e8654619bff779a1889919c9",
            "fa2f03a95d764e8bafcfb001d7535f1c",
            "8b680936eadb4e8eb11b89dd5fc687dd",
            "aefc7d633de24551a946b2f9ca592839",
            "3f2142579fa14257b277c5c602c2ef22",
            "1afc82897951429f933b7556f021fe63",
            "89063f197d6f445a8f641470f53c82ec",
            "9aae43163fac48f8b6e64d887f8b9da4",
            "a2ec3b1327ea4b0dbc8a38660d624c96",
            "c1f4bd88a0ae44c49b18bf2770873003",
            "59dad0b4c5fd483bb91a88c74f530f72",
            "e9db12ca111e453a99380d5cd815c7a3",
            "e59b8109ffc34bb4bd8f3c263090265a",
            "a45cd8355329454ca1cb63dad17f5f9b",
            "e06eb8d0d3964efdbf78411c6d518fd0",
            "d6b3e0073400452ab3aaa04207a717b4",
            "d2af5cd0c12b4ca2aff33e97aa8a2071",
            "c31c0a1c7d184293921ae91a96bea5a1",
            "9e09566862b1448992880bac2ba3f8e6",
            "d56ce66dd5a240ebb16ed4a8bca99d8e",
            "1bd33c6086a84619b8a31904c2d29cf5",
            "341335e21b324c969c0b0ddadbdd448f",
            "09c3724193744156a7732469c961722c",
            "ce7eba44f0ff4caeac1ba650424d7763",
            "d670ce5dfaec46fbafc1285eb0adb4f3",
            "20bd48a0514f424abd6417cbe05d48b8",
            "873d92a0c8d6484a8828a5d40cb43f9a",
            "bfc1d9e2e3ba4791acc8c88677488ac9",
            "a1a18e1bee974e7e90af00872db6956b",
            "740f156c886341568fb07624ff6007be",
            "8523779755bd48b295394616746447ca"
          ]
        },
        "id": "_aG0BFlZ40IT",
        "outputId": "636101d0-7763-46ad-ede3-d0662b4370cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a02f91460bc4267b21a914cc7ecf00d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcecfe2635f44bf2b981b02ee8eb4d5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa2d439f4ffd461982ee831189fb0293"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22b0a7a93b404aaab41582ac569603d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8540e67cf2f48f99e218653b66f8007"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a81efcc3c084d1a8c66c9fd40e1dc21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/711 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0adfb144a100480c8698046219c0083e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "173b218e980144b9b5d1b795b88a8641"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1bafe197aca4a7f9f2844722cc2aad1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8171858c1ff64010a7c51eaaf80fbd57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================================\n",
            "üî• TRAINING en ‚Üí de on 7500 samples\n",
            "===================================================\n",
            "Train=6000 Test=0 for en->de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "721ecdbd9740409cb1f7b2cfa883d6d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/813M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1268f17fda424faca7211457e0d90816"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1f4bd88a0ae44c49b18bf2770873003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd33c6086a84619b8a31904c2d29cf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [1:01:23<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss = 1.5987\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:44<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss = 1.4186\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:39<00:00,  7.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss = 1.3123\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:15<00:00,  7.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss = 1.2201\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:37<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss = 1.1424\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [07:38<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss = 1.0699\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:08<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss = 1.0074\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:14<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss = 0.9501\n",
            "Saved best model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n",
            "\n",
            "====== Evaluating en ‚Üí de ======\n",
            "Loading finetuned model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1147465713.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0mtest_en_de\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"de\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en_de\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m \u001b[0mevaluate_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"de\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_en_de\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0mtest_de_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"de\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"de_en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1147465713.py\u001b[0m in \u001b[0;36mevaluate_direction\u001b[0;34m(src, tgt, test_ds)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLEU:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_feature_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_feature_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36m_infer_feature_from_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_feature_from_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsvntpaO6bAd",
        "outputId": "19ce534a-e22d-43c3-94c3-1c49300f7add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['project_name', 'set_name', 'image_id', 'image_file', 'source', 'target', 'french']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL TRAINING + EVALUATION SCRIPT (SIGLIP FUSION + LORA)\n",
        "# Supports: en‚Üíde, de‚Üíen, en‚Üífr, fr‚Üíen\n",
        "# Dataset columns:\n",
        "# ['project_name','set_name','image_id','image_file','source','target','french']\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "from transformers import SiglipVisionModel, SiglipProcessor\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "# ================================================================\n",
        "# BLEU\n",
        "# ================================================================\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "MODEL_DIR = Path(BASE)\n",
        "OUT_DIR = MODEL_DIR / \"ecomm_finetuned\"\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TSV_FILE = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        "IMG_DIR = Path(\"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\")\n",
        "\n",
        "# Pretrained base checkpoints\n",
        "PRETRAINED = {\n",
        "    \"en_de\": MODEL_DIR / \"siglip_fusion_lora_en_de_mm_best.pt\",\n",
        "    \"de_en\": MODEL_DIR / \"siglip_fusion_lora_de_en_mm_best.pt\",\n",
        "    \"en_fr\": MODEL_DIR / \"siglip_fusion_lora_en_fr_mm_best.pt\",\n",
        "    \"fr_en\": MODEL_DIR / \"siglip_fusion_lora_fr_en_mm_best.pt\"\n",
        "}\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# ================================================================\n",
        "# HYPERPARAMETERS\n",
        "# ================================================================\n",
        "MAX_LEN = 64\n",
        "BATCH = 2\n",
        "LR = 2e-4\n",
        "EPOCHS = 8     # adjust if needed\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOAD\n",
        "# ================================================================\n",
        "def safe_load(img_name):\n",
        "    if not isinstance(img_name, str) or img_name.strip() == \"\":\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    img_name = img_name.strip()\n",
        "\n",
        "    for split in [\"train\",\"val\",\"test\"]:\n",
        "        fp = IMG_DIR / split / img_name\n",
        "        try:\n",
        "            if fp.exists():\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "        except:\n",
        "            return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# DATASET\n",
        "# ================================================================\n",
        "class ECommerceDataset(Dataset):\n",
        "    def __init__(self, df, src_lang, tgt_lang):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src = src_lang\n",
        "        self.tgt = tgt_lang\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"]).strip()\n",
        "        de = str(row[\"target\"]).strip()\n",
        "        fr = str(row[\"french\"]).strip()\n",
        "        img = row[\"image_file\"]\n",
        "\n",
        "        # SOURCE selection\n",
        "        if self.src == \"en\":   src_text = en\n",
        "        elif self.src == \"de\": src_text = de\n",
        "        else:                  src_text = fr\n",
        "\n",
        "        # TARGET selection\n",
        "        if self.tgt == \"en\":   tgt_text = en\n",
        "        elif self.tgt == \"de\": tgt_text = de\n",
        "        else:                  tgt_text = fr\n",
        "\n",
        "        # Clean None / empty\n",
        "        if src_text is None or src_text == \"nan\": src_text = \"\"\n",
        "        if tgt_text is None or tgt_text == \"nan\": tgt_text = \"\"\n",
        "\n",
        "        return {\"src\": src_text, \"tgt\": tgt_text, \"img\": img}\n",
        "\n",
        "# ================================================================\n",
        "# CREATE TRAIN/TEST SPLITS\n",
        "# ================================================================\n",
        "def load_split(src, tgt, total_samples):\n",
        "\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "\n",
        "    df = df[df[\"set_name\"].str.lower().isin([\"train\",\"test\"])]\n",
        "    df = df[[\"source\",\"target\",\"french\",\"image_file\",\"set_name\"]]\n",
        "\n",
        "    # Remove bad text rows\n",
        "    df = df.dropna(subset=[\"source\",\"target\",\"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # EN‚ÜîDE = 15000 max ‚Üí your dataset = 7500 ‚Üí we use all\n",
        "    train_df = df[df[\"set_name\"]==\"train\"]\n",
        "    test_df  = df[df[\"set_name\"]==\"test\"]\n",
        "\n",
        "    # Train split limit\n",
        "    train_df = train_df.sample(min(len(train_df), int(total_samples*0.8)), random_state=42)\n",
        "    test_df = test_df.sample(min(len(test_df), int(total_samples*0.2)), random_state=42)\n",
        "\n",
        "    print(f\"Train={len(train_df)} Test={len(test_df)} for {src}->{tgt}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# ================================================================\n",
        "# SIGLIP FUSION MODEL (LoRA)\n",
        "# ================================================================\n",
        "def apply_lora(m):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\",\"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(m, cfg)\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8,\n",
        "            dim_feedforward=2048, dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.enc = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        return self.enc(torch.cat([img_emb, txt_emb], dim=1))\n",
        "\n",
        "class SiglipFusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "        for p in self.vision.parameters(): p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.txt_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def forward(self, ids, mask, pixel, labels):\n",
        "        with torch.no_grad():\n",
        "            v = self.vision(pixel).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_e = self.proj(v).unsqueeze(1)\n",
        "        txt_e = self.txt_emb(ids)\n",
        "\n",
        "        fused = self.fusion(img_e, txt_e)\n",
        "        fused_mask = torch.cat([torch.ones((ids.size(0),1), device=device), mask], dim=1)\n",
        "\n",
        "        return self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TOKENIZER + PROCESSOR\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "\n",
        "# ================================================================\n",
        "# COLLATE\n",
        "# ================================================================\n",
        "def collate(batch):\n",
        "    src = [b[\"src\"] for b in batch]\n",
        "    tgt = [b[\"tgt\"] for b in batch]\n",
        "    imgs = [safe_load(b[\"img\"]) for b in batch]\n",
        "\n",
        "    # Tokenize source\n",
        "    enc_src = tokenizer(\n",
        "        src, padding=\"max_length\", truncation=True,\n",
        "        max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Tokenize target\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        enc_tgt = tokenizer(\n",
        "            tgt, padding=\"max_length\", truncation=True,\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    labels = enc_tgt[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    pixel = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": enc_src[\"input_ids\"].to(device),\n",
        "        \"mask\": enc_src[\"attention_mask\"].to(device),\n",
        "        \"labels\": labels.to(device),\n",
        "        \"pixel\": pixel.to(device)\n",
        "    }\n",
        "\n",
        "# ================================================================\n",
        "# TRAINING LOOP\n",
        "# ================================================================\n",
        "def train_direction(src, tgt, key, total_samples):\n",
        "\n",
        "    print(\"\\n===================================================\")\n",
        "    print(f\"üî• TRAINING {src} ‚Üí {tgt} on {total_samples} samples\")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    train_df, test_df = load_split(src, tgt, total_samples)\n",
        "\n",
        "    train_loader = DataLoader(ECommerceDataset(train_df, src, tgt),\n",
        "                              batch_size=BATCH, shuffle=True, collate_fn=collate)\n",
        "    test_ds = ECommerceDataset(test_df, src, tgt)\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    print(\"Loading pretrained checkpoint:\", PRETRAINED[key])\n",
        "    model.load_state_dict(torch.load(PRETRAINED[key], map_location=device), strict=False)\n",
        "\n",
        "    # Freeze all except LoRA weights\n",
        "    for n, p in model.named_parameters():\n",
        "        p.requires_grad = (\"lora\" in n)\n",
        "\n",
        "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "    best = 999999\n",
        "    save_path = OUT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optim.zero_grad()\n",
        "            out = model(batch[\"ids\"], batch[\"mask\"], batch[\"pixel\"], batch[\"labels\"])\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        ep_loss = total / len(train_loader)\n",
        "        print(f\"Epoch {ep} Loss = {ep_loss:.4f}\")\n",
        "\n",
        "        if ep_loss < best:\n",
        "            best = ep_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"Saved best model:\", save_path)\n",
        "\n",
        "    return test_ds\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION\n",
        "# ================================================================\n",
        "def evaluate_direction(src, tgt, test_ds):\n",
        "\n",
        "    print(\"\\n====== Evaluating\", src, \"‚Üí\", tgt, \"======\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    print(\"Loading finetuned model:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs = [], []\n",
        "\n",
        "    for sample in tqdm(test_ds):\n",
        "        src_text = sample[\"src\"]\n",
        "        tgt_text = sample[\"tgt\"]\n",
        "        refs.append(tgt_text)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            src_text, truncation=True, padding=\"max_length\",\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        img = safe_load(sample[\"img\"])\n",
        "        pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            v = model.vision(pixel).last_hidden_state[:,0,:]\n",
        "            img_e = model.proj(v).unsqueeze(1)\n",
        "            txt_e = model.txt_emb(enc[\"input_ids\"])\n",
        "            fused = model.fusion(img_e, txt_e)\n",
        "            fused_mask = torch.cat([torch.ones((1,1), device=device), enc[\"attention_mask\"]], dim=1)\n",
        "\n",
        "            gen = model.mbart.generate(\n",
        "                inputs_embeds=fused,\n",
        "                attention_mask=fused_mask,\n",
        "                num_beams=5,\n",
        "                max_length=MAX_LEN,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=[[r] for r in refs])[\"score\"]\n",
        "    print(\"BLEU:\", bleu)\n",
        "    return bleu\n",
        "\n",
        "# ================================================================\n",
        "# RUN TRAINING FOR ALL 4 DIRECTIONS\n",
        "# ================================================================\n",
        "# Dataset size = 7500 ‚Üí use full\n",
        "SAMPLES = 7500\n",
        "\n",
        "test_en_de = train_direction(\"en\", \"de\", \"en_de\", SAMPLES)\n",
        "#evaluate_direction(\"en\", \"de\", test_en_de)\n",
        "\n",
        "test_de_en = train_direction(\"de\", \"en\", \"de_en\", SAMPLES)\n",
        "#evaluate_direction(\"de\", \"en\", test_de_en)\n",
        "\n",
        "test_en_fr = train_direction(\"en\", \"fr\", \"en_fr\", SAMPLES)\n",
        "#evaluate_direction(\"en\", \"fr\", test_en_fr)\n",
        "\n",
        "test_fr_en = train_direction(\"fr\", \"en\", \"fr_en\", SAMPLES)\n",
        "#evaluate_direction(\"fr\", \"en\", test_fr_en)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780,
          "referenced_widgets": [
            "dafd9e216d8c48bfa08f832ca4591e4e",
            "6bbcfc87cc084fc1850a28033520a2d2",
            "d7dbcf72442949ed91119bd39bb44f8c",
            "edfb984c8a0046678ebc6f8d97d62ce4",
            "063df0d431e140078686200043023efd",
            "2e9161c7d8a345baaa4c07b56c63fddc",
            "6898fbdf742d4f87b3485bd80edaa3eb",
            "0f099f6446b24a18be4f5c4190de8291",
            "2fa238c2ad1f405cb46331b415d8c3e2",
            "2328c906111549798f5de42d318a0da0",
            "a853872d2e2c44a98eb89570803d2881",
            "bde3a878541547889c670b630b9ecfae",
            "cfbce9a56324419bbe114354533fafa1",
            "4f08ecb7a70540d29d4f9a4c5e6e64ad",
            "1852d91ea1ba48049185afd877daaa96",
            "e2c067f81e8b49d8994277bfb5cdbcf5",
            "8d30adff60784942b2065930cce14687",
            "cfdd768a2c3a4da1a29befcd9200684a",
            "596da4c0d5dc4f6984d2643694711736",
            "e7dec0fed37a4be398fe72a57b77fd27",
            "eca818624dfc4139b066b27752ee7b58",
            "8cff975e481943bc8a1c53736b456988",
            "821e5e52baae40a1bd018ea2e0e2426d",
            "01cbef8671584dc9903d7b473a0c9f70",
            "8f0a2e11be4e4a0182bf7cd7982888f9",
            "c733980b68974bcaa936f2bfa588ceda",
            "dc2167c2f2b540f0838f8bd4d4f41100",
            "c720298af8ff4942b2e78fdb671f2e44",
            "a680ecdbae0446f7ad17b14cb4565caa",
            "5c7d1bcfc9e34c8e86c8cbdde7404533",
            "d2fda5ce75714d6082ec1e4616c7a22b",
            "cd6d5af59c98485ea13fb1b34a2a5e23",
            "0eff208d315544bf91bd1eb0730c947a",
            "7f7ddf7565a0460c8332d01a0d398794",
            "90e9e0de47364e2aacbbc78d840f7a55",
            "33e6a2d8920a45279e9b2ebcce2df031",
            "90c98426d39848deb26b5e7e79fb8259",
            "c665ba91451043538ac7f567dd9b2881",
            "db213d9597324345963b98183e1174ab",
            "9c30b81fd84341c3b25d53572e8716fe",
            "3fc189a9e840440b91f4911d7e3d8962",
            "54576f808368416594412d7d2f55c1ad",
            "9358e1d060a34e869c1c8f16a90472ef",
            "d682fcc6e27f4733be45d2725640adad",
            "d277bdeb1da040329d93509ec331b5c3",
            "26368f4d7dbd45588e6b7d9c7d66f173",
            "b75078709c9d49578eacefc7b58c3860",
            "6c0ca28dc30a46e6bd5f185f2c0404d5",
            "de4de60588344e1da9e6aec16c1e03eb",
            "a07d22f0846c4487a908e491d693abbf",
            "3619fd72e29448f4a7fb4df0f4f1d6b8",
            "e9be762dbd2d43e191431fa4a623ba63",
            "c4f2ec28ef014d3eba39d8d3852afecd",
            "f55c33c05bf54478a8dc5aefe0151405",
            "16a87008c94e452f9c79b4a36a240084",
            "d9f41f26eca74478a0611ec8cf65e2d0",
            "f4a3e10871d64a71940380866423bd1c",
            "ce5d83cb2d744e3d89943a2297c2f6e2",
            "abc288b74adc4938b1ef4caf397f2287",
            "284e4820d4c04b6fb0c681a3986994e0",
            "e55ace4692824f308bea481e58e98be0",
            "456863fcf3c84aa6b797654a87374aa1",
            "a4540f3ad2484fccb0cdb78f56c9a7b2",
            "f1c47fe1b8b0488db43a68811d4e878e",
            "ffaff3f38e8546f487ed647a8f9deb16",
            "751d0a64d759412caf86806b58a9b6a2",
            "b30ea5bf8eac42b2b34561e151e29555",
            "643cfdad80f948719059a1b95cbb66f4",
            "9d1098fcad334b0bb1fbdaab6c55ccdd",
            "cca5e48eb10a4eb6bdb107577bfdf25d",
            "67b729fdc6ed4b25a65b159984849e1e",
            "2d85d58d06704fbb8153c4cac20f9d53",
            "1a996499c15c427c8e1bf153e00eb94c",
            "2417e9e501a1401a827184425be940d3",
            "0e89613d0749479390565bd823afef15",
            "8d419e7ef351496495476f09e8bd9ef0",
            "c59a9958a80b4161a61b2253447883f6",
            "9734583f334a457f8e5bc8ec697ed384",
            "04f02c23ee664a8492c7b56c298bbff5",
            "cd0de435dc14418fbeef75703c12d6e3",
            "3c24c6d8ba6c40099d6d51b159d7551b",
            "c64731ad34624c6faafa96f42b8ca6be",
            "33d564ea70ed4ea79d6a850b1cca1e52",
            "8101ca260ca84cb39a617a4add1617ad",
            "a79ba12bbc6a4b648975c910f78afde0",
            "3ded62deb8384866afc83b97b7a9c399",
            "91b61e7349624fe694ef85b00ed73156",
            "01de165ba8814e15a4e43f89873e1df6",
            "d46cd7bb00614be09e3400d552c5d9bb",
            "46f8ee4d42c440b88111d3c7d5bbf2e6",
            "d48ce1d41dd94eb8a6619bd0fb1ad15e",
            "0b7582f368464c239de258c2b30eacf1",
            "23683331628b4651b0fa638e572501a2",
            "3e28fe47f18a46f1b36c21f43b6039fd",
            "33a4ffe1a33840ef826025df23644dc5",
            "ee32d0971b4e4c1fa5cfd66018320f9b",
            "a2693d92c55a40c7a001c5427382db58",
            "9961694a06f94374b11ab4363525a947",
            "59f9542fbb2a4bfd9f470354801d11e9",
            "438ea22fed3047608dba29b3f517a136",
            "87dc07a071ee43e487159d4cd8fb2f92",
            "10e9284e957c4e8688415d26c95ec20f",
            "78e8275668714257a8ca64131cde40cf",
            "355cac62b2364a138c781c1bcc0dec61",
            "67760a6f551746aaaf0ef604a214fafa",
            "90d28bd03742452d94c7e739c571ed14",
            "29af318882b449bfa43fd1f7a4bba450",
            "9c45251aa0a047f3a33d21a4b3ec970e",
            "ef312badc8924e918378afcc25fb2e4a",
            "925c6a88db8b4abb9ffe80d9aa653c76",
            "39e5503b2ecc4fd3a877609ac4b24f8e",
            "2514d3dafc934d1c881ca0cc090d6a0d",
            "346b5c3243d1493f918e428f58e4d73b",
            "220fcc07c74f4c84b29248ddeabc69c8",
            "19ce9ed33861440bbc718a12cd14c3f9",
            "8af566c7659d4fe5a2a89f81f5f25e86",
            "563ef901b02245ab8906a6f8efbc2465",
            "12b18980526e4619935e8393857e7c22",
            "d6032a631caa4b00b2d9bc7c5794f02a",
            "1996f42e2acb4423b0dab83dfc3de10a",
            "629aa1629953411da390e881fabf0cc0",
            "3c40fd7b0c0c4e248bd618059963abe5",
            "21509915051e4e779edc8c3319e452e7",
            "13b5eab9d6cc460e997faea93cfb01db",
            "1d3eabd6f7674aeb88815dc8bd61bf37",
            "641adfb1e73147529aec0dd9e7877136",
            "1c337a7d144543729cd2c1fc32207c29",
            "98cd2f422fd54dbeb77220834f877bf1",
            "a17fe9589b3c4108ab2276c29d1c5e6a",
            "e329707c974e4c82b921ce57d3b9ed93",
            "5e3c351c4b6c46539cc21ed3f8440b3f",
            "4979c1f3321747bbb88afa6636841c82",
            "a3c746e9d2704aa89dfccb58f0b1588c",
            "ddb693d87e21470dbeeb68a82d49edf9",
            "c660c5b16f8949e7a8d52236228db8c2",
            "77e4d2dfb9ad4dbea1220b3991ed84e1",
            "8630e5ca51004defb5d674c35c33e1e9",
            "a116809a21a44a21ac6f3eec35c05977",
            "9045935a82544abbbe98e0563a7b365e",
            "ba2fb0d51024444886e25d8089852675",
            "a713b7d747cc44ffbcfc0df61af487e4",
            "6c062b1e4de44a92a9d4e5e0b05c24f4",
            "a403b8fdac854751bd9c9a145a5db821",
            "89c489d9de014797876ea598a93fbaa5",
            "fe6abf85d2bf46b9bc8bbc639ecaf1f4",
            "fa3d174069f34a2e9945ac2e69d27ccd",
            "9c769b79611940e88b478ad7aeab3096",
            "0a3cf84615f143cab8c77eee99425a80",
            "5706a091dde9412ebc768878d6dd24cb",
            "47ecfcbb19fd4a2f98429910a8496c2d",
            "fb01ca8694034f2f8a81e4fd28804aaa",
            "28e67e3d14174f689c747c71d7d1875d",
            "3abd3acdf6904e7f891c5bec2b185146",
            "673395de77514415a91983269e807674"
          ]
        },
        "id": "5lsBcNSBDTpR",
        "outputId": "10900103-9402-4955-e90f-64de26429c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dafd9e216d8c48bfa08f832ca4591e4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bde3a878541547889c670b630b9ecfae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "821e5e52baae40a1bd018ea2e0e2426d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f7ddf7565a0460c8332d01a0d398794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d277bdeb1da040329d93509ec331b5c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9f41f26eca74478a0611ec8cf65e2d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/711 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b30ea5bf8eac42b2b34561e151e29555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9734583f334a457f8e5bc8ec697ed384"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d46cd7bb00614be09e3400d552c5d9bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "438ea22fed3047608dba29b3f517a136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================================\n",
            "üî• TRAINING en ‚Üí de on 7500 samples\n",
            "===================================================\n",
            "Train=6000 Test=0 for en->de\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39e5503b2ecc4fd3a877609ac4b24f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/813M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c40fd7b0c0c4e248bd618059963abe5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3c746e9d2704aa89dfccb58f0b1588c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89c489d9de014797876ea598a93fbaa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            " 11%|‚ñà‚ñè        | 344/3000 [13:28<1:13:35,  1.66s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üîÅ FINAL FULL TRAINING + EVALUATION SCRIPT FOR EN‚ÜîFR\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast,\n",
        "    MBartForConditionalGeneration,\n",
        "    SiglipVisionModel,\n",
        "    SiglipProcessor,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# CONFIG\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "MAX_LEN = 64\n",
        "BATCH = 2\n",
        "LR = 2e-4\n",
        "EPOCHS = 10\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "MODEL_DIR = Path(BASE)\n",
        "\n",
        "# Output folder (special folder for French finetuning)\n",
        "OUT_DIR = MODEL_DIR / \"ecomm_french_finetuned\"\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Dataset files\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "IMG_DIR = Path(\n",
        "    \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        ")\n",
        "\n",
        "# Pretrained models provided by you\n",
        "PRETRAINED = {\n",
        "    \"en_fr\": MODEL_DIR / \"siglip_fusion_lora_en_fr_mm_best.pt\",\n",
        "    \"fr_en\": MODEL_DIR / \"siglip_fusion_lora_fr_en_mm_best.pt\",\n",
        "}\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load(img_name):\n",
        "    if not isinstance(img_name, str):\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    img_name = img_name.strip()\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = IMG_DIR / split / img_name\n",
        "        try:\n",
        "            if fp.exists():\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "        except:\n",
        "            return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# DATASET\n",
        "# ================================================================\n",
        "class FrenchDataset(Dataset):\n",
        "    def __init__(self, df, src, tgt):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        de = str(row[\"target\"])\n",
        "        fr = str(row[\"french\"])\n",
        "        img = row[\"image_file\"]\n",
        "\n",
        "        if self.src == \"en\":\n",
        "            src_text = en\n",
        "        else:\n",
        "            src_text = fr\n",
        "\n",
        "        if self.tgt == \"fr\":\n",
        "            tgt_text = fr\n",
        "        else:\n",
        "            tgt_text = en\n",
        "\n",
        "        return {\"src\": src_text, \"tgt\": tgt_text, \"img\": img}\n",
        "\n",
        "# ================================================================\n",
        "# CREATE TRAIN/TEST SPLITS (AUTO-SPLIT 6000 / 1500)\n",
        "# ================================================================\n",
        "def load_french_splits(src, tgt):\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "\n",
        "    df = df[df[\"set_name\"].str.lower().isin([\"train\", \"test\"])]\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    train_df = df[df[\"set_name\"] == \"train\"]\n",
        "    test_df = df[df[\"set_name\"] == \"test\"]\n",
        "\n",
        "    # enforce 6000/1500 rule\n",
        "    train_df = train_df.sample(min(len(train_df), 6000), random_state=42)\n",
        "    test_df  = test_df.sample(min(len(test_df), 1500), random_state=42)\n",
        "\n",
        "    print(f\"{src} ‚Üí {tgt}: Train={len(train_df)}, Test={len(test_df)}\")\n",
        "    return train_df, test_df\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=8,\n",
        "            dim_feedforward=2048, dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.enc = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        return self.enc(torch.cat([img_emb, txt_emb], dim=1))\n",
        "\n",
        "class SiglipFusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(\n",
        "            \"google/siglip-base-patch16-224\"\n",
        "        )\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.txt_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def forward(self, ids, mask, pixel, labels):\n",
        "        with torch.no_grad():\n",
        "            v = self.vision(pixel_values=pixel).last_hidden_state[:,0,:]\n",
        "\n",
        "        img_e = self.proj(v).unsqueeze(1)\n",
        "        txt_e = self.txt_emb(ids)\n",
        "\n",
        "        fused = self.fusion(img_e, txt_e)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((ids.size(0),1), device=device), mask],\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        return self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TOKENIZER + COLLATE\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "\n",
        "def collate(batch):\n",
        "    src = [b[\"src\"] for b in batch]\n",
        "    tgt = [b[\"tgt\"] for b in batch]\n",
        "    imgs = [safe_load(b[\"img\"]) for b in batch]\n",
        "\n",
        "    enc_s = tokenizer(\n",
        "        src,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LEN,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        enc_t = tokenizer(\n",
        "            tgt,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    labels = enc_t[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    pixel = processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": enc_s[\"input_ids\"].to(device),\n",
        "        \"mask\": enc_s[\"attention_mask\"].to(device),\n",
        "        \"labels\": labels.to(device),\n",
        "        \"pixel\": pixel.to(device)\n",
        "    }\n",
        "\n",
        "# ================================================================\n",
        "# TRAINING LOOP\n",
        "# ================================================================\n",
        "def train_french(src, tgt, key):\n",
        "    print(f\"\\nüî• Training {src} ‚Üí {tgt}\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    train_df, test_df = load_french_splits(src, tgt)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        FrenchDataset(train_df, src, tgt),\n",
        "        batch_size=BATCH,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate\n",
        "    )\n",
        "    test_ds = FrenchDataset(test_df, src, tgt)\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "\n",
        "    print(\"Loading pretrained:\", PRETRAINED[key])\n",
        "    model.load_state_dict(torch.load(PRETRAINED[key], map_location=device), strict=False)\n",
        "\n",
        "    # Freeze everything except LoRA\n",
        "    for name, p in model.named_parameters():\n",
        "        p.requires_grad = (\"lora\" in name)\n",
        "\n",
        "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "\n",
        "    best = 9999\n",
        "    save_path = OUT_DIR / f\"ecomm_{src}_{tgt}.pt\"\n",
        "\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optim.zero_grad()\n",
        "            out = model(batch[\"ids\"], batch[\"mask\"], batch[\"pixel\"], batch[\"labels\"])\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        print(f\"Epoch {ep} Loss = {total/len(train_loader):.4f}\")\n",
        "\n",
        "        if total < best:\n",
        "            best = total\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"Saved best:\", save_path)\n",
        "\n",
        "    return test_ds\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION (SAVES BLEU + PREDICTIONS)\n",
        "# ================================================================\n",
        "def evaluate_french(src, tgt, test_ds):\n",
        "    print(f\"\\nüîç Evaluating {src} ‚Üí {tgt}\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}.pt\"\n",
        "    print(\"Loading:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, sources, images = [], [], [], []\n",
        "\n",
        "    for sample in tqdm(test_ds):\n",
        "        src_text = sample[\"src\"]\n",
        "        tgt_text = sample[\"tgt\"]\n",
        "        img_name = sample[\"img\"]\n",
        "\n",
        "        sources.append(src_text)\n",
        "        refs.append(tgt_text)\n",
        "        images.append(img_name)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        img = safe_load(img_name)\n",
        "        pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            v = model.vision(pixel).last_hidden_state[:,0,:]\n",
        "            img_e = model.proj(v).unsqueeze(1)\n",
        "            txt_e = model.txt_emb(enc[\"input_ids\"])\n",
        "\n",
        "            fused = model.fusion(img_e, txt_e)\n",
        "            fused_mask = torch.cat(\n",
        "                [torch.ones((1,1),device=device), enc[\"attention_mask\"]],\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            gen = model.mbart.generate(\n",
        "                inputs_embeds=fused,\n",
        "                attention_mask=fused_mask,\n",
        "                max_length=MAX_LEN,\n",
        "                num_beams=5,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        preds.append(tokenizer.decode(gen[0], skip_special_tokens=True))\n",
        "\n",
        "    # BLEU score\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=[refs])[\"score\"]\n",
        "    print(f\"‚≠ê BLEU ({src} ‚Üí {tgt}) = {bleu:.4f}\")\n",
        "\n",
        "    # Save BLEU\n",
        "    bleu_file = OUT_DIR / f\"bleu_{src}_{tgt}.txt\"\n",
        "    with open(bleu_file, \"w\") as f:\n",
        "        f.write(f\"BLEU = {bleu:.4f}\\n\")\n",
        "\n",
        "    # Save predictions\n",
        "    pred_file = OUT_DIR / f\"preds_{src}_{tgt}.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": sources,\n",
        "        \"reference\": refs,\n",
        "        \"prediction\": preds,\n",
        "        \"image\": images\n",
        "    }).to_csv(pred_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved:\", bleu_file)\n",
        "    print(\"Saved:\", pred_file)\n",
        "\n",
        "    return bleu\n",
        "\n",
        "# ================================================================\n",
        "# RUN TRAINING\n",
        "# ================================================================\n",
        "test_en_fr = train_french(\"en\", \"fr\", \"en_fr\")\n",
        "test_fr_en = train_french(\"fr\", \"en\", \"fr_en\")\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "#evaluate_french(\"en\", \"fr\", test_en_fr)\n",
        "#evaluate_french(\"fr\", \"en\", test_fr_en)\n"
      ],
      "metadata": {
        "id": "QM1LjfOEfuJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd99e292-7df5-46bb-8246-6d692ff05c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "üî• Training en ‚Üí fr\n",
            "en ‚Üí fr: Train=6000, Test=0\n",
            "Loading pretrained: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_fr_mm_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:05<00:00,  8.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss = 1.8187\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:26<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss = 1.5648\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [07:07<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss = 1.4165\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:27<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss = 1.2953\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:49<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss = 1.2225\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:46<00:00,  7.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss = 1.1116\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:28<00:00,  7.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss = 1.0424\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:27<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss = 0.9805\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:29<00:00,  7.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss = 0.9218\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:27<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss = 0.8727\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n",
            "\n",
            "üî• Training fr ‚Üí en\n",
            "fr ‚Üí en: Train=6000, Test=0\n",
            "Loading pretrained: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_fr_en_mm_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:06<00:00,  8.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss = 2.0215\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:51<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss = 1.8208\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:27<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss = 1.6903\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:26<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss = 1.5824\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:49<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss = 1.4867\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:26<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss = 1.4055\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:50<00:00,  7.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss = 1.3354\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:28<00:00,  7.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss = 1.2661\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:35<00:00,  7.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss = 1.2136\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3000/3000 [06:31<00:00,  7.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss = 1.1580\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n",
            "\n",
            "üîç Evaluating en ‚Üí fr\n",
            "Loading: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4070889406.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;31m# RUN EVALUATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0mevaluate_french\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_en_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0mevaluate_french\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_fr_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4070889406.py\u001b[0m in \u001b[0;36mevaluate_french\u001b[0;34m(src, tgt, test_ds)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;31m# BLEU score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚≠ê BLEU ({src} ‚Üí {tgt}) = {bleu:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_feature_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_feature_from_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/evaluate/module.py\u001b[0m in \u001b[0;36m_infer_feature_from_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_feature_from_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üîÅ CONTINUED TRAINING + EVALUATION ON E-COMMERCE DATA (IMAGE + TEXT)\n",
        "#    - Directions: en‚Üíde, de‚Üíen\n",
        "#    - Models:\n",
        "#        * Multimodal (SigLIP + mBART + LoRA + Fusion)\n",
        "#        * Text-only (mBART + LoRA)\n",
        "#    - Uses existing SigLIP + MBART + LoRA checkpoints from Drive\n",
        "#    - Uses at most 15,000 train samples per direction (per split)\n",
        "#    - Computes BLEU on validation split and saves results to Drive\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ================================================================\n",
        "# Install / import HF + PEFT + evaluate\n",
        "# ================================================================\n",
        "try:\n",
        "    from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "    from transformers import SiglipVisionModel, SiglipProcessor\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "    import evaluate\n",
        "except Exception:\n",
        "    !pip install -q transformers peft accelerate sentencepiece evaluate\n",
        "    from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "    from transformers import SiglipVisionModel, SiglipProcessor\n",
        "    from peft import LoraConfig, get_peft_model, TaskType\n",
        "    import evaluate\n",
        "\n",
        "# BLEU metric\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# Mount Drive\n",
        "# ================================================================\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ================================================================\n",
        "# PATHS ‚Äì ADAPTED TO YOUR DRIVE STRUCTURE\n",
        "# ================================================================\n",
        "# 1) Model folder ‚Äì REAL path behind shared Drive shortcut\n",
        "MODEL_DIR = Path(\n",
        "    \"/content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/\"\n",
        "    \"multimodal_translation_models_siglip_lora_fusion\"\n",
        ")\n",
        "\n",
        "print(\"üìå MODEL_DIR:\", MODEL_DIR)\n",
        "print(\"üìÇ Contents of MODEL_DIR:\")\n",
        "!ls -lh \"/content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion\"\n",
        "\n",
        "# 2) Dataset TSV + images (E-commerce dataset)\n",
        "ECOMM_TSV = (\n",
        "    \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv\"\n",
        ")\n",
        "\n",
        "ECOMM_IMG_DIR = (\n",
        "    \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        ")  # contains train/val/test subfolders\n",
        "\n",
        "# Where to save new finetuned models\n",
        "OUT_MODEL_DIR = MODEL_DIR / \"ecomm_finetuned\"\n",
        "OUT_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"üìå OUT_MODEL_DIR:\", OUT_MODEL_DIR)\n",
        "\n",
        "# Where to save evaluation outputs\n",
        "EVAL_DIR = OUT_MODEL_DIR / \"evals\"\n",
        "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"üìå EVAL_DIR:\", EVAL_DIR)\n",
        "\n",
        "# ================================================================\n",
        "# LOAD CONFIG FROM PREVIOUS TRAINING (for LoRA + hyperparams)\n",
        "# ================================================================\n",
        "cfg_path = MODEL_DIR / \"config_siglip_fusion_lora.json\"\n",
        "print(\"Loading config from:\", cfg_path)\n",
        "\n",
        "with open(cfg_path, \"r\") as f:\n",
        "    config_dict = json.load(f)\n",
        "\n",
        "import types\n",
        "config = types.SimpleNamespace(**config_dict)\n",
        "\n",
        "# Fallbacks if any field missing\n",
        "BATCH_SIZE = getattr(config, \"batch_size\", 24)\n",
        "MAX_LEN = getattr(config, \"max_length\", 64)\n",
        "LR = getattr(config, \"lr\", 2e-4)\n",
        "EPOCHS = getattr(config, \"num_epochs\", 3)\n",
        "vision_model_name = getattr(config, \"vision_model_name\", \"google/siglip-base-patch16-224\")\n",
        "\n",
        "# Limit samples (per split)\n",
        "MAX_TRAIN_SAMPLES = 15000\n",
        "MAX_VAL_SAMPLES   = 2000   # you can increase if you want\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\"}\n",
        "\n",
        "print(\"‚úîÔ∏è Training hyperparams:\")\n",
        "print(\"   batch_size =\", BATCH_SIZE)\n",
        "print(\"   max_len    =\", MAX_LEN)\n",
        "print(\"   lr         =\", LR)\n",
        "print(\"   epochs     =\", EPOCHS)\n",
        "print(\"   vision     =\", vision_model_name)\n",
        "print(\"   train_max  =\", MAX_TRAIN_SAMPLES)\n",
        "print(\"   val_max    =\", MAX_VAL_SAMPLES)\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER ‚Äì searches train/val/test\n",
        "# ================================================================\n",
        "def safe_load_image(filename: Any) -> Image.Image:\n",
        "    if filename is None or str(filename).lower() == \"nan\":\n",
        "        return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "    filename = str(filename).strip()\n",
        "\n",
        "    # try each split folder\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = Path(ECOMM_IMG_DIR) / split / filename\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # last-resort fallback\n",
        "    return Image.new(\"RGB\", (224, 224), (128, 128, 128))\n",
        "\n",
        "# ================================================================\n",
        "# LoRA helpers\n",
        "# ================================================================\n",
        "def apply_lora_to_mbart(mbart: MBartForConditionalGeneration):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=config.lora_r,\n",
        "        lora_alpha=config.lora_alpha,\n",
        "        lora_dropout=config.lora_dropout,\n",
        "        target_modules=config.lora_targets,\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "def freeze_all_except_lora(mbart: MBartForConditionalGeneration):\n",
        "    for name, p in mbart.named_parameters():\n",
        "        if \"lora\" not in name:\n",
        "            p.requires_grad = False\n",
        "\n",
        "# ================================================================\n",
        "# Models\n",
        "# ================================================================\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_embed, text_embed):\n",
        "        # img_embed: [B, 1, d_model]\n",
        "        # text_embed: [B, T, d_model]\n",
        "        x = torch.cat([img_embed, text_embed], dim=1)\n",
        "        return self.encoder(x)\n",
        "\n",
        "class MultiModalModel(nn.Module):\n",
        "    \"\"\"\n",
        "    SigLIP vision encoder + MBART with LoRA + fusion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Loading SigLIP:\", vision_model_name)\n",
        "        self.vision = SiglipVisionModel.from_pretrained(vision_model_name)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False  # freeze vision\n",
        "\n",
        "        print(\"Loading MBART base...\")\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        vision_dim = self.vision.config.hidden_size\n",
        "        self.proj = nn.Linear(vision_dim, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, pixel_values, labels):\n",
        "        # 1) Vision forward (frozen)\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(vis).unsqueeze(1)   # [B, 1, d_model]\n",
        "        txt_embed = self.text_emb(input_ids)      # [B, T, d_model]\n",
        "\n",
        "        fused = self.fusion(img_embed, txt_embed) # [B, 1+T, d_model]\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0), 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        outputs = self.mbart(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, pixel_values, tokenizer, max_length=None, num_beams=5):\n",
        "        if max_length is None:\n",
        "            max_length = MAX_LEN\n",
        "\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_embed = self.proj(vis).unsqueeze(1)\n",
        "        txt_embed = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_embed, txt_embed)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0), 1), device=device), attention_mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        gen_ids = self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            num_beams=num_beams,\n",
        "            max_length=max_length,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "class TextOnlyModel(nn.Module):\n",
        "    \"\"\"\n",
        "    MBART with LoRA (no images).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora_to_mbart(base)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        return self.mbart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer, max_length=None, num_beams=5):\n",
        "        if max_length is None:\n",
        "            max_length = MAX_LEN\n",
        "        gen_ids = self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "        return gen_ids\n",
        "\n",
        "# ================================================================\n",
        "# Dataset (TSV with set_name, source, target, image_file)\n",
        "# ================================================================\n",
        "class EcommDataset(Dataset):\n",
        "    def __init__(self, csv_path: str, split: str, src_lang: str, tgt_lang: str,\n",
        "                 max_samples: int | None = None):\n",
        "        assert split in [\"train\", \"val\", \"test\"]\n",
        "\n",
        "        if csv_path.endswith(\".tsv\") or csv_path.endswith(\".txt\"):\n",
        "            df = pd.read_csv(csv_path, sep=\"\\t\")\n",
        "        else:\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "        df[\"set_name\"] = df[\"set_name\"].str.lower()\n",
        "\n",
        "        if split == \"val\":\n",
        "            mask = df[\"set_name\"].isin([\"val\", \"valid\", \"validation\"])\n",
        "        else:\n",
        "            mask = df[\"set_name\"] == split\n",
        "\n",
        "        df = df[mask].reset_index(drop=True)\n",
        "\n",
        "        if max_samples is not None and len(df) > max_samples:\n",
        "            df = df.sample(n=max_samples, random_state=42).reset_index(drop=True)\n",
        "\n",
        "        self.df = df\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "        print(f\"[{src_lang}->{tgt_lang}] {split} rows:\", len(self.df))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        de = str(row[\"target\"])\n",
        "        img_file = row[\"image_file\"]\n",
        "\n",
        "        if self.src_lang == \"en\" and self.tgt_lang == \"de\":\n",
        "            src_text = en\n",
        "            tgt_text = de\n",
        "        elif self.src_lang == \"de\" and self.tgt_lang == \"en\":\n",
        "            src_text = de\n",
        "            tgt_text = en\n",
        "        else:\n",
        "            # just in case; but we only use en<->de here\n",
        "            src_text = en\n",
        "            tgt_text = de\n",
        "\n",
        "        return {\n",
        "            \"src\": src_text,\n",
        "            \"tgt\": tgt_text,\n",
        "            \"img\": img_file,\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# Collate\n",
        "# ================================================================\n",
        "def make_collate_fn(tokenizer, image_processor, max_length: int):\n",
        "    def collate_fn(batch):\n",
        "        src_texts = [b[\"src\"] for b in batch]\n",
        "        tgt_texts = [b[\"tgt\"] for b in batch]\n",
        "        img_files = [b[\"img\"] for b in batch]\n",
        "\n",
        "        # tokenize source\n",
        "        enc_src = tokenizer(\n",
        "            src_texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # tokenize target\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            enc_tgt = tokenizer(\n",
        "                tgt_texts,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        labels = enc_tgt[\"input_ids\"]\n",
        "        labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "        # images\n",
        "        imgs = [safe_load_image(fn) for fn in img_files]\n",
        "        pixel_values = image_processor(images=imgs, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "\n",
        "        batch_out = {\n",
        "            \"input_ids\": enc_src[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": enc_src[\"attention_mask\"].to(device),\n",
        "            \"labels\": labels.to(device),\n",
        "            \"pixel_values\": pixel_values.to(device),\n",
        "        }\n",
        "        return batch_out\n",
        "\n",
        "    return collate_fn\n",
        "\n",
        "# ================================================================\n",
        "# TRAINING LOOP\n",
        "# ================================================================\n",
        "def train_model(src_lang: str, tgt_lang: str, model_type: str,\n",
        "                tokenizer, processor,\n",
        "                train_limit=15000, val_limit=2000):\n",
        "    \"\"\"\n",
        "    model_type: \"mm\" (multimodal) or \"txt\" (text-only)\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üöÄ TRAINING {model_type.upper()} MODEL FOR {src_lang} ‚Üí {tgt_lang}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src_lang]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "    # ================================================================\n",
        "    # LOAD DATASET ‚Äî FIXED PARAMETER NAME (max_samples instead of limit)\n",
        "    # ================================================================\n",
        "    train_ds = EcommDataset(ECOMM_TSV, \"train\", src_lang, tgt_lang, max_samples=train_limit)\n",
        "    val_ds   = EcommDataset(ECOMM_TSV, \"val\",   src_lang, tgt_lang, max_samples=val_limit)\n",
        "\n",
        "\n",
        "    collate_fn = make_collate_fn(tokenizer, image_processor, MAX_LEN)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=0,\n",
        "        pin_memory=False,\n",
        "    )\n",
        "\n",
        "    # model + base checkpoint (pre-ecomm)\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        base_ckpt = MODEL_DIR / f\"siglip_fusion_lora_{src_lang}_{tgt_lang}_mm_best.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        base_ckpt = MODEL_DIR / f\"mbart_lora_{src_lang}_{tgt_lang}_text_best.pt\"\n",
        "\n",
        "    print(\"üì• Loading base checkpoint:\", base_ckpt)\n",
        "    model.load_state_dict(torch.load(base_ckpt, map_location=device))\n",
        "\n",
        "    # freeze all but LoRA\n",
        "    freeze_all_except_lora(model.mbart)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        [p for p in model.parameters() if p.requires_grad],\n",
        "        lr=LR,\n",
        "        weight_decay=0.01,\n",
        "    )\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    out_ckpt = OUT_MODEL_DIR / f\"ecomm_{src_lang}_{tgt_lang}_{model_type}.pt\"\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
        "\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        n_steps = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=\"Train\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if model_type == \"mm\":\n",
        "                out = model(\n",
        "                    batch[\"input_ids\"],\n",
        "                    batch[\"attention_mask\"],\n",
        "                    batch[\"pixel_values\"],\n",
        "                    batch[\"labels\"],\n",
        "                )\n",
        "            else:\n",
        "                out = model(\n",
        "                    batch[\"input_ids\"],\n",
        "                    batch[\"attention_mask\"],\n",
        "                    batch[\"labels\"],\n",
        "                )\n",
        "\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running += loss.item()\n",
        "            n_steps += 1\n",
        "\n",
        "        train_loss = running / max(1, n_steps)\n",
        "\n",
        "        # ---- val ----\n",
        "        model.eval()\n",
        "        val_running = 0.0\n",
        "        val_steps = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=\"Val\"):\n",
        "                if model_type == \"mm\":\n",
        "                    out = model(\n",
        "                        batch[\"input_ids\"],\n",
        "                        batch[\"attention_mask\"],\n",
        "                        batch[\"pixel_values\"],\n",
        "                        batch[\"labels\"],\n",
        "                    )\n",
        "                else:\n",
        "                    out = model(\n",
        "                        batch[\"input_ids\"],\n",
        "                        batch[\"attention_mask\"],\n",
        "                        batch[\"labels\"],\n",
        "                    )\n",
        "\n",
        "                val_running += out.loss.item()\n",
        "                val_steps += 1\n",
        "\n",
        "        val_loss = val_running / max(1, val_steps)\n",
        "        print(f\"Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), out_ckpt)\n",
        "            print(f\"  ‚úÖ New best; saved to {out_ckpt}\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"‚úÖ Done {model_type.upper()} {src_lang}‚Üí{tgt_lang}; best val={best_val:.4f}\")\n",
        "    return val_ds  # return val dataset for evaluation later if needed\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION (BLEU ON VAL)\n",
        "# ================================================================\n",
        "def evaluate_model(src_lang: str, tgt_lang: str, model_type: str,\n",
        "                   tokenizer, image_processor):\n",
        "    \"\"\"\n",
        "    Evaluate given ecomm model on VAL split using sacreBLEU.\n",
        "    \"\"\"\n",
        "    assert model_type in [\"mm\", \"txt\"]\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üîç Evaluating {model_type.upper()} model for {src_lang} ‚Üí {tgt_lang}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src_lang]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt_lang]\n",
        "\n",
        "    # load val data (we eval on same MAX_VAL_SAMPLES subset)\n",
        "    val_ds = EcommDataset(ECOMM_TSV, \"val\", src_lang, tgt_lang, max_samples=MAX_VAL_SAMPLES)\n",
        "\n",
        "    # load model from ecomm_finetuned\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        ckpt = OUT_MODEL_DIR / f\"ecomm_{src_lang}_{tgt_lang}_mm.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        ckpt = OUT_MODEL_DIR / f\"ecomm_{src_lang}_{tgt_lang}_txt.pt\"\n",
        "\n",
        "    print(\"üì• Loading finetuned checkpoint:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    preds = []\n",
        "    golds = []\n",
        "    srcs  = []\n",
        "    imgs  = []\n",
        "\n",
        "    for i in tqdm(range(len(val_ds)), desc=\"Eval\"):\n",
        "        sample = val_ds[i]\n",
        "        src = sample[\"src\"]\n",
        "        tgt = sample[\"tgt\"]\n",
        "        img_file = sample[\"img\"]\n",
        "\n",
        "        srcs.append(src)\n",
        "        golds.append(tgt)\n",
        "        imgs.append(img_file)\n",
        "\n",
        "        # tokenize source\n",
        "        enc = tokenizer(\n",
        "            src,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        if model_type == \"mm\":\n",
        "            # image\n",
        "            img = safe_load_image(img_file)\n",
        "            pixel = image_processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "            gen_ids = model.generate(\n",
        "                enc[\"input_ids\"],\n",
        "                enc[\"attention_mask\"],\n",
        "                pixel,\n",
        "                tokenizer,\n",
        "                max_length=MAX_LEN,\n",
        "                num_beams=5,\n",
        "            )\n",
        "        else:\n",
        "            gen_ids = model.generate(\n",
        "                enc[\"input_ids\"],\n",
        "                enc[\"attention_mask\"],\n",
        "                tokenizer,\n",
        "                max_length=MAX_LEN,\n",
        "                num_beams=5,\n",
        "            )\n",
        "\n",
        "        pred_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
        "        preds.append(pred_text)\n",
        "\n",
        "    # BLEU\n",
        "    references = [[g for g in golds]]  # sacrebleu expects list of reference lists\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=[golds])[\"score\"]\n",
        "\n",
        "    # save predictions\n",
        "    out_tsv = EVAL_DIR / f\"preds_{model_type}_{src_lang}_{tgt_lang}.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"src\": srcs,\n",
        "        \"gold\": golds,\n",
        "        \"pred\": preds,\n",
        "        \"image_file\": imgs,\n",
        "    }).to_csv(out_tsv, sep=\"\\t\", index=False)\n",
        "\n",
        "    out_bleu = EVAL_DIR / f\"bleu_{model_type}_{src_lang}_{tgt_lang}.txt\"\n",
        "    with open(out_bleu, \"w\") as f:\n",
        "        f.write(f\"BLEU = {bleu:.4f}\\n\")\n",
        "\n",
        "    print(f\"‚≠ê BLEU ({model_type.upper()} {src_lang}‚Üí{tgt_lang}) = {bleu:.4f}\")\n",
        "    print(f\"üìÅ Predictions saved to: {out_tsv}\")\n",
        "    print(f\"üìÅ BLEU score saved to: {out_bleu}\")\n",
        "\n",
        "    return bleu\n",
        "\n",
        "# ================================================================\n",
        "# RUN TRAINING + EVAL FOR EN‚ÜîDE\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "image_processor = SiglipProcessor.from_pretrained(vision_model_name)\n",
        "\n",
        "# -------- TRAIN --------\n",
        "# EN ‚Üí DE\n",
        "train_model(\"en\", \"de\", \"mm\",  tokenizer, image_processor)\n",
        "#train_model(\"en\", \"de\", \"txt\", tokenizer, image_processor)\n",
        "\n",
        "# DE ‚Üí EN\n",
        "train_model(\"de\", \"en\", \"mm\",  tokenizer, image_processor)\n",
        "#train_model(\"de\", \"en\", \"txt\", tokenizer, image_processor)\n",
        "\n",
        "# -------- EVAL (BLEU on VAL) --------\n",
        "results = {}\n",
        "#results[\"en_de_mm\"]  = evaluate_model(\"en\", \"de\", \"mm\",  tokenizer, image_processor)\n",
        "#results[\"en_de_txt\"] = evaluate_model(\"en\", \"de\", \"txt\", tokenizer, image_processor)\n",
        "#results[\"de_en_mm\"]  = evaluate_model(\"de\", \"en\", \"mm\",  tokenizer, image_processor)\n",
        "#results[\"de_en_txt\"] = evaluate_model(\"de\", \"en\", \"txt\", tokenizer, image_processor)\n",
        "\n",
        "# Save combined BLEU summary\n",
        "summary_path = EVAL_DIR / \"BLEU_summary_ecomm_en_de.json\"\n",
        "with open(summary_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"\\n===================================================\")\n",
        "print(\"üéâ All fine-tuning & evaluation runs completed.\")\n",
        "print(\"üìå BLEU summary saved at:\", summary_path)\n",
        "print(\"===================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjpaxeHqCO52",
        "outputId": "9e052f99-cf54-4497-ea28-ea26536303ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "üìå MODEL_DIR: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion\n",
            "üìÇ Contents of MODEL_DIR:\n",
            "total 35G\n",
            "-rw------- 1 root root  962 Dec  3 00:47 config_siglip_fusion_lora_all6.json\n",
            "-rw------- 1 root root  776 Nov 20 00:52 config_siglip_fusion_lora.json\n",
            "drwx------ 2 root root 4.0K Dec  3 17:50 ecomm_eval_en_de\n",
            "drwx------ 2 root root 4.0K Dec  3 01:46 ecomm_finetuned\n",
            "drwx------ 2 root root 4.0K Dec  7 09:02 ecomm_finetuned_fixed\n",
            "drwx------ 2 root root 4.0K Dec  8 21:35 ecomm_french_finetuned\n",
            "-rw------- 1 root root 2.3G Dec  3 04:36 mbart_lora_all6_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 19 17:04 mbart_lora_de_en_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 19 21:37 mbart_lora_de_fr_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 19 08:19 mbart_lora_en_de_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 19 12:56 mbart_lora_en_fr_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 20 10:48 mbart_lora_fr_de_text_best.pt\n",
            "-rw------- 1 root root 2.3G Nov 20 06:41 mbart_lora_fr_en_text_best.pt\n",
            "-rw------- 1 root root 2.7G Dec  3 03:01 siglip_fusion_lora_all6_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 19 15:22 siglip_fusion_lora_de_en_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 19 19:27 siglip_fusion_lora_de_fr_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 19 06:16 siglip_fusion_lora_en_de_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 19 11:15 siglip_fusion_lora_en_fr_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 20 08:15 siglip_fusion_lora_fr_de_mm_best.pt\n",
            "-rw------- 1 root root 2.7G Nov 20 05:10 siglip_fusion_lora_fr_en_mm_best.pt\n",
            "drwx------ 2 root root 4.0K Dec  3 05:14 test2016_all6_eval\n",
            "drwx------ 2 root root 4.0K Nov 21 08:43 test2016_predictions\n",
            "drwx------ 2 root root 4.0K Nov 21 16:26 test2017_predictions\n",
            "üìå OUT_MODEL_DIR: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned\n",
            "üìå EVAL_DIR: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/evals\n",
            "Loading config from: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/config_siglip_fusion_lora.json\n",
            "‚úîÔ∏è Training hyperparams:\n",
            "   batch_size = 2\n",
            "   max_len    = 64\n",
            "   lr         = 0.0002\n",
            "   epochs     = 6\n",
            "   vision     = google/siglip-base-patch16-224\n",
            "   train_max  = 15000\n",
            "   val_max    = 2000\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRAINING MM MODEL FOR en ‚Üí de\n",
            "======================================================================\n",
            "[en->de] train rows: 15000\n",
            "[en->de] val rows: 2000\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART base...\n",
            "üì• Loading base checkpoint: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_en_de_mm_best.pt\n",
            "\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/7500 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [1:34:11<00:00,  1.33it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [12:25<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.5769 | Val loss: 1.4035\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n",
            "\n",
            "Epoch 2/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:03<00:00,  7.33it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:13<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.4200 | Val loss: 1.3532\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n",
            "\n",
            "Epoch 3/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:03<00:00,  7.33it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:12<00:00, 13.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.3115 | Val loss: 1.2850\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n",
            "\n",
            "Epoch 4/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:02<00:00,  7.33it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:12<00:00, 13.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.2313 | Val loss: 1.3019\n",
            "\n",
            "Epoch 5/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:39<00:00,  7.50it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:13<00:00, 13.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.1848 | Val loss: 1.2396\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n",
            "\n",
            "Epoch 6/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:01<00:00,  7.34it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:13<00:00, 13.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.1384 | Val loss: 1.2460\n",
            "‚úÖ Done MM en‚Üíde; best val=1.2396\n",
            "\n",
            "======================================================================\n",
            "üöÄ TRAINING MM MODEL FOR de ‚Üí en\n",
            "======================================================================\n",
            "[de->en] train rows: 15000\n",
            "[de->en] val rows: 2000\n",
            "Loading SigLIP: google/siglip-base-patch16-224\n",
            "Loading MBART base...\n",
            "üì• Loading base checkpoint: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/siglip_fusion_lora_de_en_mm_best.pt\n",
            "\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   0%|          | 0/7500 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:39<00:00,  7.50it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:13<00:00, 13.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.4294 | Val loss: 1.2780\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n",
            "\n",
            "Epoch 2/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [17:01<00:00,  7.34it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:13<00:00, 13.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.2967 | Val loss: 1.2336\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n",
            "\n",
            "Epoch 3/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:46<00:00,  7.45it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:11<00:00, 13.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.2047 | Val loss: 1.1781\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n",
            "\n",
            "Epoch 4/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:57<00:00,  7.37it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:11<00:00, 13.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.1826 | Val loss: 1.1622\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n",
            "\n",
            "Epoch 5/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:58<00:00,  7.37it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:11<00:00, 13.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.0817 | Val loss: 1.1250\n",
            "  ‚úÖ New best; saved to /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n",
            "\n",
            "Epoch 6/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [16:39<00:00,  7.50it/s]\n",
            "Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:11<00:00, 14.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 1.0206 | Val loss: 1.1287\n",
            "‚úÖ Done MM de‚Üíen; best val=1.1250\n",
            "\n",
            "===================================================\n",
            "üéâ All fine-tuning & evaluation runs completed.\n",
            "üìå BLEU summary saved at: /content/drive/.shortcut-targets-by-id/1GcIeOxxtd-cnipwAaf8rdRqrjBuQeOWP/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/evals/BLEU_summary_ecomm_en_de.json\n",
            "===================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL ERROR-PROOF EVALUATION SCRIPT (1500 TEST SAMPLES)\n",
        "# SigLIP + mBART + LoRA Fusion ‚Äî Evaluation Only\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast, MBartForConditionalGeneration,\n",
        "    SiglipVisionModel, SiglipProcessor\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "OUT_DIR = Path(BASE) / \"ecomm_french_finetuned\"\n",
        "\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "IMG_DIR = Path(\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/images\"\n",
        ")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load(img_name):\n",
        "    if not isinstance(img_name, str):\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = IMG_DIR / split / img_name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# LOAD EXACT 1500 TEST SAMPLES (FROM FIRST 7500 ONLY)\n",
        "# ================================================================\n",
        "def load_french_test_set():\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "    print(\"\\nColumns in dataset:\", df.columns.tolist())\n",
        "\n",
        "    if \"french\" not in df.columns:\n",
        "        raise ValueError(\"‚ùå ERROR: 'french' column NOT found in dataset!\")\n",
        "\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # First 7500 rows only\n",
        "    df = df.iloc[:7500].reset_index(drop=True)\n",
        "    print(\"Usable rows (first 7500):\", len(df))\n",
        "\n",
        "    # Shuffle\n",
        "    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Last 1500 = test\n",
        "    test_df = df.tail(1500).reset_index(drop=True)\n",
        "    print(\"Loaded test size:\", len(test_df))\n",
        "\n",
        "    return test_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=d_model,\n",
        "                nhead=8,\n",
        "                dim_feedforward=2048,\n",
        "                dropout=0.1,\n",
        "                batch_first=True\n",
        "            ),\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        x = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        return self.enc(x)\n",
        "\n",
        "\n",
        "class SiglipFusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Vision encoder\n",
        "        self.vision = SiglipVisionModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # mBART + LoRA\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.txt_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION FUNCTION (FIXED BLEU)\n",
        "# ================================================================\n",
        "def evaluate_french(src, tgt, test_df):\n",
        "\n",
        "    print(f\"\\nüîç Evaluating {src} ‚Üí {tgt} on {len(test_df)} samples\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}.pt\"\n",
        "    print(\"Loading finetuned model:\", ckpt)\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, srcs, imgs = [], [], [], []\n",
        "\n",
        "    for idx in tqdm(range(len(test_df))):\n",
        "        row = test_df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"french\"])\n",
        "        img_file = row[\"image_file\"]\n",
        "\n",
        "        # Direction\n",
        "        src_text = en if src == \"en\" else fr\n",
        "        tgt_text = fr if tgt == \"fr\" else en\n",
        "\n",
        "        refs.append(str(tgt_text))\n",
        "        srcs.append(src_text)\n",
        "        imgs.append(img_file)\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        # Process image\n",
        "        img = safe_load(img_file)\n",
        "        pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            v = model.vision(pixel).last_hidden_state[:, 0, :]\n",
        "            img_e = model.proj(v).unsqueeze(1)\n",
        "\n",
        "            txt_e = model.txt_emb(enc[\"input_ids\"])\n",
        "\n",
        "            fused = model.fusion(img_e, txt_e)\n",
        "            fused_mask = torch.cat(\n",
        "                [torch.ones((1, 1), device=device), enc[\"attention_mask\"]],\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            gen = model.mbart.generate(\n",
        "                inputs_embeds=fused,\n",
        "                attention_mask=fused_mask,\n",
        "                num_beams=5,\n",
        "                max_length=64,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        preds.append(tokenizer.decode(gen[0], skip_special_tokens=True))\n",
        "\n",
        "    # ============================================================\n",
        "    # DEBUG COUNTS\n",
        "    # ============================================================\n",
        "    print(\"\\nüîé DEBUG ‚Äî Prediction & Reference Counts\")\n",
        "    print(\"Pred count:\", len(preds))\n",
        "    print(\"Ref count: \", len(refs))\n",
        "\n",
        "    # ============================================================\n",
        "    # ‚≠ê FIXED BLEU ‚Äî WRAP REFS PROPERLY\n",
        "    # ============================================================\n",
        "    wrapped_refs = [[r] for r in refs]   # <-- THE FIX\n",
        "\n",
        "    bleu = sacrebleu.compute(\n",
        "        predictions=preds,\n",
        "        references=wrapped_refs\n",
        "    )[\"score\"]\n",
        "\n",
        "    print(f\"\\n‚≠ê BLEU ({src} ‚Üí {tgt}) = {bleu}\")\n",
        "\n",
        "    # Save results\n",
        "    out_file = OUT_DIR / f\"preds_{src}_{tgt}_1500.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": srcs,\n",
        "        \"gold\": refs,\n",
        "        \"pred\": preds,\n",
        "        \"image_file\": imgs\n",
        "    }).to_csv(out_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved predictions ‚Üí\", out_file)\n",
        "    return bleu\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "\n",
        "test_df = load_french_test_set()\n",
        "\n",
        "evaluate_french(\"en\", \"fr\", test_df)\n",
        "evaluate_french(\"fr\", \"en\", test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O86xmtL16ZC",
        "outputId": "36f91192-64b0-497f-c5d8-1de72c69b064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n",
            "\n",
            "Columns in dataset: ['project_name', 'set_name', 'image_id', 'image_file', 'source', 'target', 'french']\n",
            "Usable rows (first 7500): 7500\n",
            "Loaded test size: 1500\n",
            "\n",
            "üîç Evaluating en ‚Üí fr on 1500 samples\n",
            "Loading finetuned model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [15:46<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê BLEU (en ‚Üí fr) = 32.086293476649935\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/preds_en_fr_1500.tsv\n",
            "\n",
            "üîç Evaluating fr ‚Üí en on 1500 samples\n",
            "Loading finetuned model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [13:50<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê BLEU (fr ‚Üí en) = 31.07808077842777\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/preds_fr_en_1500.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.07808077842777"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL ERROR-PROOF EVALUATION SCRIPT (1500 TEST SAMPLES)\n",
        "# SigLIP + mBART + LoRA Fusion ‚Äî Evaluation Only\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast, MBartForConditionalGeneration,\n",
        "    SiglipVisionModel, SiglipProcessor\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "OUT_DIR = Path(BASE) / \"ecomm_french_finetuned\"\n",
        "\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "IMG_DIR = Path(\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/images\"\n",
        ")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADER\n",
        "# ================================================================\n",
        "def safe_load(img_name):\n",
        "    if not isinstance(img_name, str):\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = IMG_DIR / split / img_name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# LOAD EXACT 1500 TEST SAMPLES (FROM FIRST 7500 ONLY)\n",
        "# ================================================================\n",
        "def load_french_test_set():\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "    print(\"\\nColumns in dataset:\", df.columns.tolist())\n",
        "\n",
        "    if \"french\" not in df.columns:\n",
        "        raise ValueError(\"‚ùå ERROR: 'french' column NOT found in dataset!\")\n",
        "\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # First 7500 rows only\n",
        "    df = df.iloc[:7500].reset_index(drop=True)\n",
        "    print(\"Usable rows (first 7500):\", len(df))\n",
        "\n",
        "    # Shuffle\n",
        "    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Last 1500 = test\n",
        "    test_df = df.head(1500).reset_index(drop=True)\n",
        "    print(\"Loaded test size:\", len(test_df))\n",
        "\n",
        "    return test_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "\n",
        "class FusionBlock(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.enc = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=d_model,\n",
        "                nhead=8,\n",
        "                dim_feedforward=2048,\n",
        "                dropout=0.1,\n",
        "                batch_first=True\n",
        "            ),\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        x = torch.cat([img_emb, txt_emb], dim=1)\n",
        "        return self.enc(x)\n",
        "\n",
        "\n",
        "class SiglipFusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Vision encoder\n",
        "        self.vision = SiglipVisionModel.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # mBART + LoRA\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.txt_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION FUNCTION (FIXED BLEU)\n",
        "# ================================================================\n",
        "def evaluate_french(src, tgt, test_df):\n",
        "\n",
        "    print(f\"\\nüîç Evaluating {src} ‚Üí {tgt} on {len(test_df)} samples\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}.pt\"\n",
        "    print(\"Loading finetuned model:\", ckpt)\n",
        "\n",
        "    model = SiglipFusionModel().to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, srcs, imgs = [], [], [], []\n",
        "\n",
        "    for idx in tqdm(range(len(test_df))):\n",
        "        row = test_df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"french\"])\n",
        "        img_file = row[\"image_file\"]\n",
        "\n",
        "        # Direction\n",
        "        src_text = en if src == \"en\" else fr\n",
        "        tgt_text = fr if tgt == \"fr\" else en\n",
        "\n",
        "        refs.append(str(tgt_text))\n",
        "        srcs.append(src_text)\n",
        "        imgs.append(img_file)\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        # Process image\n",
        "        img = safe_load(img_file)\n",
        "        pixel = processor(images=[img], return_tensors=\"pt\")[\"pixel_values\"].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            v = model.vision(pixel).last_hidden_state[:, 0, :]\n",
        "            img_e = model.proj(v).unsqueeze(1)\n",
        "\n",
        "            txt_e = model.txt_emb(enc[\"input_ids\"])\n",
        "\n",
        "            fused = model.fusion(img_e, txt_e)\n",
        "            fused_mask = torch.cat(\n",
        "                [torch.ones((1, 1), device=device), enc[\"attention_mask\"]],\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "            gen = model.mbart.generate(\n",
        "                inputs_embeds=fused,\n",
        "                attention_mask=fused_mask,\n",
        "                num_beams=5,\n",
        "                max_length=64,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        preds.append(tokenizer.decode(gen[0], skip_special_tokens=True))\n",
        "\n",
        "    # ============================================================\n",
        "    # DEBUG COUNTS\n",
        "    # ============================================================\n",
        "    print(\"\\nüîé DEBUG ‚Äî Prediction & Reference Counts\")\n",
        "    print(\"Pred count:\", len(preds))\n",
        "    print(\"Ref count: \", len(refs))\n",
        "\n",
        "    # ============================================================\n",
        "    # ‚≠ê FIXED BLEU ‚Äî WRAP REFS PROPERLY\n",
        "    # ============================================================\n",
        "    wrapped_refs = [[r] for r in refs]   # <-- THE FIX\n",
        "\n",
        "    bleu = sacrebleu.compute(\n",
        "        predictions=preds,\n",
        "        references=wrapped_refs\n",
        "    )[\"score\"]\n",
        "\n",
        "    print(f\"\\n‚≠ê BLEU ({src} ‚Üí {tgt}) = {bleu}\")\n",
        "\n",
        "    # Save results\n",
        "    out_file = OUT_DIR / f\"preds_{src}_{tgt}_1500.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": srcs,\n",
        "        \"gold\": refs,\n",
        "        \"pred\": preds,\n",
        "        \"image_file\": imgs\n",
        "    }).to_csv(out_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved predictions ‚Üí\", out_file)\n",
        "    return bleu\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "processor = SiglipProcessor.from_pretrained(\"google/siglip-base-patch16-224\")\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "\n",
        "test_df = load_french_test_set()\n",
        "\n",
        "evaluate_french(\"en\", \"fr\", test_df)\n",
        "evaluate_french(\"fr\", \"en\", test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsIAG80WEMVQ",
        "outputId": "05389366-e4b1-41c0-9227-d956d1c70922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n",
            "\n",
            "Columns in dataset: ['project_name', 'set_name', 'image_id', 'image_file', 'source', 'target', 'french']\n",
            "Usable rows (first 7500): 7500\n",
            "Loaded test size: 1500\n",
            "\n",
            "üîç Evaluating en ‚Üí fr on 1500 samples\n",
            "Loading finetuned model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [15:41<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê BLEU (en ‚Üí fr) = 49.444148843245\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/preds_en_fr_1500.tsv\n",
            "\n",
            "üîç Evaluating fr ‚Üí en on 1500 samples\n",
            "Loading finetuned model: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/ecomm_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [13:46<00:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê BLEU (fr ‚Üí en) = 42.289458052779175\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_finetuned/preds_fr_en_1500.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.289458052779175"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKFpZj6JqLaS",
        "outputId": "39d52b3c-e447-4ea0-f21a-51ac8acc7a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== EVALUATING MM en->de ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [04:25<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, mm): 20.31750199975862\n",
            "\n",
            "====== EVALUATING TXT en->de ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:56<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, txt): 20.19394399919782\n",
            "\n",
            "====== EVALUATING MM de->en ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:50<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, mm): 21.885141269601355\n",
            "\n",
            "====== EVALUATING TXT de->en ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:41<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, txt): 22.135581100657067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FIXED EVALUATION SCRIPT ‚Äî BLEU MISMATCH SOLVED FOREVER (EN <-> DE)\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import MBart50TokenizerFast, SiglipProcessor\n",
        "from transformers import MBartForConditionalGeneration, SiglipVisionModel\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# ================================================================\n",
        "# CONSTANTS\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\"}\n",
        "\n",
        "MAX_LEN = 64\n",
        "TEST_LIMIT = 1500  # <= change this to 1500 for full test\n",
        "\n",
        "VISION_MODEL_NAME = \"google/siglip-base-patch16-224\"\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "CKPT_DIR = Path(BASE_DIR) / \"ecomm_finetuned\"\n",
        "\n",
        "ECOMM_TSV = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv\"\n",
        ")\n",
        "\n",
        "IMG_ROOT = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADING\n",
        "# ================================================================\n",
        "def safe_load_image(img_name):\n",
        "    \"\"\"Load image safely; return fallback image if missing.\"\"\"\n",
        "    if not isinstance(img_name, str) or img_name.strip() == \"\":\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    img_name = img_name.strip()\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = Path(IMG_ROOT) / split / img_name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# DATASET CLASS (CORRECTED: source = ENGLISH, target = GERMAN)\n",
        "# ================================================================\n",
        "class EcommDataset:\n",
        "    \"\"\"\n",
        "    Dataset wrapper:\n",
        "      English  = `source`\n",
        "      German   = `target`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt, limit=TEST_LIMIT):\n",
        "        df = pd.read_csv(ECOMM_TSV, sep=\"\\t\")\n",
        "\n",
        "        # Keep validation split\n",
        "        df = df[df[\"set_name\"].str.lower().isin([\"val\", \"valid\", \"validation\"])]\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "        if len(df) > limit:\n",
        "            df = df.iloc[:limit]\n",
        "\n",
        "        self.df = df\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "        print(f\"Evaluation samples loaded: {len(df)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "\n",
        "        en = str(row[\"source\"])   # English\n",
        "        de = str(row[\"target\"])   # German\n",
        "\n",
        "        # Choose direction\n",
        "        src_text = en if self.src == \"en\" else de\n",
        "        tgt_text = de if self.tgt == \"de\" else en\n",
        "\n",
        "        return {\n",
        "            \"src\": src_text,\n",
        "            \"tgt\": tgt_text,\n",
        "            \"img\": row[\"image_file\"]\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "def apply_lora(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=\"SEQ_2_SEQ_LM\",\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "\n",
        "class FusionBlock(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = torch.nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = torch.nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        return self.encoder(torch.cat([img_emb, txt_emb], dim=1))\n",
        "\n",
        "\n",
        "class MultiModalModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(VISION_MODEL_NAME)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = torch.nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel_values, tokenizer):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_emb = self.proj(vis).unsqueeze(1)\n",
        "        txt_emb = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_emb, txt_emb)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0), 1), device=device), mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "\n",
        "\n",
        "class TextOnlyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tokenizer):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION (BLEU FIXED)\n",
        "# ================================================================\n",
        "def evaluate_one(src, tgt, model_type, tokenizer, processor):\n",
        "    print(f\"\\n====== EVALUATING {model_type.upper()} {src}->{tgt} ======\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ds = EcommDataset(src, tgt, limit=TEST_LIMIT)\n",
        "\n",
        "    # Load model + checkpoint\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_txt.pt\"\n",
        "\n",
        "    print(\"Loading checkpoint:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs = [], []\n",
        "\n",
        "    for i in tqdm(range(len(ds))):\n",
        "        sample = ds[i]\n",
        "\n",
        "        tgt_clean = str(sample[\"tgt\"]).strip().replace(\"\\n\", \" \")\n",
        "        refs.append(tgt_clean)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            sample[\"src\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        if model_type == \"mm\":\n",
        "            img = safe_load_image(sample[\"img\"])\n",
        "            pixel = processor(images=[img], return_tensors=\"pt\")[\n",
        "                \"pixel_values\"\n",
        "            ].to(device)\n",
        "            out = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], pixel, tokenizer)\n",
        "        else:\n",
        "            out = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer)\n",
        "\n",
        "        pred = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "        preds.append(pred.strip())\n",
        "\n",
        "    # CLEAN OUTPUT FOR BLEU\n",
        "    preds = [p.strip() for p in preds]\n",
        "    refs = [r.strip() for r in refs]\n",
        "\n",
        "    references = [[r] for r in refs]\n",
        "\n",
        "    print(\"Final Pred Count:\", len(preds))\n",
        "    print(\"Final Ref Count :\", len(references))\n",
        "\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=references)[\"score\"]\n",
        "\n",
        "    print(f\"‚≠ê BLEU SCORE ({src} ‚Üí {tgt}, {model_type}):\", bleu)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "processor = SiglipProcessor.from_pretrained(VISION_MODEL_NAME)\n",
        "\n",
        "# Multimodal + Text-only, both directions\n",
        "evaluate_one(\"en\", \"de\", \"mm\", tokenizer, processor)\n",
        "evaluate_one(\"en\", \"de\", \"txt\", tokenizer, processor)\n",
        "\n",
        "evaluate_one(\"de\", \"en\", \"mm\", tokenizer, processor)\n",
        "evaluate_one(\"de\", \"en\", \"txt\", tokenizer, processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdoeXRaZsqge",
        "outputId": "75bdffa8-f703-4562-fa52-dde9b4f003c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== EVALUATING MM en->de ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [03:03<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, mm): 38.317652582244285\n",
            "\n",
            "====== EVALUATING TXT en->de ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:53<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, txt): 35.821675907249606\n",
            "\n",
            "====== EVALUATING MM de->en ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:49<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, mm): 45.94036035099213\n",
            "\n",
            "====== EVALUATING TXT de->en ======\n",
            "Evaluation samples loaded: 300\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [02:41<00:00,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 300\n",
            "Final Ref Count : 300\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, txt): 45.153433337371354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FIXED EVALUATION SCRIPT ‚Äî BLEU MISMATCH SOLVED FOREVER (EN <-> DE)\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import MBart50TokenizerFast, SiglipProcessor\n",
        "from transformers import MBartForConditionalGeneration, SiglipVisionModel\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "# ================================================================\n",
        "# CONSTANTS\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"de\": \"de_DE\"}\n",
        "\n",
        "MAX_LEN = 64\n",
        "TEST_LIMIT = 1500  # <= change this to 1500 for full test\n",
        "\n",
        "VISION_MODEL_NAME = \"google/siglip-base-patch16-224\"\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "CKPT_DIR = Path(BASE_DIR) / \"ecomm_finetuned\"\n",
        "\n",
        "ECOMM_TSV = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de.tsv\"\n",
        ")\n",
        "\n",
        "IMG_ROOT = \"/content/drive/MyDrive/dataset/ImageGuidedTranslationDataset-main/dataset/images\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# SAFE IMAGE LOADING\n",
        "# ================================================================\n",
        "def safe_load_image(img_name):\n",
        "    \"\"\"Load image safely; return fallback image if missing.\"\"\"\n",
        "    if not isinstance(img_name, str) or img_name.strip() == \"\":\n",
        "        return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    img_name = img_name.strip()\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        fp = Path(IMG_ROOT) / split / img_name\n",
        "        if fp.exists():\n",
        "            try:\n",
        "                return Image.open(fp).convert(\"RGB\")\n",
        "            except:\n",
        "                return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "    return Image.new(\"RGB\", (224,224), (128,128,128))\n",
        "\n",
        "# ================================================================\n",
        "# DATASET CLASS (CORRECTED: source = ENGLISH, target = GERMAN)\n",
        "# ================================================================\n",
        "class EcommDataset:\n",
        "    \"\"\"\n",
        "    Dataset wrapper:\n",
        "      English  = `source`\n",
        "      German   = `target`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, src, tgt, limit=TEST_LIMIT):\n",
        "        df = pd.read_csv(ECOMM_TSV, sep=\"\\t\")\n",
        "\n",
        "        # Keep validation split\n",
        "        df = df[df[\"set_name\"].str.lower().isin([\"val\", \"valid\", \"validation\"])]\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "        if len(df) > limit:\n",
        "            df = df.iloc[:limit]\n",
        "\n",
        "        self.df = df\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "        print(f\"Evaluation samples loaded: {len(df)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "\n",
        "        en = str(row[\"source\"])   # English\n",
        "        de = str(row[\"target\"])   # German\n",
        "\n",
        "        # Choose direction\n",
        "        src_text = en if self.src == \"en\" else de\n",
        "        tgt_text = de if self.tgt == \"de\" else en\n",
        "\n",
        "        return {\n",
        "            \"src\": src_text,\n",
        "            \"tgt\": tgt_text,\n",
        "            \"img\": row[\"image_file\"]\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITIONS\n",
        "# ================================================================\n",
        "def apply_lora(mbart):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=\"SEQ_2_SEQ_LM\",\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(mbart, cfg)\n",
        "\n",
        "\n",
        "class FusionBlock(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        layer = torch.nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.encoder = torch.nn.TransformerEncoder(layer, num_layers=1)\n",
        "\n",
        "    def forward(self, img_emb, txt_emb):\n",
        "        return self.encoder(torch.cat([img_emb, txt_emb], dim=1))\n",
        "\n",
        "\n",
        "class MultiModalModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.vision = SiglipVisionModel.from_pretrained(VISION_MODEL_NAME)\n",
        "        for p in self.vision.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "        self.text_emb = self.mbart.get_input_embeddings()\n",
        "\n",
        "        self.proj = torch.nn.Linear(768, self.mbart.config.d_model)\n",
        "        self.fusion = FusionBlock(self.mbart.config.d_model)\n",
        "\n",
        "    def generate(self, input_ids, mask, pixel_values, tokenizer):\n",
        "        with torch.no_grad():\n",
        "            vis = self.vision(pixel_values=pixel_values).last_hidden_state[:, 0, :]\n",
        "\n",
        "        img_emb = self.proj(vis).unsqueeze(1)\n",
        "        txt_emb = self.text_emb(input_ids)\n",
        "\n",
        "        fused = self.fusion(img_emb, txt_emb)\n",
        "        fused_mask = torch.cat(\n",
        "            [torch.ones((input_ids.size(0), 1), device=device), mask],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        return self.mbart.generate(\n",
        "            inputs_embeds=fused,\n",
        "            attention_mask=fused_mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "\n",
        "\n",
        "class TextOnlyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(base)\n",
        "\n",
        "    def generate(self, input_ids, mask, tokenizer):\n",
        "        return self.mbart.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=mask,\n",
        "            num_beams=5,\n",
        "            max_length=MAX_LEN,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n",
        "        )\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION (BLEU FIXED)\n",
        "# ================================================================\n",
        "def evaluate_one(src, tgt, model_type, tokenizer, processor):\n",
        "    print(f\"\\n====== EVALUATING {model_type.upper()} {src}->{tgt} ======\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ds = EcommDataset(src, tgt, limit=TEST_LIMIT)\n",
        "\n",
        "    # Load model + checkpoint\n",
        "    if model_type == \"mm\":\n",
        "        model = MultiModalModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_mm.pt\"\n",
        "    else:\n",
        "        model = TextOnlyModel().to(device)\n",
        "        ckpt = CKPT_DIR / f\"ecomm_{src}_{tgt}_txt.pt\"\n",
        "\n",
        "    print(\"Loading checkpoint:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs = [], []\n",
        "\n",
        "    for i in tqdm(range(len(ds))):\n",
        "        sample = ds[i]\n",
        "\n",
        "        tgt_clean = str(sample[\"tgt\"]).strip().replace(\"\\n\", \" \")\n",
        "        refs.append(tgt_clean)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            sample[\"src\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        if model_type == \"mm\":\n",
        "            img = safe_load_image(sample[\"img\"])\n",
        "            pixel = processor(images=[img], return_tensors=\"pt\")[\n",
        "                \"pixel_values\"\n",
        "            ].to(device)\n",
        "            out = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], pixel, tokenizer)\n",
        "        else:\n",
        "            out = model.generate(enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer)\n",
        "\n",
        "        pred = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "        preds.append(pred.strip())\n",
        "\n",
        "    # CLEAN OUTPUT FOR BLEU\n",
        "    preds = [p.strip() for p in preds]\n",
        "    refs = [r.strip() for r in refs]\n",
        "\n",
        "    references = [[r] for r in refs]\n",
        "\n",
        "    print(\"Final Pred Count:\", len(preds))\n",
        "    print(\"Final Ref Count :\", len(references))\n",
        "\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=references)[\"score\"]\n",
        "\n",
        "    print(f\"‚≠ê BLEU SCORE ({src} ‚Üí {tgt}, {model_type}):\", bleu)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "processor = SiglipProcessor.from_pretrained(VISION_MODEL_NAME)\n",
        "\n",
        "# Multimodal + Text-only, both directions\n",
        "evaluate_one(\"en\", \"de\", \"mm\", tokenizer, processor)\n",
        "evaluate_one(\"en\", \"de\", \"txt\", tokenizer, processor)\n",
        "\n",
        "evaluate_one(\"de\", \"en\", \"mm\", tokenizer, processor)\n",
        "evaluate_one(\"de\", \"en\", \"txt\", tokenizer, processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgl5Qt2ytDQ8",
        "outputId": "d7b2beaf-998b-48db-88e8-e56145206de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== EVALUATING MM en->de ======\n",
            "Evaluation samples loaded: 1500\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [20:43<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 1500\n",
            "Final Ref Count : 1500\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, mm): 37.32377458033243\n",
            "\n",
            "====== EVALUATING TXT en->de ======\n",
            "Evaluation samples loaded: 1500\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_de_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [14:37<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 1500\n",
            "Final Ref Count : 1500\n",
            "‚≠ê BLEU SCORE (en ‚Üí de, txt): 35.98922332352579\n",
            "\n",
            "====== EVALUATING MM de->en ======\n",
            "Evaluation samples loaded: 1500\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_mm.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [14:20<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 1500\n",
            "Final Ref Count : 1500\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, mm): 45.38777071440199\n",
            "\n",
            "====== EVALUATING TXT de->en ======\n",
            "Evaluation samples loaded: 1500\n",
            "Loading checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_de_en_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [13:35<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Pred Count: 1500\n",
            "Final Ref Count : 1500\n",
            "‚≠ê BLEU SCORE (de ‚Üí en, txt): 44.2543981919643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL ERROR-PROOF TEXT-ONLY EVALUATION SCRIPT (1500 TEST SAMPLES)\n",
        "# mBART + LoRA ‚Äî TEXT ONLY ‚Äî NO IMAGES\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from PIL import Image\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "OUT_DIR = Path(BASE) / \"ecomm_french_finetuned\"\n",
        "\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# LOAD EXACT 1500 TEST SAMPLES FROM FIRST 7500\n",
        "# ================================================================\n",
        "def load_french_test_set():\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "    print(\"\\nColumns in dataset:\", df.columns.tolist())\n",
        "\n",
        "    if \"french\" not in df.columns:\n",
        "        raise ValueError(\"‚ùå ERROR: 'french' column NOT found!\")\n",
        "\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # First 7500 rows only\n",
        "    df = df.iloc[:7500].reset_index(drop=True)\n",
        "    print(\"Usable rows (first 7500):\", len(df))\n",
        "\n",
        "    # Shuffle\n",
        "    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Last 1500 = test\n",
        "    test_df = df.tail(1500).reset_index(drop=True)\n",
        "    print(\"Loaded test size:\", len(test_df))\n",
        "    return test_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# TEXT-ONLY MODEL LOADER\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "\n",
        "class MBartTextOnly(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.model = apply_lora(base)\n",
        "\n",
        "    def generate_text(self, input_ids, attention_mask, tokenizer):\n",
        "        return self.model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            num_beams=5,\n",
        "            max_length=64,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION FUNCTION ‚Äî TEXT ONLY\n",
        "# ================================================================\n",
        "def evaluate_french_text(src, tgt, test_df):\n",
        "\n",
        "    print(f\"\\nüîç Evaluating TEXT-ONLY {src} ‚Üí {tgt} on {len(test_df)} samples\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"ecomm_{src}_{tgt}_txt.pt\"\n",
        "    print(\"Loading TEXT-ONLY checkpoint:\", ckpt)\n",
        "\n",
        "    model = MBartTextOnly().to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, srcs = [], [], []\n",
        "\n",
        "    for idx in tqdm(range(len(test_df))):\n",
        "        row = test_df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"french\"])\n",
        "\n",
        "        # Direction\n",
        "        src_text = en if src == \"en\" else fr\n",
        "        tgt_text = fr if tgt == \"fr\" else en\n",
        "\n",
        "        refs.append(tgt_text)\n",
        "        srcs.append(src_text)\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gen = model.generate_text(\n",
        "                enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "\n",
        "    print(\"\\nüîé DEBUG ‚Äî Prediction & Reference Counts\")\n",
        "    print(\"Pred count:\", len(preds))\n",
        "    print(\"Ref count: \", len(refs))\n",
        "\n",
        "    # BLEU requires list[list[str]]\n",
        "    wrapped_refs = [[r] for r in refs]\n",
        "\n",
        "    bleu = sacrebleu.compute(\n",
        "        predictions=preds,\n",
        "        references=wrapped_refs\n",
        "    )[\"score\"]\n",
        "\n",
        "    print(f\"\\n‚≠ê TEXT-ONLY BLEU ({src} ‚Üí {tgt}) = {bleu}\")\n",
        "\n",
        "    # Save predictions\n",
        "    out_file = OUT_DIR / f\"preds_textonly_{src}_{tgt}_1500.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": srcs,\n",
        "        \"gold\": refs,\n",
        "        \"pred\": preds,\n",
        "    }).to_csv(out_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved TEXT-ONLY predictions ‚Üí\", out_file)\n",
        "    return bleu\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "\n",
        "test_df = load_french_test_set()\n",
        "\n",
        "evaluate_french_text(\"en\", \"fr\", test_df)\n",
        "evaluate_french_text(\"fr\", \"en\", test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851,
          "referenced_widgets": [
            "eace40d796b1496184b9e256b0f5ff58",
            "683f283f15a54975b8068831a34b63e8",
            "eba0d010b09d4b17a0a592d192fefb67",
            "2923c1ebbff8425ca76f365e4a9a8ab5",
            "cdedf8f59d9b4973a5a64e62634f1d62",
            "e166b4ba63cf426aa0c35d767419d496",
            "595504dafce84302bf2a187f8cb4cab0",
            "0f8d704da73040ca98f7745373bb3283",
            "b66ce8abac1e402b8c20a96588c25ba4",
            "9eeef73edac346e3ba76aa795c48a011",
            "25ce6dac042245e5895d22d61d3b0024",
            "e1c148e40ef94b249cfa3e3c4f181448",
            "ae5f109a13004ab1b10f2969449e6050",
            "d49c98f5e4fc4df196ca8518ca35b019",
            "047525958d5e44fc83da915051fe7622",
            "44aa552ad86c4f05a01d56816bff0cb4",
            "19d51f726c2f4642bb7d911f07efcc1a",
            "59e61726b7ee4fa48fa15df134f704fe",
            "16c01af05e914d2191fac56a95d455ab",
            "f6da6279ee2f45ec8e81fee8342dfec6",
            "2d6aed2abfa24ddaa6d9691307457f41",
            "90c05a13a3c7464794f67b6495d60a23",
            "ebbf542bd7474cb3a3aaa53c185f0826",
            "5f7d6c0b9749453ab9dde7924e1c612f",
            "679ffac103aa4add8cc5339a2c23f498",
            "959a78963d8842f388670c9e1aae824c",
            "efad8f6e7e7548b0a2e5a38780d6ff42",
            "54a7819e493542bab160d146ba72fa44",
            "c19069b47d5448d98e0e43bd2a9d59e9",
            "d0d1f142890d44329877a956d4986ea9",
            "b7d97ffa0abc4cb2a313d3e3f3b940ab",
            "28491f4453f043be89d0f8077a9ef576",
            "94871188327e44fcb5bfc76371112299",
            "5b381cf7e884430c8412e8df5d9e33a6",
            "f760e8cb131349ac92bc93553f1c7574",
            "e75aca5ac1a94752ba75882bbb5a0d4b",
            "48a0af3674d34a0f8132bfcc12c83448",
            "650b8dbc46e341adac58be59acebf4dd",
            "de3ce9408c5342b684ccff80b730ee2f",
            "208f8d0dbda445dc8cd5dccbfaced4c7",
            "4d2ea420d92a4012ab0909acec025ede",
            "9b84c4e31e6f444896cd46a763af3467",
            "2f7b7158071d4bb3adc6a358b6f89c26",
            "b08aff255bad4c83b8dec98c5f0030b9",
            "43ec7a5235b64120a959411ea7691a6f",
            "e15b388c2b284d01b09fe74e76429e86",
            "795c4b755e714de0903584a0495b00fa",
            "ac21efc6674745a69f2d26d56aa314e4",
            "fe908d82d1814a12b1641cec37776c00",
            "aaef1a9a980346678b89dd7225785fd5",
            "9f98853077dd44398a117ceffa1b5b76",
            "07d8906a388c4f4ab220dc75abcc6147",
            "8d954cad081b4c16bd64006f0556a593",
            "5bb2773583304b0297006a8e887055f0",
            "92e0755372244b9497ddb5d778902bc5",
            "f91a9b35beae4da989cb147e53a171ed",
            "7eb62fd65cac4fc3b4f9e662cdc2d9c0",
            "3fcf7bd3b5194c19805f56409c8c497e",
            "fbefa02c4cfd418f85b7a630394f23d4",
            "784e3f0d0c414eda92f78aeac60a0d85",
            "a5b73824c62f4e90bd60471939d04525",
            "5b31330ebaeb456398c50d6c51cafde7",
            "7684eedb95ff4dacad4ced3c1e15b669",
            "15837c271aee43e4b6b1df94cdd312e6",
            "5a8e3d431071488f947553436063054e",
            "ee7fc3632d2945c193a87bbcbeb8d81a",
            "8b6bb771c3184ed9a9aa936ddcc47130",
            "2a972c9f86e34d4bbf1fa609cf73e42f",
            "521ba5683e9e49a49a9a5ac69c6757d6",
            "0b83fa1701504fba895aa59569f691e4",
            "0139e25e63db497781c06b1f5f05f29d",
            "afd3c74d56e04fe2b5d0e365eb341ecf",
            "9a0d43501b2544b393b3de39689181d6",
            "c186ac99572b4306a0365554eb026995",
            "9743bae6a9b547368de2765a8cd89915",
            "2e7753cf5b014bfbaec55f651f8967af",
            "139d08a797854e43bd9c0f4fde9c0f2c"
          ]
        },
        "id": "mIVjcS9I0wt8",
        "outputId": "0f4a834c-7259-47d9-83df-c0c949572350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eace40d796b1496184b9e256b0f5ff58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c148e40ef94b249cfa3e3c4f181448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebbf542bd7474cb3a3aaa53c185f0826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b381cf7e884430c8412e8df5d9e33a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43ec7a5235b64120a959411ea7691a6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns in dataset: ['project_name', 'set_name', 'image_id', 'image_file', 'source', 'target', 'french']\n",
            "Usable rows (first 7500): 7500\n",
            "Loaded test size: 1500\n",
            "\n",
            "üîç Evaluating TEXT-ONLY en ‚Üí fr on 1500 samples\n",
            "Loading TEXT-ONLY checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_en_fr_txt.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f91a9b35beae4da989cb147e53a171ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b6bb771c3184ed9a9aa936ddcc47130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [14:43<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê TEXT-ONLY BLEU (en ‚Üí fr) = 17.79124277319568\n",
            "Saved TEXT-ONLY predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/preds_textonly_en_fr_1500.tsv\n",
            "\n",
            "üîç Evaluating TEXT-ONLY fr ‚Üí en on 1500 samples\n",
            "Loading TEXT-ONLY checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/ecomm_fr_en_txt.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [13:15<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê TEXT-ONLY BLEU (fr ‚Üí en) = 20.96915203789267\n",
            "Saved TEXT-ONLY predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_finetuned/preds_textonly_fr_en_1500.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.96915203789267"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# üîÅ FINAL FULL TRAINING + EVALUATION SCRIPT FOR EN‚ÜîFR (TEXT-ONLY)\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import (\n",
        "    MBart50TokenizerFast,\n",
        "    MBartForConditionalGeneration\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# ================================================================\n",
        "# CONFIG\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "MAX_LEN = 64\n",
        "BATCH = 8\n",
        "LR = 2e-4\n",
        "EPOCHS = 6\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "MODEL_DIR = Path(BASE)\n",
        "OUT_DIR = MODEL_DIR / \"ecomm_french_text_only\"\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "# ================================================================\n",
        "# DATASET\n",
        "# ================================================================\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, src, tgt):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"french\"])\n",
        "\n",
        "        src_text = en if self.src == \"en\" else fr\n",
        "        tgt_text = fr if self.tgt == \"fr\" else en\n",
        "\n",
        "        return {\"src\": src_text, \"tgt\": tgt_text}\n",
        "\n",
        "# ================================================================\n",
        "# CREATE TRAIN/TEST SPLITS\n",
        "# ================================================================\n",
        "def load_french_splits(src, tgt):\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "\n",
        "    df = df[df[\"set_name\"].str.lower().isin([\"train\", \"test\"])]\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    train_df = df[df[\"set_name\"] == \"train\"]\n",
        "    test_df  = df[df[\"set_name\"] == \"test\"]\n",
        "\n",
        "    train_df = train_df.sample(min(6000, len(train_df)), random_state=42)\n",
        "    test_df  = test_df.sample(min(1500, len(test_df)), random_state=42)\n",
        "\n",
        "    print(f\"{src} ‚Üí {tgt}: Train={len(train_df)}, Test={len(test_df)}\")\n",
        "    return train_df, test_df\n",
        "\n",
        "# ================================================================\n",
        "# MODEL DEFINITION (TEXT ONLY)\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "class TextOnlyMT(nn.Module):\n",
        "    \"\"\" mBART + LoRA only (no images) \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mbart = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.mbart = apply_lora(self.mbart)\n",
        "\n",
        "    def forward(self, ids, mask, labels):\n",
        "        return self.mbart(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "# ================================================================\n",
        "# TOKENIZER + COLLATE\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        ")\n",
        "\n",
        "def collate(batch):\n",
        "    src = [b[\"src\"] for b in batch]\n",
        "    tgt = [b[\"tgt\"] for b in batch]\n",
        "\n",
        "    enc_s = tokenizer(\n",
        "        src, truncation=True, padding=\"max_length\",\n",
        "        max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        enc_t = tokenizer(\n",
        "            tgt, truncation=True, padding=\"max_length\",\n",
        "            max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    labels = enc_t[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return {\n",
        "        \"ids\": enc_s[\"input_ids\"].to(device),\n",
        "        \"mask\": enc_s[\"attention_mask\"].to(device),\n",
        "        \"labels\": labels.to(device)\n",
        "    }\n",
        "\n",
        "# ================================================================\n",
        "# TRAINING LOOP\n",
        "# ================================================================\n",
        "def train_text_model(src, tgt):\n",
        "    print(f\"\\nüî• Training TEXT-ONLY {src} ‚Üí {tgt}\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    train_df, test_df = load_french_splits(src, tgt)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        TextDataset(train_df, src, tgt),\n",
        "        batch_size=BATCH,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate\n",
        "    )\n",
        "    test_ds = TextDataset(test_df, src, tgt)\n",
        "\n",
        "    model = TextOnlyMT().to(device)\n",
        "    optim = torch.optim.AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=LR\n",
        "    )\n",
        "\n",
        "    best = 9999\n",
        "    save_path = OUT_DIR / f\"text_{src}_{tgt}.pt\"\n",
        "\n",
        "    for ep in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "            optim.zero_grad()\n",
        "            out = model(batch[\"ids\"], batch[\"mask\"], batch[\"labels\"])\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total += loss.item()\n",
        "\n",
        "        print(f\"Epoch {ep} Loss = {total/len(train_loader):.4f}\")\n",
        "\n",
        "        if total < best:\n",
        "            best = total\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"Saved best:\", save_path)\n",
        "\n",
        "    return test_ds\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION\n",
        "# ================================================================\n",
        "def evaluate_text(src, tgt, test_ds):\n",
        "    print(f\"\\nüîç Evaluating TEXT-ONLY {src} ‚Üí {tgt}\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    model = TextOnlyMT().to(device)\n",
        "    ckpt = OUT_DIR / f\"text_{src}_{tgt}.pt\"\n",
        "    print(\"Loading:\", ckpt)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, sources = [], [], []\n",
        "\n",
        "    for sample in tqdm(test_ds):\n",
        "        src_text = sample[\"src\"]\n",
        "        tgt_text = sample[\"tgt\"]\n",
        "\n",
        "        sources.append(src_text)\n",
        "        refs.append(tgt_text)\n",
        "\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gen = model.mbart.generate(\n",
        "                input_ids=enc[\"input_ids\"],\n",
        "                attention_mask=enc[\"attention_mask\"],\n",
        "                max_length=MAX_LEN,\n",
        "                num_beams=5,\n",
        "                forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "            )\n",
        "\n",
        "        preds.append(tokenizer.decode(gen[0], skip_special_tokens=True))\n",
        "\n",
        "    bleu = sacrebleu.compute(predictions=preds, references=[refs])[\"score\"]\n",
        "    print(f\"‚≠ê BLEU ({src} ‚Üí {tgt}) = {bleu:.4f}\")\n",
        "\n",
        "    pred_file = OUT_DIR / f\"preds_text_{src}_{tgt}.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": sources,\n",
        "        \"reference\": refs,\n",
        "        \"prediction\": preds,\n",
        "    }).to_csv(pred_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved:\", pred_file)\n",
        "    return bleu\n",
        "\n",
        "# ================================================================\n",
        "# RUN TRAINING + EVALUATION\n",
        "# ================================================================\n",
        "test_en_fr = train_text_model(\"en\", \"fr\")\n",
        "test_fr_en = train_text_model(\"fr\", \"en\")\n",
        "\n",
        "#evaluate_text(\"en\", \"fr\", test_en_fr)\n",
        "#evaluate_text(\"fr\", \"en\", test_fr_en)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDpr_j0WA_qL",
        "outputId": "b3246451-48b5-4c37-9cfe-b81d4a0cb3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n",
            "\n",
            "üî• Training TEXT-ONLY en ‚Üí fr\n",
            "en ‚Üí fr: Train=6000, Test=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/750 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss = 1.8541\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss = 1.6293\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss = 1.5011\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss = 1.4104\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss = 1.3316\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss = 1.2616\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n",
            "\n",
            "üî• Training TEXT-ONLY fr ‚Üí en\n",
            "fr ‚Üí en: Train=6000, Test=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/750 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss = 2.0173\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss = 1.8523\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss = 1.7547\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss = 1.6695\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss = 1.5947\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 750/750 [02:19<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss = 1.5291\n",
            "Saved best: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# FINAL ERROR-PROOF TEXT-ONLY EVALUATION SCRIPT (1500 TEST SAMPLES)\n",
        "# mBART + LoRA ‚Äî TEXT ONLY ‚Äî NO IMAGES\n",
        "# ================================================================\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "from transformers import MBart50TokenizerFast, MBartForConditionalGeneration\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from PIL import Image\n",
        "\n",
        "# ================================================================\n",
        "# DEVICE\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)\n",
        "\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# ================================================================\n",
        "# PATHS\n",
        "# ================================================================\n",
        "BASE = \"/content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion\"\n",
        "OUT_DIR = Path(BASE) / \"ecomm_french_text_only\"\n",
        "\n",
        "TSV_FILE = (\n",
        "    \"/content/drive/MyDrive/dataset/\"\n",
        "    \"ImageGuidedTranslationDataset-main/dataset/\"\n",
        "    \"listingtitle-image-mappings/listingtitles_with_matched_images.en-de_with_french.tsv\"\n",
        ")\n",
        "\n",
        "LANG_CODES = {\"en\": \"en_XX\", \"fr\": \"fr_XX\"}\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# LOAD EXACT 1500 TEST SAMPLES FROM FIRST 7500\n",
        "# ================================================================\n",
        "def load_french_test_set():\n",
        "    df = pd.read_csv(TSV_FILE, sep=\"\\t\")\n",
        "    print(\"\\nColumns in dataset:\", df.columns.tolist())\n",
        "\n",
        "    if \"french\" not in df.columns:\n",
        "        raise ValueError(\"‚ùå ERROR: 'french' column NOT found!\")\n",
        "\n",
        "    df = df.dropna(subset=[\"source\", \"french\"]).reset_index(drop=True)\n",
        "\n",
        "    # First 7500 rows only\n",
        "    df = df.iloc[:7500].reset_index(drop=True)\n",
        "    print(\"Usable rows (first 7500):\", len(df))\n",
        "\n",
        "    # Shuffle\n",
        "    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Last 1500 = test\n",
        "    test_df = df.tail(1500).reset_index(drop=True)\n",
        "    print(\"Loaded test size:\", len(test_df))\n",
        "    return test_df\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# TEXT-ONLY MODEL LOADER\n",
        "# ================================================================\n",
        "def apply_lora(model):\n",
        "    cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\", \"v_proj\"]\n",
        "    )\n",
        "    return get_peft_model(model, cfg)\n",
        "\n",
        "\n",
        "class MBartTextOnly(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = MBartForConditionalGeneration.from_pretrained(\n",
        "            \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "        )\n",
        "        self.model = apply_lora(base)\n",
        "\n",
        "    def generate_text(self, input_ids, attention_mask, tokenizer):\n",
        "        return self.model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            num_beams=5,\n",
        "            max_length=64,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
        "        )\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# EVALUATION FUNCTION ‚Äî TEXT ONLY\n",
        "# ================================================================\n",
        "def evaluate_french_text(src, tgt, test_df):\n",
        "\n",
        "    print(f\"\\nüîç Evaluating TEXT-ONLY {src} ‚Üí {tgt} on {len(test_df)} samples\")\n",
        "\n",
        "    tokenizer.src_lang = LANG_CODES[src]\n",
        "    tokenizer.tgt_lang = LANG_CODES[tgt]\n",
        "\n",
        "    ckpt = OUT_DIR / f\"text_{src}_{tgt}.pt\"\n",
        "    print(\"Loading TEXT-ONLY checkpoint:\", ckpt)\n",
        "\n",
        "    model = MBartTextOnly().to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device), strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, refs, srcs = [], [], []\n",
        "\n",
        "    for idx in tqdm(range(len(test_df))):\n",
        "        row = test_df.iloc[idx]\n",
        "\n",
        "        en = str(row[\"source\"])\n",
        "        fr = str(row[\"french\"])\n",
        "\n",
        "        # Direction\n",
        "        src_text = en if src == \"en\" else fr\n",
        "        tgt_text = fr if tgt == \"fr\" else en\n",
        "\n",
        "        refs.append(tgt_text)\n",
        "        srcs.append(src_text)\n",
        "\n",
        "        # Tokenize\n",
        "        enc = tokenizer(\n",
        "            src_text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=64,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gen = model.generate_text(\n",
        "                enc[\"input_ids\"], enc[\"attention_mask\"], tokenizer\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(gen[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "\n",
        "    print(\"\\nüîé DEBUG ‚Äî Prediction & Reference Counts\")\n",
        "    print(\"Pred count:\", len(preds))\n",
        "    print(\"Ref count: \", len(refs))\n",
        "\n",
        "    # BLEU requires list[list[str]]\n",
        "    wrapped_refs = [[r] for r in refs]\n",
        "\n",
        "    bleu = sacrebleu.compute(\n",
        "        predictions=preds,\n",
        "        references=wrapped_refs\n",
        "    )[\"score\"]\n",
        "\n",
        "    print(f\"\\n‚≠ê TEXT-ONLY BLEU ({src} ‚Üí {tgt}) = {bleu}\")\n",
        "\n",
        "    # Save predictions\n",
        "    out_file = OUT_DIR / f\"preds_textonly_{src}_{tgt}_1500.tsv\"\n",
        "    pd.DataFrame({\n",
        "        \"source\": srcs,\n",
        "        \"gold\": refs,\n",
        "        \"pred\": preds,\n",
        "    }).to_csv(out_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(\"Saved TEXT-ONLY predictions ‚Üí\", out_file)\n",
        "    return bleu\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# RUN EVALUATION\n",
        "# ================================================================\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "\n",
        "test_df = load_french_test_set()\n",
        "\n",
        "evaluate_french_text(\"en\", \"fr\", test_df)\n",
        "evaluate_french_text(\"fr\", \"en\", test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LG4yWi4XTxB",
        "outputId": "39b970ab-5bb0-4941-c831-a2e13160b826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n",
            "\n",
            "Columns in dataset: ['project_name', 'set_name', 'image_id', 'image_file', 'source', 'target', 'french']\n",
            "Usable rows (first 7500): 7500\n",
            "Loaded test size: 1500\n",
            "\n",
            "üîç Evaluating TEXT-ONLY en ‚Üí fr on 1500 samples\n",
            "Loading TEXT-ONLY checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_en_fr.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [14:28<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê TEXT-ONLY BLEU (en ‚Üí fr) = 17.79124277319568\n",
            "Saved TEXT-ONLY predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/preds_textonly_en_fr_1500.tsv\n",
            "\n",
            "üîç Evaluating TEXT-ONLY fr ‚Üí en on 1500 samples\n",
            "Loading TEXT-ONLY checkpoint: /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/text_fr_en.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [13:08<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé DEBUG ‚Äî Prediction & Reference Counts\n",
            "Pred count: 1500\n",
            "Ref count:  1500\n",
            "\n",
            "‚≠ê TEXT-ONLY BLEU (fr ‚Üí en) = 20.96915203789267\n",
            "Saved TEXT-ONLY predictions ‚Üí /content/drive/MyDrive/multimodal_translation_models_siglip_lora_fusion/ecomm_french_text_only/preds_textonly_fr_en_1500.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.96915203789267"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0s7cGUzrebyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1xbhzqLBztwVSIrRlw4vTDMPmobUPbFZB",
      "authorship_tag": "ABX9TyMMBVXc1EEZZXrw8mDu9zJj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0312c79425fa440cb31155f6cd3b26bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e809c6e1789e40f4bb2257576ff7a5ed",
              "IPY_MODEL_8102b2725c444e5c8c249e027363e07a",
              "IPY_MODEL_c91acd80da19416eb951e06acd891bb8"
            ],
            "layout": "IPY_MODEL_d43e6ad0227f4e499dda96d801ac522f"
          }
        },
        "0338ee6cd456495f927ac13794f74580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db1f76fbcc746e19f901f04e18c74fd",
            "max": 529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd5b46af47304638ba8226944e118f05",
            "value": 529
          }
        },
        "065f61de3fc84e9081c76e3447e97c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0677d631b1564ab796ae4dd1bf4009b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95930dd5efd443a862f2ec8ce584335",
              "IPY_MODEL_d292d6a4cf584056a4eb42a1f96e472b",
              "IPY_MODEL_f889d3f9bce84ab0a4be318141ba4762"
            ],
            "layout": "IPY_MODEL_7e12af3fbfe24cf28d050138aa0ed225"
          }
        },
        "068cb71c294c4a4abbd9980d9a131917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09648870a3c646c59ae2472f69322668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a77930da1944443885b3e1c8288d513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9503d756554b9aa6138a327f1559c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b98358bc84a45fdbeecadc1d9835fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f1c6d0881f84f27b080439464e54e2a",
              "IPY_MODEL_657f706698c349699b2b4197c9f7ea73",
              "IPY_MODEL_bf8ee0e4c19a43d1b03c28b3cb755a5c"
            ],
            "layout": "IPY_MODEL_ee4e47b7240a495b80d4d985cd9dbfa1"
          }
        },
        "0c72415451324987b78db9f98bd3e133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d89d17fe57f4dcbbcaa0707f7774e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7b26ef0f80340d982985bb7cf2b66ce",
              "IPY_MODEL_da50889622124fd191e30537ae832498",
              "IPY_MODEL_c8602548205e44d6af022ebb714e319e"
            ],
            "layout": "IPY_MODEL_c12c0935de0d421db904da033f8dc474"
          }
        },
        "1054ccffe4684952840169568a363f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1103b8ed1b9f4863a2640050b666ecb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a4f65fe18b4c75bca39eec8e1fd88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5955e99027d49e7b21f6acc1c4b65bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0b9503d756554b9aa6138a327f1559c5",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "13daf82f4e924cb68591cba902496d28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160260d58c944a9d8cab4291c26aecef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16738a350272410687e0771b846b8490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e31b7738b0948a2829fe53157595cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20a06c4ef4514dfaad4e4cce8104cf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e21158f1f77b49f6aa3b82602f73f070",
              "IPY_MODEL_f39024eda5b74e7081bed2f8720567a5",
              "IPY_MODEL_32d8ab1d835342acbf2f59df779696e0"
            ],
            "layout": "IPY_MODEL_f3f61afd46374557963f1106bed46958"
          }
        },
        "2269db8978d44eb09c76be8d15a27f83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24897badff594c26becefb450bb0dc32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265dc91599af4166a31a1e081cca5990": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2824da3b61f94192bfc730103b209e40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e4caa6d00e4d108addd6c449f9c180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f6aa45ab4664d5e8c3045731198d3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310915fc47a74b43917113d3df98dc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_955dec69ef66432bb14862b35bf3d0f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8aa1abddbcbc47cabc34189d59b75415",
            "value": "sentencepiece.bpe.model:‚Äá100%"
          }
        },
        "32d8ab1d835342acbf2f59df779696e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c72415451324987b78db9f98bd3e133",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_522f4ea7f4ca4f759abda3eff04dd532",
            "value": "‚Äá798k/798k‚Äá[00:01&lt;00:00,‚Äá141kB/s]"
          }
        },
        "3415cea7e11b47af8e297c8a3708f923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35dcaf345b6146ff945c1bcbdf3fa3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08037b7740a42679d18d8f09d8e1832",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9048856d0674347aa994e65ccce1dae",
            "value": "config.json:‚Äá100%"
          }
        },
        "37fd1d74a3354616a983369b3b391424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c64a53138cc44298e7b3afd772bbe70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db1f76fbcc746e19f901f04e18c74fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e77c084d6e74521a3c5e31dedd02382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40954e5acfbe41fbb684192d3018a42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13a4f65fe18b4c75bca39eec8e1fd88c",
              "IPY_MODEL_bdca8d2d36ac4560b54dc8fff17caf5c",
              "IPY_MODEL_f004b5964f0d4fb69060a727f94598b7"
            ],
            "layout": "IPY_MODEL_0a77930da1944443885b3e1c8288d513"
          }
        },
        "40a0568b23ed4f3db596c3fe9323ebca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4144ecce8fbc48fbb3efd497436b32ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45f2d438b0db494b838325d88387b30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4821421edf7e4a768b5fe498b897c469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c775586e9934efd8787817a0d0284f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1c6d0881f84f27b080439464e54e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24897badff594c26becefb450bb0dc32",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_29e4caa6d00e4d108addd6c449f9c180",
            "value": "config.json:‚Äá"
          }
        },
        "50747bcc68fc4c16af25d18fd9c010f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507a70dd03dd48658d1712296c440785": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522f4ea7f4ca4f759abda3eff04dd532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52daf14c1bde43f89f7902cc734be539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "538bc83886a641b9bff536a2f9c83d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_692f77351a3d43c6ba96311e9060505c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_40a0568b23ed4f3db596c3fe9323ebca",
            "value": "‚Äá261/261‚Äá[00:00&lt;00:00,‚Äá34.5kB/s]"
          }
        },
        "550abb6168d840b79ffdd27e9a357396": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5edabb58d2964ae9b526e5a43d93c053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b059f6e6d84a9bb85bef1f0568a13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6561c2f3d276439b9407d953585f9e82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6577d6b09d0943b388a5aedea0475d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3cb146b16d4d2aa11b0c2cfc36d16f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4821421edf7e4a768b5fe498b897c469",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "657f706698c349699b2b4197c9f7ea73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad347bf85ea4398aa6256d9c6fbfffe",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b62e2676869e4153af765e5c40aae712",
            "value": 1
          }
        },
        "65c428704bdd4951a4ca14a82ebe17d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "665fe121914d4f378b34efe28b0f7bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae5677c37bc47cc9b77388ad89159d7",
            "max": 261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dedfea2321644deaafc0f2277230273a",
            "value": 261
          }
        },
        "680cccbd456d44488fbabb8352382a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692f77351a3d43c6ba96311e9060505c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9e73c5b6be4349ac2762fa25695561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2269db8978d44eb09c76be8d15a27f83",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6d819e2ea45a43fd9af17995989b8c53",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "6bdd9d4deedc411cac127402388bd988": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eef52bca57984cafb36101d315d95a3a",
              "IPY_MODEL_8befc8d9ecce4ae28a22e23ae33438a9",
              "IPY_MODEL_cb5c42a1fab44429be7ac104e44ea6c7"
            ],
            "layout": "IPY_MODEL_b0abc34d3e384060be7a62d738c607a9"
          }
        },
        "6c7805aa83964361b88cbc53e62b5a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce0d9076f9a4b66a9de38a86b08b166",
              "IPY_MODEL_c6e334d4ac3d430eb59aca0325b14e4c",
              "IPY_MODEL_dae375b95ec94b00bf71b3039f55240e"
            ],
            "layout": "IPY_MODEL_507a70dd03dd48658d1712296c440785"
          }
        },
        "6ce0d9076f9a4b66a9de38a86b08b166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bffabc017f9d4566a9879a7c2654cf14",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b1c06764155e48f1b424c922ab95e2a3",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "6d819e2ea45a43fd9af17995989b8c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e4a9dc77658449ab5b440a9036c71fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6577d6b09d0943b388a5aedea0475d05",
              "IPY_MODEL_665fe121914d4f378b34efe28b0f7bdd",
              "IPY_MODEL_538bc83886a641b9bff536a2f9c83d29"
            ],
            "layout": "IPY_MODEL_160260d58c944a9d8cab4291c26aecef"
          }
        },
        "6fc309fd76824db1b42290f673151d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed07f7a399f941e09d7ac3f6c82cca6e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a22e20e410ee466b8ba7752fd20056be",
            "value": "‚Äá409/409‚Äá[00:00&lt;00:00,‚Äá57.6kB/s]"
          }
        },
        "701bb12af3574157957985dd03b4a881": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7284e5d040154be5a8213b43a285c7db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b24f4b6d954a8a83fdef7acb97ebaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b82781d977412cbe566d45115395b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d8c92b77d9423baf983c8f41cc6926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75faf4d3a34341269c46367dc3e93c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ee347eb1be4cbab3fa0d497bc7b772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ae5677c37bc47cc9b77388ad89159d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1f4c63a5404680b141380abca3707b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6ab5fd871d4683a71d84781f82c1df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e12af3fbfe24cf28d050138aa0ed225": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8102b2725c444e5c8c249e027363e07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb19e49cd2c24ceaa27cb30c8175a92e",
            "max": 368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1054ccffe4684952840169568a363f66",
            "value": 368
          }
        },
        "82c82362271c4a7480fc2d1259db162c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856b79b158254c44b4a2f2d9c345167e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8639027519094e8ba398d5de4356a43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c775586e9934efd8787817a0d0284f7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37fd1d74a3354616a983369b3b391424",
            "value": "‚Äá5.07M/5.07M‚Äá[00:01&lt;00:00,‚Äá2.64MB/s]"
          }
        },
        "88135b50a5ff43498a8927f47cdfbdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b9e73c5b6be4349ac2762fa25695561",
              "IPY_MODEL_dd44f8315b1f415da7f0658e01dd20a8",
              "IPY_MODEL_6fc309fd76824db1b42290f673151d7f"
            ],
            "layout": "IPY_MODEL_ea872156c37e446da3c118a344455965"
          }
        },
        "8aa1abddbcbc47cabc34189d59b75415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ad347bf85ea4398aa6256d9c6fbfffe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8befc8d9ecce4ae28a22e23ae33438a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee16cc853cd549af9c2bc275bf6210e1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3415cea7e11b47af8e297c8a3708f923",
            "value": 1
          }
        },
        "8ed14b43b00e4a728508936f103c642b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f0ca78958e5486a9ada4f1404c377a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da60ebf35b3045f6815bf4a95df4e5b3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_adfce349c8914d73aca98214755613d5",
            "value": "‚Äá529/529‚Äá[00:00&lt;00:00,‚Äá65.2kB/s]"
          }
        },
        "93611efa688640cbb9a4df5a2be51019": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cefe21bb1c4f2ca8a966bd796fa1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94bc683d342c4b69ac5d6e2769edf607": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09648870a3c646c59ae2472f69322668",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ebf65ed63cff47fc8cc481cb3464203f",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "955dec69ef66432bb14862b35bf3d0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a70470f6af4565a49617f16f5891e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8ce7491a8c4cbbb66f10c0dd6ca25b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a21db26faa17424fb4ef0783345a82c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a22e20e410ee466b8ba7752fd20056be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5955e99027d49e7b21f6acc1c4b65bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7084c843c32443eaae26450df0dc8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adfce349c8914d73aca98214755613d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5d71fe88fa4687956e06d8413a1228": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0abc34d3e384060be7a62d738c607a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1c06764155e48f1b424c922ab95e2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b388787fecb446a1b3629f81b4e70c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94bc683d342c4b69ac5d6e2769edf607",
              "IPY_MODEL_efc1b581808b43549e7c028dc467ed52",
              "IPY_MODEL_d6e39a968d0b4de2b258faf9ddf56d4c"
            ],
            "layout": "IPY_MODEL_a7084c843c32443eaae26450df0dc8a3"
          }
        },
        "b62e2676869e4153af765e5c40aae712": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6ecdc71deee4705ae82dacea74f5985": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b887eb5c224325a73f447a4e358d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701bb12af3574157957985dd03b4a881",
            "max": 432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78ee347eb1be4cbab3fa0d497bc7b772",
            "value": 432
          }
        },
        "b9048856d0674347aa994e65ccce1dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb19e49cd2c24ceaa27cb30c8175a92e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdca8d2d36ac4560b54dc8fff17caf5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee12272836345acb52fec4441e39d1d",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b059f6e6d84a9bb85bef1f0568a13d",
            "value": 649
          }
        },
        "bf8ee0e4c19a43d1b03c28b3cb755a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1f4c63a5404680b141380abca3707b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f8aded6c8da04a01bee2a7aa6c97cee2",
            "value": "‚Äá1.43k/?‚Äá[00:00&lt;00:00,‚Äá181kB/s]"
          }
        },
        "bffabc017f9d4566a9879a7c2654cf14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12c0935de0d421db904da033f8dc474": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37485ee85d24ee8825af336f818c89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35dcaf345b6146ff945c1bcbdf3fa3ab",
              "IPY_MODEL_b8b887eb5c224325a73f447a4e358d49",
              "IPY_MODEL_cd1842e4811841d7b776afa14a4714db"
            ],
            "layout": "IPY_MODEL_c9900f1038064d9980b2dbe81ad1194d"
          }
        },
        "c6e334d4ac3d430eb59aca0325b14e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b24f4b6d954a8a83fdef7acb97ebaa",
            "max": 812672320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ed14b43b00e4a728508936f103c642b",
            "value": 812672320
          }
        },
        "c8602548205e44d6af022ebb714e319e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6def134edcb4847b7c1af28547c302f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5edabb58d2964ae9b526e5a43d93c053",
            "value": "‚Äá2.44G/2.44G‚Äá[00:08&lt;00:00,‚Äá735MB/s]"
          }
        },
        "c91acd80da19416eb951e06acd891bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068cb71c294c4a4abbd9980d9a131917",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_50747bcc68fc4c16af25d18fd9c010f2",
            "value": "‚Äá368/368‚Äá[00:00&lt;00:00,‚Äá48.9kB/s]"
          }
        },
        "c9900f1038064d9980b2dbe81ad1194d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0b84c612934a81ab1b0e29f5f4c932": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5c42a1fab44429be7ac104e44ea6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6561c2f3d276439b9407d953585f9e82",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74d8c92b77d9423baf983c8f41cc6926",
            "value": "‚Äá8.15k/?‚Äá[00:00&lt;00:00,‚Äá967kB/s]"
          }
        },
        "cd1842e4811841d7b776afa14a4714db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6ab5fd871d4683a71d84781f82c1df",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ddacbcf75ea94b2ca99dec9cf0d2c0f1",
            "value": "‚Äá432/432‚Äá[00:00&lt;00:00,‚Äá63.7kB/s]"
          }
        },
        "ceb0199adae946198b8f8158956aa006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee12272836345acb52fec4441e39d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08037b7740a42679d18d8f09d8e1832": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d292d6a4cf584056a4eb42a1f96e472b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265dc91599af4166a31a1e081cca5990",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52daf14c1bde43f89f7902cc734be539",
            "value": 1
          }
        },
        "d3d37cd5a6354061812131abb1b6c2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93cefe21bb1c4f2ca8a966bd796fa1d0",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16738a350272410687e0771b846b8490",
            "value": 5069051
          }
        },
        "d43e6ad0227f4e499dda96d801ac522f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6352956785c41d69c16c2f4c932451b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_310915fc47a74b43917113d3df98dc75",
              "IPY_MODEL_d3d37cd5a6354061812131abb1b6c2d8",
              "IPY_MODEL_8639027519094e8ba398d5de4356a43f"
            ],
            "layout": "IPY_MODEL_b6ecdc71deee4705ae82dacea74f5985"
          }
        },
        "d6e39a968d0b4de2b258faf9ddf56d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680cccbd456d44488fbabb8352382a5d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_96a70470f6af4565a49617f16f5891e8",
            "value": "‚Äá711/711‚Äá[00:00&lt;00:00,‚Äá101kB/s]"
          }
        },
        "d95930dd5efd443a862f2ec8ce584335": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b82781d977412cbe566d45115395b3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_65c428704bdd4951a4ca14a82ebe17d0",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "d9a29fb51778465fbcd3c9e2ba46eaa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da50889622124fd191e30537ae832498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea1be469f5f24a128565d470524dca1e",
            "max": 2444578688,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a21db26faa17424fb4ef0783345a82c3",
            "value": 2444578688
          }
        },
        "da60ebf35b3045f6815bf4a95df4e5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae375b95ec94b00bf71b3039f55240e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbbcb8289b154591a8508be5fc40370b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3e77c084d6e74521a3c5e31dedd02382",
            "value": "‚Äá813M/813M‚Äá[00:05&lt;00:00,‚Äá251MB/s]"
          }
        },
        "dd44f8315b1f415da7f0658e01dd20a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75faf4d3a34341269c46367dc3e93c2b",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856b79b158254c44b4a2f2d9c345167e",
            "value": 409
          }
        },
        "dd5b46af47304638ba8226944e118f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddacbcf75ea94b2ca99dec9cf0d2c0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3cb146b16d4d2aa11b0c2cfc36d16f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedfea2321644deaafc0f2277230273a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfe09ba34a1f470390dc9752b31088a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8ce7491a8c4cbbb66f10c0dd6ca25b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ca0b84c612934a81ab1b0e29f5f4c932",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "e21158f1f77b49f6aa3b82602f73f070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6aa45ab4664d5e8c3045731198d3b9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_550abb6168d840b79ffdd27e9a357396",
            "value": "spiece.model:‚Äá100%"
          }
        },
        "e809c6e1789e40f4bb2257576ff7a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13daf82f4e924cb68591cba902496d28",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1e31b7738b0948a2829fe53157595cc0",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "ea1be469f5f24a128565d470524dca1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea872156c37e446da3c118a344455965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebf65ed63cff47fc8cc481cb3464203f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed07f7a399f941e09d7ac3f6c82cca6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee16cc853cd549af9c2bc275bf6210e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ee26dc7265f643549fb8a123e11ceee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfe09ba34a1f470390dc9752b31088a5",
              "IPY_MODEL_0338ee6cd456495f927ac13794f74580",
              "IPY_MODEL_8f0ca78958e5486a9ada4f1404c377a9"
            ],
            "layout": "IPY_MODEL_2824da3b61f94192bfc730103b209e40"
          }
        },
        "ee4e47b7240a495b80d4d985cd9dbfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef52bca57984cafb36101d315d95a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1103b8ed1b9f4863a2640050b666ecb2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ceb0199adae946198b8f8158956aa006",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "efc1b581808b43549e7c028dc467ed52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7284e5d040154be5a8213b43a285c7db",
            "max": 711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c64a53138cc44298e7b3afd772bbe70",
            "value": 711
          }
        },
        "f004b5964f0d4fb69060a727f94598b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065f61de3fc84e9081c76e3447e97c2d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_45f2d438b0db494b838325d88387b30c",
            "value": "‚Äá649/649‚Äá[00:00&lt;00:00,‚Äá51.1kB/s]"
          }
        },
        "f39024eda5b74e7081bed2f8720567a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c82362271c4a7480fc2d1259db162c",
            "max": 798330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4144ecce8fbc48fbb3efd497436b32ee",
            "value": 798330
          }
        },
        "f3f61afd46374557963f1106bed46958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56aa9eea7d44048a24bb306eaad6611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6def134edcb4847b7c1af28547c302f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b26ef0f80340d982985bb7cf2b66ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a29fb51778465fbcd3c9e2ba46eaa9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ae5d71fe88fa4687956e06d8413a1228",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "f889d3f9bce84ab0a4be318141ba4762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93611efa688640cbb9a4df5a2be51019",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f56aa9eea7d44048a24bb306eaad6611",
            "value": "‚Äá2.40M/?‚Äá[00:00&lt;00:00,‚Äá105MB/s]"
          }
        },
        "f8aded6c8da04a01bee2a7aa6c97cee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbbcb8289b154591a8508be5fc40370b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a02f91460bc4267b21a914cc7ecf00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e466432262d440de82879755ad34b98f",
              "IPY_MODEL_f5c15b3c40824fde8c3b56ca3098ba96",
              "IPY_MODEL_049f3d16e66c4af9b9f0f93c1c6019a0"
            ],
            "layout": "IPY_MODEL_e02ab3f4794245648c01d9df75d70474"
          }
        },
        "e466432262d440de82879755ad34b98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b5588bf3f141a9b9b7b15a4248c3ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dbc6cea6d70c40e497637470794ad3e5",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "f5c15b3c40824fde8c3b56ca3098ba96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78e8cf398a74c65bce15d3e1360fb46",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad3559c3ccdb4c4c96571b25f161972b",
            "value": 1
          }
        },
        "049f3d16e66c4af9b9f0f93c1c6019a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae79e08811554190ad60ba7bc0808daa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a6cb42d18fd442a3ae505784df944176",
            "value": "‚Äá8.15k/?‚Äá[00:00&lt;00:00,‚Äá806kB/s]"
          }
        },
        "e02ab3f4794245648c01d9df75d70474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b5588bf3f141a9b9b7b15a4248c3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc6cea6d70c40e497637470794ad3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78e8cf398a74c65bce15d3e1360fb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ad3559c3ccdb4c4c96571b25f161972b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae79e08811554190ad60ba7bc0808daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6cb42d18fd442a3ae505784df944176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcecfe2635f44bf2b981b02ee8eb4d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26a14b72f03d4526b8b023895752254a",
              "IPY_MODEL_759c9b470cac48b482fc4320084d0f9a",
              "IPY_MODEL_0a793ed73444428da5332dc0f41351ba"
            ],
            "layout": "IPY_MODEL_243785bb061f42a5b2cc9c9bfe81b881"
          }
        },
        "26a14b72f03d4526b8b023895752254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e03626aa4744303803604d6e347af77",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ddba7818be1a4d9681731d15678588d5",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "759c9b470cac48b482fc4320084d0f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c59f393a68c4cdd9cd2a999dcdaa64d",
            "max": 529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b98884906cf243548f9b8aca8541271c",
            "value": 529
          }
        },
        "0a793ed73444428da5332dc0f41351ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83884b28ef3e409187c6c749ac1b9881",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3b4c6f7ca4074bdb9afe1b72f7ba9176",
            "value": "‚Äá529/529‚Äá[00:00&lt;00:00,‚Äá70.4kB/s]"
          }
        },
        "243785bb061f42a5b2cc9c9bfe81b881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e03626aa4744303803604d6e347af77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddba7818be1a4d9681731d15678588d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c59f393a68c4cdd9cd2a999dcdaa64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b98884906cf243548f9b8aca8541271c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83884b28ef3e409187c6c749ac1b9881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4c6f7ca4074bdb9afe1b72f7ba9176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa2d439f4ffd461982ee831189fb0293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f30d5bfa19f04139b0c8b9d2d9f845a3",
              "IPY_MODEL_d01f2ca1996e41c896bf0c1f5e3d0a35",
              "IPY_MODEL_74ad6696d36147b39c842e22794b8f77"
            ],
            "layout": "IPY_MODEL_90bc0d10ebdd409a99bce17169725c12"
          }
        },
        "f30d5bfa19f04139b0c8b9d2d9f845a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7a36794b1e4bfba0e1ec3f67ce5ad9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5239a4ee8aec467d87956a81d4f647ee",
            "value": "sentencepiece.bpe.model:‚Äá100%"
          }
        },
        "d01f2ca1996e41c896bf0c1f5e3d0a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659d53ebac874f0cbc525af12d293361",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f671ec55c9334d1eaa26dedfcae5b94f",
            "value": 5069051
          }
        },
        "74ad6696d36147b39c842e22794b8f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ae4f234d864f1cb6db8624ef9469ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6fb266a34b2047b89196d1f26f803ec1",
            "value": "‚Äá5.07M/5.07M‚Äá[00:00&lt;00:00,‚Äá6.61MB/s]"
          }
        },
        "90bc0d10ebdd409a99bce17169725c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7a36794b1e4bfba0e1ec3f67ce5ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5239a4ee8aec467d87956a81d4f647ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659d53ebac874f0cbc525af12d293361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f671ec55c9334d1eaa26dedfcae5b94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8ae4f234d864f1cb6db8624ef9469ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb266a34b2047b89196d1f26f803ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22b0a7a93b404aaab41582ac569603d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2aba43f29c1474dbea6f066f42a6094",
              "IPY_MODEL_d5aa57b643fe47e9943b8a665bcf5f71",
              "IPY_MODEL_f65a54e7a0724d9c90d22ed396eb5330"
            ],
            "layout": "IPY_MODEL_793ecdb57e7f47c9ae57e14d58578a52"
          }
        },
        "e2aba43f29c1474dbea6f066f42a6094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51eeefcf7ef74e389b2b4f58099ec382",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_faf895167c534ee0826a1588bf324869",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "d5aa57b643fe47e9943b8a665bcf5f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520d6bdf6ce24dd0b752982320a012b8",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df288abf838b48dcae664e8a95760dda",
            "value": 649
          }
        },
        "f65a54e7a0724d9c90d22ed396eb5330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d202af25354b93a056de4ccea93ce7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_45cc92ab16b14c21ba02e80454260dff",
            "value": "‚Äá649/649‚Äá[00:00&lt;00:00,‚Äá88.6kB/s]"
          }
        },
        "793ecdb57e7f47c9ae57e14d58578a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eeefcf7ef74e389b2b4f58099ec382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf895167c534ee0826a1588bf324869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "520d6bdf6ce24dd0b752982320a012b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df288abf838b48dcae664e8a95760dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00d202af25354b93a056de4ccea93ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45cc92ab16b14c21ba02e80454260dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8540e67cf2f48f99e218653b66f8007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1a1aafd9599420893801cc27c027265",
              "IPY_MODEL_871940531f43497da902f168149f6a0d",
              "IPY_MODEL_f41d98c88f0b4f26a9827d6045557860"
            ],
            "layout": "IPY_MODEL_570793b845724a1189d2ca1c491f9e97"
          }
        },
        "a1a1aafd9599420893801cc27c027265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d62058c7fc6a43dfb69bf203fde91259",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fe84ce7a74bd44698a4318db61f5c69c",
            "value": "config.json:‚Äá"
          }
        },
        "871940531f43497da902f168149f6a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b84aa4ea2ee2428da066e67215ee813a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a3b5fa90a0849c881a52bb4cfed432c",
            "value": 1
          }
        },
        "f41d98c88f0b4f26a9827d6045557860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31b63f0d3be24846b72c8c2d4aba9d4e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ed73a1c2ca284d7891c1566925ead08d",
            "value": "‚Äá1.43k/?‚Äá[00:00&lt;00:00,‚Äá156kB/s]"
          }
        },
        "570793b845724a1189d2ca1c491f9e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d62058c7fc6a43dfb69bf203fde91259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe84ce7a74bd44698a4318db61f5c69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b84aa4ea2ee2428da066e67215ee813a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0a3b5fa90a0849c881a52bb4cfed432c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31b63f0d3be24846b72c8c2d4aba9d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed73a1c2ca284d7891c1566925ead08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a81efcc3c084d1a8c66c9fd40e1dc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ca2c832ec38401fb56c88467f7b6e23",
              "IPY_MODEL_52a28f04afcb40299a0797ff5fa50577",
              "IPY_MODEL_074864f5abc5411fb48996c96089c797"
            ],
            "layout": "IPY_MODEL_c3932b7336aa48bb86e12064a25f3f3e"
          }
        },
        "9ca2c832ec38401fb56c88467f7b6e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97a54c081194a728290b8a9511508aa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c75c74b549674d4a806d006c7ecda890",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "52a28f04afcb40299a0797ff5fa50577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f642047d356424fb7878afed371f8e0",
            "max": 368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb17825fbeae4c0bb8582cae97263dd8",
            "value": 368
          }
        },
        "074864f5abc5411fb48996c96089c797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_114c321f865b451b90f2c2d1b7a10c91",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d8413760d1844a1b96c4899e240713a6",
            "value": "‚Äá368/368‚Äá[00:00&lt;00:00,‚Äá49.6kB/s]"
          }
        },
        "c3932b7336aa48bb86e12064a25f3f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97a54c081194a728290b8a9511508aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75c74b549674d4a806d006c7ecda890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f642047d356424fb7878afed371f8e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb17825fbeae4c0bb8582cae97263dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "114c321f865b451b90f2c2d1b7a10c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8413760d1844a1b96c4899e240713a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0adfb144a100480c8698046219c0083e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_762b1a2797904cdf85ee805ed354f552",
              "IPY_MODEL_9f40f55d74d24946a347de8569ab4b3b",
              "IPY_MODEL_7904458f37c7495e951efb9b0ad56d7b"
            ],
            "layout": "IPY_MODEL_aeea88b882284431aedf165898621585"
          }
        },
        "762b1a2797904cdf85ee805ed354f552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_272943e4466c4fa6aef5f443a38abf45",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_82ad021fc8244c89b5c13387bd6ccea7",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "9f40f55d74d24946a347de8569ab4b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0412e77fa7a4e08852b33419a5458d8",
            "max": 711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9211c0ba359c46f6b0d278ccce68329a",
            "value": 711
          }
        },
        "7904458f37c7495e951efb9b0ad56d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4392c79475944cebbfcc6101343ae1fd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_458e76270526405fa6ac3d3f90cf12b5",
            "value": "‚Äá711/711‚Äá[00:00&lt;00:00,‚Äá91.7kB/s]"
          }
        },
        "aeea88b882284431aedf165898621585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "272943e4466c4fa6aef5f443a38abf45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ad021fc8244c89b5c13387bd6ccea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0412e77fa7a4e08852b33419a5458d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9211c0ba359c46f6b0d278ccce68329a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4392c79475944cebbfcc6101343ae1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458e76270526405fa6ac3d3f90cf12b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "173b218e980144b9b5d1b795b88a8641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe59ffe426684a6296e45d9c3dc02464",
              "IPY_MODEL_ed50608804a24a148a1403ac3130d7b9",
              "IPY_MODEL_a8425c0ba6104bf885f47068d51d6c98"
            ],
            "layout": "IPY_MODEL_2cfa42664b3f45d18df30fa1d0f0caed"
          }
        },
        "fe59ffe426684a6296e45d9c3dc02464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8cc813c40e4afe9490b18034d791fc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_24e4b1bacf01491096a2fef1ca90ffac",
            "value": "spiece.model:‚Äá100%"
          }
        },
        "ed50608804a24a148a1403ac3130d7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c2464b7b49d477d990377c7e440d0c0",
            "max": 798330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d033e63b8d774e128ab0b8db244f93b2",
            "value": 798330
          }
        },
        "a8425c0ba6104bf885f47068d51d6c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9637fed26d8d44b1abcfec42755efaae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0d38c3fccffb48f0a5f517e16f7a7e3b",
            "value": "‚Äá798k/798k‚Äá[00:00&lt;00:00,‚Äá648kB/s]"
          }
        },
        "2cfa42664b3f45d18df30fa1d0f0caed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c8cc813c40e4afe9490b18034d791fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e4b1bacf01491096a2fef1ca90ffac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c2464b7b49d477d990377c7e440d0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d033e63b8d774e128ab0b8db244f93b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9637fed26d8d44b1abcfec42755efaae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d38c3fccffb48f0a5f517e16f7a7e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bafe197aca4a7f9f2844722cc2aad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f76257d971c43d1b1f2478d08656c66",
              "IPY_MODEL_062b456e323849b197d7bb02180af5f3",
              "IPY_MODEL_b3f3942036584c73b767fb882d79cce0"
            ],
            "layout": "IPY_MODEL_9b9a9fbfbf7348e4923fadcc539656ea"
          }
        },
        "7f76257d971c43d1b1f2478d08656c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5821a25111c248338421f76a72625475",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bbd0534c78434e5ca728c19c513717e0",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "062b456e323849b197d7bb02180af5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93ed162121941089045073f8691a40d",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cd0973dc9124d65b6175591e44950da",
            "value": 409
          }
        },
        "b3f3942036584c73b767fb882d79cce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628325f94c3a49e6bcc135bf28214aea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8627903678c34811b10775fee4517080",
            "value": "‚Äá409/409‚Äá[00:00&lt;00:00,‚Äá55.1kB/s]"
          }
        },
        "9b9a9fbfbf7348e4923fadcc539656ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5821a25111c248338421f76a72625475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd0534c78434e5ca728c19c513717e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93ed162121941089045073f8691a40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd0973dc9124d65b6175591e44950da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "628325f94c3a49e6bcc135bf28214aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8627903678c34811b10775fee4517080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8171858c1ff64010a7c51eaaf80fbd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dde4acc6e0b41409c8bc160977e9c24",
              "IPY_MODEL_8cee413d23894fea820033d53d8f2335",
              "IPY_MODEL_861d3460e663491ba1a1d35d36c93b06"
            ],
            "layout": "IPY_MODEL_f9b56c7768de4f6ebc029599e366dade"
          }
        },
        "8dde4acc6e0b41409c8bc160977e9c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3adc0b0b0c47158b97b19fbad7f657",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_37d21542cc1d471fbbfc74d5b4ee7062",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "8cee413d23894fea820033d53d8f2335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5660c978e344d9191431d532b624d9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f3dd6d7f4514f5481d1ab904f71b44a",
            "value": 1
          }
        },
        "861d3460e663491ba1a1d35d36c93b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a55f1ee782b49bca977dce644a9ac9b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_da3466df754645c38679126e38c89bfd",
            "value": "‚Äá2.40M/?‚Äá[00:00&lt;00:00,‚Äá70.8MB/s]"
          }
        },
        "f9b56c7768de4f6ebc029599e366dade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3adc0b0b0c47158b97b19fbad7f657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d21542cc1d471fbbfc74d5b4ee7062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5660c978e344d9191431d532b624d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3f3dd6d7f4514f5481d1ab904f71b44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a55f1ee782b49bca977dce644a9ac9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3466df754645c38679126e38c89bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "721ecdbd9740409cb1f7b2cfa883d6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fc5484cd7c94d4cb411f9e894a0168a",
              "IPY_MODEL_f815ff9d38604b20b03bf2f5c3226bb4",
              "IPY_MODEL_ed2524f2939f48c8b13e4939c2f7ac92"
            ],
            "layout": "IPY_MODEL_ec6c44f2425d4bfc89e2e9843a942da0"
          }
        },
        "4fc5484cd7c94d4cb411f9e894a0168a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628954d116c64f15b9158544009b2a81",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dc45f2b13988415d86ef83a678c34767",
            "value": "config.json:‚Äá100%"
          }
        },
        "f815ff9d38604b20b03bf2f5c3226bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d61d66be68486cb4c9b50e8fced3fa",
            "max": 432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcb35cab7c054d15bbb3a57be4ee163e",
            "value": 432
          }
        },
        "ed2524f2939f48c8b13e4939c2f7ac92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5df35cf6d8f14e5a93df67e668a518db",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1843fdbdecf64164a65e56fc1a8652b4",
            "value": "‚Äá432/432‚Äá[00:00&lt;00:00,‚Äá58.1kB/s]"
          }
        },
        "ec6c44f2425d4bfc89e2e9843a942da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628954d116c64f15b9158544009b2a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc45f2b13988415d86ef83a678c34767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3d61d66be68486cb4c9b50e8fced3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb35cab7c054d15bbb3a57be4ee163e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5df35cf6d8f14e5a93df67e668a518db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1843fdbdecf64164a65e56fc1a8652b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1268f17fda424faca7211457e0d90816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_494d213123264d399aaa0698482c661b",
              "IPY_MODEL_63cd1016e8654619bff779a1889919c9",
              "IPY_MODEL_fa2f03a95d764e8bafcfb001d7535f1c"
            ],
            "layout": "IPY_MODEL_8b680936eadb4e8eb11b89dd5fc687dd"
          }
        },
        "494d213123264d399aaa0698482c661b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aefc7d633de24551a946b2f9ca592839",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3f2142579fa14257b277c5c602c2ef22",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "63cd1016e8654619bff779a1889919c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1afc82897951429f933b7556f021fe63",
            "max": 812672320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89063f197d6f445a8f641470f53c82ec",
            "value": 812672320
          }
        },
        "fa2f03a95d764e8bafcfb001d7535f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aae43163fac48f8b6e64d887f8b9da4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a2ec3b1327ea4b0dbc8a38660d624c96",
            "value": "‚Äá813M/813M‚Äá[00:01&lt;00:00,‚Äá775MB/s]"
          }
        },
        "8b680936eadb4e8eb11b89dd5fc687dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aefc7d633de24551a946b2f9ca592839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2142579fa14257b277c5c602c2ef22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1afc82897951429f933b7556f021fe63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89063f197d6f445a8f641470f53c82ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9aae43163fac48f8b6e64d887f8b9da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ec3b1327ea4b0dbc8a38660d624c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1f4bd88a0ae44c49b18bf2770873003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59dad0b4c5fd483bb91a88c74f530f72",
              "IPY_MODEL_e9db12ca111e453a99380d5cd815c7a3",
              "IPY_MODEL_e59b8109ffc34bb4bd8f3c263090265a"
            ],
            "layout": "IPY_MODEL_a45cd8355329454ca1cb63dad17f5f9b"
          }
        },
        "59dad0b4c5fd483bb91a88c74f530f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06eb8d0d3964efdbf78411c6d518fd0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d6b3e0073400452ab3aaa04207a717b4",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "e9db12ca111e453a99380d5cd815c7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2af5cd0c12b4ca2aff33e97aa8a2071",
            "max": 2444578688,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c31c0a1c7d184293921ae91a96bea5a1",
            "value": 2444578688
          }
        },
        "e59b8109ffc34bb4bd8f3c263090265a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e09566862b1448992880bac2ba3f8e6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d56ce66dd5a240ebb16ed4a8bca99d8e",
            "value": "‚Äá2.44G/2.44G‚Äá[00:04&lt;00:00,‚Äá1.31GB/s]"
          }
        },
        "a45cd8355329454ca1cb63dad17f5f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06eb8d0d3964efdbf78411c6d518fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b3e0073400452ab3aaa04207a717b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2af5cd0c12b4ca2aff33e97aa8a2071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31c0a1c7d184293921ae91a96bea5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e09566862b1448992880bac2ba3f8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56ce66dd5a240ebb16ed4a8bca99d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd33c6086a84619b8a31904c2d29cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_341335e21b324c969c0b0ddadbdd448f",
              "IPY_MODEL_09c3724193744156a7732469c961722c",
              "IPY_MODEL_ce7eba44f0ff4caeac1ba650424d7763"
            ],
            "layout": "IPY_MODEL_d670ce5dfaec46fbafc1285eb0adb4f3"
          }
        },
        "341335e21b324c969c0b0ddadbdd448f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20bd48a0514f424abd6417cbe05d48b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_873d92a0c8d6484a8828a5d40cb43f9a",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "09c3724193744156a7732469c961722c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc1d9e2e3ba4791acc8c88677488ac9",
            "max": 261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1a18e1bee974e7e90af00872db6956b",
            "value": 261
          }
        },
        "ce7eba44f0ff4caeac1ba650424d7763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740f156c886341568fb07624ff6007be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8523779755bd48b295394616746447ca",
            "value": "‚Äá261/261‚Äá[00:00&lt;00:00,‚Äá31.3kB/s]"
          }
        },
        "d670ce5dfaec46fbafc1285eb0adb4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bd48a0514f424abd6417cbe05d48b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873d92a0c8d6484a8828a5d40cb43f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfc1d9e2e3ba4791acc8c88677488ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a18e1bee974e7e90af00872db6956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "740f156c886341568fb07624ff6007be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8523779755bd48b295394616746447ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dafd9e216d8c48bfa08f832ca4591e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bbcfc87cc084fc1850a28033520a2d2",
              "IPY_MODEL_d7dbcf72442949ed91119bd39bb44f8c",
              "IPY_MODEL_edfb984c8a0046678ebc6f8d97d62ce4"
            ],
            "layout": "IPY_MODEL_063df0d431e140078686200043023efd"
          }
        },
        "6bbcfc87cc084fc1850a28033520a2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e9161c7d8a345baaa4c07b56c63fddc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6898fbdf742d4f87b3485bd80edaa3eb",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "d7dbcf72442949ed91119bd39bb44f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f099f6446b24a18be4f5c4190de8291",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fa238c2ad1f405cb46331b415d8c3e2",
            "value": 1
          }
        },
        "edfb984c8a0046678ebc6f8d97d62ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2328c906111549798f5de42d318a0da0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a853872d2e2c44a98eb89570803d2881",
            "value": "‚Äá8.15k/?‚Äá[00:00&lt;00:00,‚Äá841kB/s]"
          }
        },
        "063df0d431e140078686200043023efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e9161c7d8a345baaa4c07b56c63fddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6898fbdf742d4f87b3485bd80edaa3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f099f6446b24a18be4f5c4190de8291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2fa238c2ad1f405cb46331b415d8c3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2328c906111549798f5de42d318a0da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a853872d2e2c44a98eb89570803d2881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bde3a878541547889c670b630b9ecfae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfbce9a56324419bbe114354533fafa1",
              "IPY_MODEL_4f08ecb7a70540d29d4f9a4c5e6e64ad",
              "IPY_MODEL_1852d91ea1ba48049185afd877daaa96"
            ],
            "layout": "IPY_MODEL_e2c067f81e8b49d8994277bfb5cdbcf5"
          }
        },
        "cfbce9a56324419bbe114354533fafa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d30adff60784942b2065930cce14687",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfdd768a2c3a4da1a29befcd9200684a",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "4f08ecb7a70540d29d4f9a4c5e6e64ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_596da4c0d5dc4f6984d2643694711736",
            "max": 529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7dec0fed37a4be398fe72a57b77fd27",
            "value": 529
          }
        },
        "1852d91ea1ba48049185afd877daaa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca818624dfc4139b066b27752ee7b58",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8cff975e481943bc8a1c53736b456988",
            "value": "‚Äá529/529‚Äá[00:00&lt;00:00,‚Äá66.6kB/s]"
          }
        },
        "e2c067f81e8b49d8994277bfb5cdbcf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d30adff60784942b2065930cce14687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfdd768a2c3a4da1a29befcd9200684a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "596da4c0d5dc4f6984d2643694711736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dec0fed37a4be398fe72a57b77fd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eca818624dfc4139b066b27752ee7b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cff975e481943bc8a1c53736b456988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "821e5e52baae40a1bd018ea2e0e2426d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01cbef8671584dc9903d7b473a0c9f70",
              "IPY_MODEL_8f0a2e11be4e4a0182bf7cd7982888f9",
              "IPY_MODEL_c733980b68974bcaa936f2bfa588ceda"
            ],
            "layout": "IPY_MODEL_dc2167c2f2b540f0838f8bd4d4f41100"
          }
        },
        "01cbef8671584dc9903d7b473a0c9f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c720298af8ff4942b2e78fdb671f2e44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a680ecdbae0446f7ad17b14cb4565caa",
            "value": "sentencepiece.bpe.model:‚Äá100%"
          }
        },
        "8f0a2e11be4e4a0182bf7cd7982888f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7d1bcfc9e34c8e86c8cbdde7404533",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2fda5ce75714d6082ec1e4616c7a22b",
            "value": 5069051
          }
        },
        "c733980b68974bcaa936f2bfa588ceda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6d5af59c98485ea13fb1b34a2a5e23",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0eff208d315544bf91bd1eb0730c947a",
            "value": "‚Äá5.07M/5.07M‚Äá[00:02&lt;00:00,‚Äá2.06MB/s]"
          }
        },
        "dc2167c2f2b540f0838f8bd4d4f41100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c720298af8ff4942b2e78fdb671f2e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a680ecdbae0446f7ad17b14cb4565caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7d1bcfc9e34c8e86c8cbdde7404533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2fda5ce75714d6082ec1e4616c7a22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd6d5af59c98485ea13fb1b34a2a5e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eff208d315544bf91bd1eb0730c947a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f7ddf7565a0460c8332d01a0d398794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90e9e0de47364e2aacbbc78d840f7a55",
              "IPY_MODEL_33e6a2d8920a45279e9b2ebcce2df031",
              "IPY_MODEL_90c98426d39848deb26b5e7e79fb8259"
            ],
            "layout": "IPY_MODEL_c665ba91451043538ac7f567dd9b2881"
          }
        },
        "90e9e0de47364e2aacbbc78d840f7a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db213d9597324345963b98183e1174ab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9c30b81fd84341c3b25d53572e8716fe",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "33e6a2d8920a45279e9b2ebcce2df031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc189a9e840440b91f4911d7e3d8962",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54576f808368416594412d7d2f55c1ad",
            "value": 649
          }
        },
        "90c98426d39848deb26b5e7e79fb8259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9358e1d060a34e869c1c8f16a90472ef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d682fcc6e27f4733be45d2725640adad",
            "value": "‚Äá649/649‚Äá[00:00&lt;00:00,‚Äá93.9kB/s]"
          }
        },
        "c665ba91451043538ac7f567dd9b2881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db213d9597324345963b98183e1174ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c30b81fd84341c3b25d53572e8716fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc189a9e840440b91f4911d7e3d8962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54576f808368416594412d7d2f55c1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9358e1d060a34e869c1c8f16a90472ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d682fcc6e27f4733be45d2725640adad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d277bdeb1da040329d93509ec331b5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26368f4d7dbd45588e6b7d9c7d66f173",
              "IPY_MODEL_b75078709c9d49578eacefc7b58c3860",
              "IPY_MODEL_6c0ca28dc30a46e6bd5f185f2c0404d5"
            ],
            "layout": "IPY_MODEL_de4de60588344e1da9e6aec16c1e03eb"
          }
        },
        "26368f4d7dbd45588e6b7d9c7d66f173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07d22f0846c4487a908e491d693abbf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3619fd72e29448f4a7fb4df0f4f1d6b8",
            "value": "config.json:‚Äá"
          }
        },
        "b75078709c9d49578eacefc7b58c3860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9be762dbd2d43e191431fa4a623ba63",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4f2ec28ef014d3eba39d8d3852afecd",
            "value": 1
          }
        },
        "6c0ca28dc30a46e6bd5f185f2c0404d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55c33c05bf54478a8dc5aefe0151405",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_16a87008c94e452f9c79b4a36a240084",
            "value": "‚Äá1.43k/?‚Äá[00:00&lt;00:00,‚Äá176kB/s]"
          }
        },
        "de4de60588344e1da9e6aec16c1e03eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07d22f0846c4487a908e491d693abbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3619fd72e29448f4a7fb4df0f4f1d6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9be762dbd2d43e191431fa4a623ba63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c4f2ec28ef014d3eba39d8d3852afecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f55c33c05bf54478a8dc5aefe0151405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a87008c94e452f9c79b4a36a240084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9f41f26eca74478a0611ec8cf65e2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a3e10871d64a71940380866423bd1c",
              "IPY_MODEL_ce5d83cb2d744e3d89943a2297c2f6e2",
              "IPY_MODEL_abc288b74adc4938b1ef4caf397f2287"
            ],
            "layout": "IPY_MODEL_284e4820d4c04b6fb0c681a3986994e0"
          }
        },
        "f4a3e10871d64a71940380866423bd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55ace4692824f308bea481e58e98be0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_456863fcf3c84aa6b797654a87374aa1",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "ce5d83cb2d744e3d89943a2297c2f6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4540f3ad2484fccb0cdb78f56c9a7b2",
            "max": 368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1c47fe1b8b0488db43a68811d4e878e",
            "value": 368
          }
        },
        "abc288b74adc4938b1ef4caf397f2287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffaff3f38e8546f487ed647a8f9deb16",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_751d0a64d759412caf86806b58a9b6a2",
            "value": "‚Äá368/368‚Äá[00:00&lt;00:00,‚Äá51.0kB/s]"
          }
        },
        "284e4820d4c04b6fb0c681a3986994e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55ace4692824f308bea481e58e98be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456863fcf3c84aa6b797654a87374aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4540f3ad2484fccb0cdb78f56c9a7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c47fe1b8b0488db43a68811d4e878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffaff3f38e8546f487ed647a8f9deb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751d0a64d759412caf86806b58a9b6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b30ea5bf8eac42b2b34561e151e29555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_643cfdad80f948719059a1b95cbb66f4",
              "IPY_MODEL_9d1098fcad334b0bb1fbdaab6c55ccdd",
              "IPY_MODEL_cca5e48eb10a4eb6bdb107577bfdf25d"
            ],
            "layout": "IPY_MODEL_67b729fdc6ed4b25a65b159984849e1e"
          }
        },
        "643cfdad80f948719059a1b95cbb66f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d85d58d06704fbb8153c4cac20f9d53",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1a996499c15c427c8e1bf153e00eb94c",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "9d1098fcad334b0bb1fbdaab6c55ccdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2417e9e501a1401a827184425be940d3",
            "max": 711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e89613d0749479390565bd823afef15",
            "value": 711
          }
        },
        "cca5e48eb10a4eb6bdb107577bfdf25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d419e7ef351496495476f09e8bd9ef0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c59a9958a80b4161a61b2253447883f6",
            "value": "‚Äá711/711‚Äá[00:00&lt;00:00,‚Äá94.9kB/s]"
          }
        },
        "67b729fdc6ed4b25a65b159984849e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d85d58d06704fbb8153c4cac20f9d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a996499c15c427c8e1bf153e00eb94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2417e9e501a1401a827184425be940d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e89613d0749479390565bd823afef15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d419e7ef351496495476f09e8bd9ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59a9958a80b4161a61b2253447883f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9734583f334a457f8e5bc8ec697ed384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04f02c23ee664a8492c7b56c298bbff5",
              "IPY_MODEL_cd0de435dc14418fbeef75703c12d6e3",
              "IPY_MODEL_3c24c6d8ba6c40099d6d51b159d7551b"
            ],
            "layout": "IPY_MODEL_c64731ad34624c6faafa96f42b8ca6be"
          }
        },
        "04f02c23ee664a8492c7b56c298bbff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d564ea70ed4ea79d6a850b1cca1e52",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8101ca260ca84cb39a617a4add1617ad",
            "value": "spiece.model:‚Äá100%"
          }
        },
        "cd0de435dc14418fbeef75703c12d6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79ba12bbc6a4b648975c910f78afde0",
            "max": 798330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ded62deb8384866afc83b97b7a9c399",
            "value": 798330
          }
        },
        "3c24c6d8ba6c40099d6d51b159d7551b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91b61e7349624fe694ef85b00ed73156",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_01de165ba8814e15a4e43f89873e1df6",
            "value": "‚Äá798k/798k‚Äá[00:00&lt;00:00,‚Äá1.10MB/s]"
          }
        },
        "c64731ad34624c6faafa96f42b8ca6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d564ea70ed4ea79d6a850b1cca1e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8101ca260ca84cb39a617a4add1617ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a79ba12bbc6a4b648975c910f78afde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ded62deb8384866afc83b97b7a9c399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91b61e7349624fe694ef85b00ed73156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01de165ba8814e15a4e43f89873e1df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d46cd7bb00614be09e3400d552c5d9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46f8ee4d42c440b88111d3c7d5bbf2e6",
              "IPY_MODEL_d48ce1d41dd94eb8a6619bd0fb1ad15e",
              "IPY_MODEL_0b7582f368464c239de258c2b30eacf1"
            ],
            "layout": "IPY_MODEL_23683331628b4651b0fa638e572501a2"
          }
        },
        "46f8ee4d42c440b88111d3c7d5bbf2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e28fe47f18a46f1b36c21f43b6039fd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_33a4ffe1a33840ef826025df23644dc5",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "d48ce1d41dd94eb8a6619bd0fb1ad15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee32d0971b4e4c1fa5cfd66018320f9b",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2693d92c55a40c7a001c5427382db58",
            "value": 409
          }
        },
        "0b7582f368464c239de258c2b30eacf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9961694a06f94374b11ab4363525a947",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_59f9542fbb2a4bfd9f470354801d11e9",
            "value": "‚Äá409/409‚Äá[00:00&lt;00:00,‚Äá53.3kB/s]"
          }
        },
        "23683331628b4651b0fa638e572501a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e28fe47f18a46f1b36c21f43b6039fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a4ffe1a33840ef826025df23644dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee32d0971b4e4c1fa5cfd66018320f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2693d92c55a40c7a001c5427382db58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9961694a06f94374b11ab4363525a947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f9542fbb2a4bfd9f470354801d11e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "438ea22fed3047608dba29b3f517a136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87dc07a071ee43e487159d4cd8fb2f92",
              "IPY_MODEL_10e9284e957c4e8688415d26c95ec20f",
              "IPY_MODEL_78e8275668714257a8ca64131cde40cf"
            ],
            "layout": "IPY_MODEL_355cac62b2364a138c781c1bcc0dec61"
          }
        },
        "87dc07a071ee43e487159d4cd8fb2f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67760a6f551746aaaf0ef604a214fafa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90d28bd03742452d94c7e739c571ed14",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "10e9284e957c4e8688415d26c95ec20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29af318882b449bfa43fd1f7a4bba450",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c45251aa0a047f3a33d21a4b3ec970e",
            "value": 1
          }
        },
        "78e8275668714257a8ca64131cde40cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef312badc8924e918378afcc25fb2e4a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_925c6a88db8b4abb9ffe80d9aa653c76",
            "value": "‚Äá2.40M/?‚Äá[00:00&lt;00:00,‚Äá96.5MB/s]"
          }
        },
        "355cac62b2364a138c781c1bcc0dec61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67760a6f551746aaaf0ef604a214fafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d28bd03742452d94c7e739c571ed14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29af318882b449bfa43fd1f7a4bba450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c45251aa0a047f3a33d21a4b3ec970e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef312badc8924e918378afcc25fb2e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925c6a88db8b4abb9ffe80d9aa653c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39e5503b2ecc4fd3a877609ac4b24f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2514d3dafc934d1c881ca0cc090d6a0d",
              "IPY_MODEL_346b5c3243d1493f918e428f58e4d73b",
              "IPY_MODEL_220fcc07c74f4c84b29248ddeabc69c8"
            ],
            "layout": "IPY_MODEL_19ce9ed33861440bbc718a12cd14c3f9"
          }
        },
        "2514d3dafc934d1c881ca0cc090d6a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af566c7659d4fe5a2a89f81f5f25e86",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_563ef901b02245ab8906a6f8efbc2465",
            "value": "config.json:‚Äá100%"
          }
        },
        "346b5c3243d1493f918e428f58e4d73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b18980526e4619935e8393857e7c22",
            "max": 432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6032a631caa4b00b2d9bc7c5794f02a",
            "value": 432
          }
        },
        "220fcc07c74f4c84b29248ddeabc69c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1996f42e2acb4423b0dab83dfc3de10a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_629aa1629953411da390e881fabf0cc0",
            "value": "‚Äá432/432‚Äá[00:00&lt;00:00,‚Äá56.8kB/s]"
          }
        },
        "19ce9ed33861440bbc718a12cd14c3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af566c7659d4fe5a2a89f81f5f25e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563ef901b02245ab8906a6f8efbc2465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12b18980526e4619935e8393857e7c22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6032a631caa4b00b2d9bc7c5794f02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1996f42e2acb4423b0dab83dfc3de10a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629aa1629953411da390e881fabf0cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c40fd7b0c0c4e248bd618059963abe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21509915051e4e779edc8c3319e452e7",
              "IPY_MODEL_13b5eab9d6cc460e997faea93cfb01db",
              "IPY_MODEL_1d3eabd6f7674aeb88815dc8bd61bf37"
            ],
            "layout": "IPY_MODEL_641adfb1e73147529aec0dd9e7877136"
          }
        },
        "21509915051e4e779edc8c3319e452e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c337a7d144543729cd2c1fc32207c29",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_98cd2f422fd54dbeb77220834f877bf1",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "13b5eab9d6cc460e997faea93cfb01db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17fe9589b3c4108ab2276c29d1c5e6a",
            "max": 812672320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e329707c974e4c82b921ce57d3b9ed93",
            "value": 812672320
          }
        },
        "1d3eabd6f7674aeb88815dc8bd61bf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3c351c4b6c46539cc21ed3f8440b3f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4979c1f3321747bbb88afa6636841c82",
            "value": "‚Äá813M/813M‚Äá[00:04&lt;00:00,‚Äá326MB/s]"
          }
        },
        "641adfb1e73147529aec0dd9e7877136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c337a7d144543729cd2c1fc32207c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cd2f422fd54dbeb77220834f877bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a17fe9589b3c4108ab2276c29d1c5e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e329707c974e4c82b921ce57d3b9ed93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e3c351c4b6c46539cc21ed3f8440b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4979c1f3321747bbb88afa6636841c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3c746e9d2704aa89dfccb58f0b1588c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb693d87e21470dbeeb68a82d49edf9",
              "IPY_MODEL_c660c5b16f8949e7a8d52236228db8c2",
              "IPY_MODEL_77e4d2dfb9ad4dbea1220b3991ed84e1"
            ],
            "layout": "IPY_MODEL_8630e5ca51004defb5d674c35c33e1e9"
          }
        },
        "ddb693d87e21470dbeeb68a82d49edf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a116809a21a44a21ac6f3eec35c05977",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9045935a82544abbbe98e0563a7b365e",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "c660c5b16f8949e7a8d52236228db8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2fb0d51024444886e25d8089852675",
            "max": 2444578688,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a713b7d747cc44ffbcfc0df61af487e4",
            "value": 2444578688
          }
        },
        "77e4d2dfb9ad4dbea1220b3991ed84e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c062b1e4de44a92a9d4e5e0b05c24f4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a403b8fdac854751bd9c9a145a5db821",
            "value": "‚Äá2.44G/2.44G‚Äá[00:06&lt;00:00,‚Äá572MB/s]"
          }
        },
        "8630e5ca51004defb5d674c35c33e1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a116809a21a44a21ac6f3eec35c05977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9045935a82544abbbe98e0563a7b365e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba2fb0d51024444886e25d8089852675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a713b7d747cc44ffbcfc0df61af487e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c062b1e4de44a92a9d4e5e0b05c24f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a403b8fdac854751bd9c9a145a5db821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89c489d9de014797876ea598a93fbaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe6abf85d2bf46b9bc8bbc639ecaf1f4",
              "IPY_MODEL_fa3d174069f34a2e9945ac2e69d27ccd",
              "IPY_MODEL_9c769b79611940e88b478ad7aeab3096"
            ],
            "layout": "IPY_MODEL_0a3cf84615f143cab8c77eee99425a80"
          }
        },
        "fe6abf85d2bf46b9bc8bbc639ecaf1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5706a091dde9412ebc768878d6dd24cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_47ecfcbb19fd4a2f98429910a8496c2d",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "fa3d174069f34a2e9945ac2e69d27ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb01ca8694034f2f8a81e4fd28804aaa",
            "max": 261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28e67e3d14174f689c747c71d7d1875d",
            "value": 261
          }
        },
        "9c769b79611940e88b478ad7aeab3096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3abd3acdf6904e7f891c5bec2b185146",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_673395de77514415a91983269e807674",
            "value": "‚Äá261/261‚Äá[00:00&lt;00:00,‚Äá35.7kB/s]"
          }
        },
        "0a3cf84615f143cab8c77eee99425a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5706a091dde9412ebc768878d6dd24cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ecfcbb19fd4a2f98429910a8496c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb01ca8694034f2f8a81e4fd28804aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e67e3d14174f689c747c71d7d1875d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3abd3acdf6904e7f891c5bec2b185146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673395de77514415a91983269e807674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eace40d796b1496184b9e256b0f5ff58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_683f283f15a54975b8068831a34b63e8",
              "IPY_MODEL_eba0d010b09d4b17a0a592d192fefb67",
              "IPY_MODEL_2923c1ebbff8425ca76f365e4a9a8ab5"
            ],
            "layout": "IPY_MODEL_cdedf8f59d9b4973a5a64e62634f1d62"
          }
        },
        "683f283f15a54975b8068831a34b63e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e166b4ba63cf426aa0c35d767419d496",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_595504dafce84302bf2a187f8cb4cab0",
            "value": "Downloading‚Äábuilder‚Äáscript:‚Äá"
          }
        },
        "eba0d010b09d4b17a0a592d192fefb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8d704da73040ca98f7745373bb3283",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b66ce8abac1e402b8c20a96588c25ba4",
            "value": 1
          }
        },
        "2923c1ebbff8425ca76f365e4a9a8ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eeef73edac346e3ba76aa795c48a011",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25ce6dac042245e5895d22d61d3b0024",
            "value": "‚Äá8.15k/?‚Äá[00:00&lt;00:00,‚Äá809kB/s]"
          }
        },
        "cdedf8f59d9b4973a5a64e62634f1d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e166b4ba63cf426aa0c35d767419d496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595504dafce84302bf2a187f8cb4cab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f8d704da73040ca98f7745373bb3283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b66ce8abac1e402b8c20a96588c25ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eeef73edac346e3ba76aa795c48a011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ce6dac042245e5895d22d61d3b0024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c148e40ef94b249cfa3e3c4f181448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae5f109a13004ab1b10f2969449e6050",
              "IPY_MODEL_d49c98f5e4fc4df196ca8518ca35b019",
              "IPY_MODEL_047525958d5e44fc83da915051fe7622"
            ],
            "layout": "IPY_MODEL_44aa552ad86c4f05a01d56816bff0cb4"
          }
        },
        "ae5f109a13004ab1b10f2969449e6050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d51f726c2f4642bb7d911f07efcc1a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_59e61726b7ee4fa48fa15df134f704fe",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "d49c98f5e4fc4df196ca8518ca35b019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c01af05e914d2191fac56a95d455ab",
            "max": 529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6da6279ee2f45ec8e81fee8342dfec6",
            "value": 529
          }
        },
        "047525958d5e44fc83da915051fe7622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6aed2abfa24ddaa6d9691307457f41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90c05a13a3c7464794f67b6495d60a23",
            "value": "‚Äá529/529‚Äá[00:00&lt;00:00,‚Äá47.6kB/s]"
          }
        },
        "44aa552ad86c4f05a01d56816bff0cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d51f726c2f4642bb7d911f07efcc1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e61726b7ee4fa48fa15df134f704fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c01af05e914d2191fac56a95d455ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6da6279ee2f45ec8e81fee8342dfec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d6aed2abfa24ddaa6d9691307457f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c05a13a3c7464794f67b6495d60a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebbf542bd7474cb3a3aaa53c185f0826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f7d6c0b9749453ab9dde7924e1c612f",
              "IPY_MODEL_679ffac103aa4add8cc5339a2c23f498",
              "IPY_MODEL_959a78963d8842f388670c9e1aae824c"
            ],
            "layout": "IPY_MODEL_efad8f6e7e7548b0a2e5a38780d6ff42"
          }
        },
        "5f7d6c0b9749453ab9dde7924e1c612f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a7819e493542bab160d146ba72fa44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c19069b47d5448d98e0e43bd2a9d59e9",
            "value": "sentencepiece.bpe.model:‚Äá100%"
          }
        },
        "679ffac103aa4add8cc5339a2c23f498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d1f142890d44329877a956d4986ea9",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7d97ffa0abc4cb2a313d3e3f3b940ab",
            "value": 5069051
          }
        },
        "959a78963d8842f388670c9e1aae824c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28491f4453f043be89d0f8077a9ef576",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_94871188327e44fcb5bfc76371112299",
            "value": "‚Äá5.07M/5.07M‚Äá[00:01&lt;00:00,‚Äá4.00MB/s]"
          }
        },
        "efad8f6e7e7548b0a2e5a38780d6ff42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a7819e493542bab160d146ba72fa44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19069b47d5448d98e0e43bd2a9d59e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d1f142890d44329877a956d4986ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d97ffa0abc4cb2a313d3e3f3b940ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28491f4453f043be89d0f8077a9ef576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94871188327e44fcb5bfc76371112299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b381cf7e884430c8412e8df5d9e33a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f760e8cb131349ac92bc93553f1c7574",
              "IPY_MODEL_e75aca5ac1a94752ba75882bbb5a0d4b",
              "IPY_MODEL_48a0af3674d34a0f8132bfcc12c83448"
            ],
            "layout": "IPY_MODEL_650b8dbc46e341adac58be59acebf4dd"
          }
        },
        "f760e8cb131349ac92bc93553f1c7574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3ce9408c5342b684ccff80b730ee2f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_208f8d0dbda445dc8cd5dccbfaced4c7",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "e75aca5ac1a94752ba75882bbb5a0d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2ea420d92a4012ab0909acec025ede",
            "max": 649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b84c4e31e6f444896cd46a763af3467",
            "value": 649
          }
        },
        "48a0af3674d34a0f8132bfcc12c83448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7b7158071d4bb3adc6a358b6f89c26",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b08aff255bad4c83b8dec98c5f0030b9",
            "value": "‚Äá649/649‚Äá[00:00&lt;00:00,‚Äá80.1kB/s]"
          }
        },
        "650b8dbc46e341adac58be59acebf4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3ce9408c5342b684ccff80b730ee2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208f8d0dbda445dc8cd5dccbfaced4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d2ea420d92a4012ab0909acec025ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b84c4e31e6f444896cd46a763af3467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f7b7158071d4bb3adc6a358b6f89c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b08aff255bad4c83b8dec98c5f0030b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ec7a5235b64120a959411ea7691a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e15b388c2b284d01b09fe74e76429e86",
              "IPY_MODEL_795c4b755e714de0903584a0495b00fa",
              "IPY_MODEL_ac21efc6674745a69f2d26d56aa314e4"
            ],
            "layout": "IPY_MODEL_fe908d82d1814a12b1641cec37776c00"
          }
        },
        "e15b388c2b284d01b09fe74e76429e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaef1a9a980346678b89dd7225785fd5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9f98853077dd44398a117ceffa1b5b76",
            "value": "config.json:‚Äá"
          }
        },
        "795c4b755e714de0903584a0495b00fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d8906a388c4f4ab220dc75abcc6147",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d954cad081b4c16bd64006f0556a593",
            "value": 1
          }
        },
        "ac21efc6674745a69f2d26d56aa314e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bb2773583304b0297006a8e887055f0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92e0755372244b9497ddb5d778902bc5",
            "value": "‚Äá1.43k/?‚Äá[00:00&lt;00:00,‚Äá176kB/s]"
          }
        },
        "fe908d82d1814a12b1641cec37776c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaef1a9a980346678b89dd7225785fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f98853077dd44398a117ceffa1b5b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d8906a388c4f4ab220dc75abcc6147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8d954cad081b4c16bd64006f0556a593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bb2773583304b0297006a8e887055f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e0755372244b9497ddb5d778902bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f91a9b35beae4da989cb147e53a171ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7eb62fd65cac4fc3b4f9e662cdc2d9c0",
              "IPY_MODEL_3fcf7bd3b5194c19805f56409c8c497e",
              "IPY_MODEL_fbefa02c4cfd418f85b7a630394f23d4"
            ],
            "layout": "IPY_MODEL_784e3f0d0c414eda92f78aeac60a0d85"
          }
        },
        "7eb62fd65cac4fc3b4f9e662cdc2d9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5b73824c62f4e90bd60471939d04525",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5b31330ebaeb456398c50d6c51cafde7",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "3fcf7bd3b5194c19805f56409c8c497e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7684eedb95ff4dacad4ced3c1e15b669",
            "max": 2444578688,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15837c271aee43e4b6b1df94cdd312e6",
            "value": 2444578688
          }
        },
        "fbefa02c4cfd418f85b7a630394f23d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a8e3d431071488f947553436063054e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ee7fc3632d2945c193a87bbcbeb8d81a",
            "value": "‚Äá2.44G/2.44G‚Äá[00:07&lt;00:00,‚Äá333MB/s]"
          }
        },
        "784e3f0d0c414eda92f78aeac60a0d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b73824c62f4e90bd60471939d04525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b31330ebaeb456398c50d6c51cafde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7684eedb95ff4dacad4ced3c1e15b669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15837c271aee43e4b6b1df94cdd312e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a8e3d431071488f947553436063054e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee7fc3632d2945c193a87bbcbeb8d81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b6bb771c3184ed9a9aa936ddcc47130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a972c9f86e34d4bbf1fa609cf73e42f",
              "IPY_MODEL_521ba5683e9e49a49a9a5ac69c6757d6",
              "IPY_MODEL_0b83fa1701504fba895aa59569f691e4"
            ],
            "layout": "IPY_MODEL_0139e25e63db497781c06b1f5f05f29d"
          }
        },
        "2a972c9f86e34d4bbf1fa609cf73e42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd3c74d56e04fe2b5d0e365eb341ecf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9a0d43501b2544b393b3de39689181d6",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "521ba5683e9e49a49a9a5ac69c6757d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c186ac99572b4306a0365554eb026995",
            "max": 261,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9743bae6a9b547368de2765a8cd89915",
            "value": 261
          }
        },
        "0b83fa1701504fba895aa59569f691e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7753cf5b014bfbaec55f651f8967af",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_139d08a797854e43bd9c0f4fde9c0f2c",
            "value": "‚Äá261/261‚Äá[00:00&lt;00:00,‚Äá35.2kB/s]"
          }
        },
        "0139e25e63db497781c06b1f5f05f29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd3c74d56e04fe2b5d0e365eb341ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0d43501b2544b393b3de39689181d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c186ac99572b4306a0365554eb026995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9743bae6a9b547368de2765a8cd89915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7753cf5b014bfbaec55f651f8967af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "139d08a797854e43bd9c0f4fde9c0f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}